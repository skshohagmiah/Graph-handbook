<!DOCTYPE html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Essential Algorithms Handbook</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>
        // Configure Mermaid for better print rendering
        mermaid.initialize({
            startOnLoad: true,
            theme: 'base',
            themeVariables: {
                primaryColor: '#f9f9f9',
                primaryTextColor: '#000000',
                primaryBorderColor: '#333333',
                lineColor: '#333333',
                fontSize: '14px'
            },
            flowchart: {
                useMaxWidth: true,
                htmlLabels: false,
                curve: 'basis'
            },
            sequence: {
                useMaxWidth: true
            },
            gantt: {
                useMaxWidth: true
            },
            fontFamily: 'Arial, sans-serif',
            fontSize: 14
        });
        
        // Fix for print rendering
        window.addEventListener('beforeprint', function() {
            mermaid.init();
        });
    </script>
    <style>
        /* Academic book styling like CPH */
        body { 
            font-family: 'Times New Roman', serif; 
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            font-family: 'Times New Roman', serif;
            font-weight: normal;
        }
        
        .academic-content {
            max-width: 750px;
            margin: 0 auto;
            padding: 60px 40px;
        }
        
        .chapter-number {
            font-size: 16px;
            color: #333;
            text-transform: uppercase;
            letter-spacing: 2px;
            margin-bottom: 12px;
            font-weight: bold;
        }
        
        .chapter-title {
            font-size: 32px;
            font-weight: bold;
            color: #000;
            margin-bottom: 40px;
            line-height: 1.2;
        }
        
        .section-title {
            font-size: 22px;
            font-weight: bold;
            color: #1a202c;
            margin: 45px 0 20px 0;
            border-bottom: 2px solid #4299e1;
            padding-bottom: 10px;
        }
        
        .academic-text {
            font-size: 12pt;
            line-height: 1.7;
            color: #2d3748;
            text-align: justify;
            margin-bottom: 14px;
        }
        
        .code-block {
            background-color: #2d2d2d; /* deeper gray for print clarity */
            color: #f8f8f2; /* softer white */
            border: 1.5px solid #444;
            border-left: 4px solid #3b82f6; /* subtle blue accent */
            border-radius: 6px;
            padding: 14px 18px;
            font-family: 'Fira Code', 'Courier New', monospace;
            font-size: 10pt;
            margin: 20px 0;
            overflow-x: auto;
            white-space: pre;
            line-height: 1.5;
            box-shadow: none; /* remove for PDF */
            }

        
        .definition-box {
            border-left: 4px solid #2196f3;
            background-color: #f8f9fa;
            padding: 16px;
            margin: 20px 0;
            font-style: italic;
            border-radius: 4px;
        }
        
        /* Mermaid diagram styling */
        .mermaid {
            text-align: center;
            margin: 20px 0;
        }
        
        .mermaid svg {
            max-width: 100%;
            height: auto;
        }
        
        .cover-title {
            font-size: 48px;
            font-weight: normal;
            color: black;
            margin-bottom: 40px;
            line-height: 1.3;
            text-align: center;
        }
        
        .cover-divider {
            width: 128px;
            height: 1px;
            background: black;
            margin: 0 auto 40px auto;
        }
        
        .cover-subtitle {
            font-size: 18px;
            color: black;
            font-weight: 300;
            max-width: 400px;
            line-height: 1.5;
            margin: 0 auto 100px auto;
            text-align: center;
        }
        
        .cover-author {
            font-size: 18px;
            color: black;
            font-weight: normal;
            margin-bottom: 12px;
            text-align: center;
        }
        
        .cover-year {
            font-size: 16px;
            color: black;
            font-weight: 300;
            text-align: center;
        }
        
        /* Cover page container styling */
        .cover-page {
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            text-align: center;
            padding: 0 48px;
            font-family: 'Times New Roman', serif;
        }
        
        .cover-content {
            flex: 1;
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            align-items: center;
            width: 100%;
            max-width: 600px;
        }
        
        .cover-main {
            flex: 2;
            display: flex;
            flex-direction: column;
            justify-content: center;
        }
        
        .cover-footer {
            flex: 1;
            display: flex;
            flex-direction: column;
            justify-content: flex-end;
            padding-bottom: 60px;
        }
        
        /* Summary section styling to match diagram backgrounds */
        .summary-section {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .performance-summary {
            background-color: #f8f9fa;
            border: 2px solid #4caf50;
            border-radius: 8px;
            padding: 25px;
            margin: 30px 0;
        }
        
        .completion-summary {
            background-color: #f8f9fa;
            border-left: 5px solid #2196f3;
            padding: 20px;
            margin: 30px 0;
        }
        
        @media print {
            body {
                font-family: Times, serif !important;
                font-size: 14pt !important;
                line-height: 1.5 !important;
                margin: 0.1in !important;
                color: black !important;
                background: white !important;
            }
            
            /* Keep chapter titles with content */
            .chapter-number {
                font-size: 16pt !important;
                font-weight: bold !important;
                margin: 0 0 6pt 0 !important;
                page-break-before: always;
                page-break-after: avoid;
            }
            
            .chapter-title {
                font-size: 24pt !important;
                font-weight: bold !important;
                margin: 6pt 0 15pt 0 !important;
                page-break-after: avoid;
                page-break-inside: avoid;
            }
            
            .section-title, h2 {
                font-size: 18pt !important;
                font-weight: bold !important;
                margin: 15pt 0 10pt 0 !important;
                page-break-after: avoid;
            }
            
            h3 {
                font-size: 16pt !important;
                font-weight: bold !important;
                margin: 12pt 0 8pt 0 !important;
                page-break-after: avoid;
            }
            
            p, .academic-text {
                margin: 0 0 8pt 0 !important;
                text-align: justify !important;
            }
            
            /* Keep first content with chapter title */
            .chapter-title + p,
            .chapter-title + .academic-text,
            .chapter-title + ul,
            .chapter-title + ol,
            .chapter-title + pre,
            .chapter-title + .code-block {
                page-break-before: avoid !important;
            }
            
            pre, .code-block {
                font-family: 'Courier New', Courier, monospace !important;
                font-size: 9pt !important;
                line-height: 1.3 !important;
                background-color: #1a1a1a !important;
                color: #f0f0f0 !important;
                border: 2pt solid #444444 !important;
                padding: 10pt !important;
                margin: 12pt 0 !important;
                page-break-inside: avoid !important;
                white-space: pre-wrap !important;
                word-wrap: break-word !important;
                -webkit-print-color-adjust: exact !important;
                print-color-adjust: exact !important;
            }
            
            ul, ol {
                margin: 8pt 0 10pt 20pt !important;
            }
            
            li {
                margin-bottom: 3pt !important;
            }
            
            .mermaid {
                margin: 12pt 0 !important;
                text-align: center !important;
            }
            
            .definition-box {
                background: #f9f9f9 !important;
                border-left: 3pt solid #333 !important;
                padding: 8pt !important;
                margin: 10pt 0 !important;
            }
            
            /* Cover page with author/year at bottom */
            .cover-container {
                page-break-inside: avoid !important;
                page-break-after: always !important;
                page-break-before: auto !important;
                text-align: center !important;
                padding: 30pt !important;
                min-height: calc(100vh - 60pt) !important;
                display: flex !important;
                flex-direction: column !important;
                justify-content: space-between !important;
            }
            
            .cover-container * {
                page-break-inside: avoid !important;
                page-break-before: avoid !important;
                page-break-after: avoid !important;
            }
            
            .cover-title {
                font-size: 26pt !important;
                font-weight: bold !important;
                margin: 10pt 0 15pt 0 !important;
                line-height: 1.1 !important;
                text-align: center !important;
            }
            
            .cover-subtitle {
                font-size: 14pt !important;
                margin: 0 0 20pt 0 !important;
                line-height: 1.3 !important;
                text-align: center !important;
            }
            
            .cover-author {
                font-size: 16pt !important;
                font-weight: bold !important;
                margin: auto 0 5pt 0 !important;
                text-align: center !important;
            }
            
            .cover-year {
                font-size: 14pt !important;
                margin: 0 !important;
                text-align: center !important;
            }
        }
        }
    </style>
</head>
<body class="font-sans text-gray-800 bg-white">

    <div class="cover-page " id="cover">
        
    <div class="cover-container">
        <div class="cover-content">
            <div class="cover-main">
                <h1 class="cover-title">The Essential Algorithms Handbook</h1>
                <div class="cover-divider"></div>
                <p class="cover-subtitle">70 Must-Know Algorithms for Programming Interviews and Competitive Programming</p>
            </div>
            <div class="cover-footer">
                <p class="cover-author">Shohag Miah</p>
                <p class="cover-year">2025</p>
            </div>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="preface">
        
    <div class="academic-content">
        <h1 class="chapter-title">Preface</h1>
        
        <p class="academic-text">
            Welcome to <strong>The Essential Algorithms Handbook</strong> – your comprehensive guide to mastering 70 fundamental algorithms that every programmer should know. This handbook is designed to be a practical reference for students, software engineers, and anyone preparing for technical interviews or competitive programming contests.
        </p>
        
        <p class="academic-text">
            In today's rapidly evolving tech landscape, having a solid foundation in algorithms is more crucial than ever. Whether you're solving complex business problems, optimizing system performance, or tackling coding challenges, the algorithms in this handbook will serve as your trusted toolkit.
        </p>
        
        <h2 class="section-title">Why This Handbook?</h2>
        
        <p class="academic-text">
            This handbook stands out for several reasons:
        </p>
        
        <ul>
            <li><strong>Comprehensive Coverage:</strong> 70 carefully selected algorithms spanning 13 different categories</li>
            <li><strong>Practical Focus:</strong> Each algorithm includes real-world applications and use cases</li>
            <li><strong>Interview Ready:</strong> Algorithms are presented in a format suitable for technical interviews</li>
            <li><strong>Multiple Languages:</strong> Code examples primarily in C++ with explanations applicable to other languages</li>
            <li><strong>Visual Learning:</strong> Diagrams and step-by-step explanations for complex concepts</li>
        </ul>
        
        <h2 class="section-title">How to Use This Book</h2>
        
        <p class="academic-text">
            This handbook is organized into 13 parts, each focusing on a specific category of algorithms. You can read it sequentially or jump to specific sections based on your needs:
        </p>
        
        <ul>
            <li><strong>For Beginners:</strong> Start with searching and sorting algorithms, then progress through the parts</li>
            <li><strong>For Interview Preparation:</strong> Focus on dynamic programming, graph algorithms, and string algorithms</li>
            <li><strong>For Competitive Programming:</strong> Pay special attention to mathematical algorithms and advanced data structures</li>
            <li><strong>As a Reference:</strong> Use the complexity cheat sheet and jump to specific algorithms as needed</li>
        </ul>
        
        <h2 class="section-title">Prerequisites</h2>
        
        <p class="academic-text">
            This handbook assumes basic familiarity with:
        </p>
        
        <ul>
            <li>Programming fundamentals (variables, loops, functions)</li>
            <li>Basic data structures (arrays, linked lists, stacks, queues)</li>
            <li>Elementary mathematics (logarithms, basic combinatorics)</li>
            <li>C++ syntax (for code examples)</li>
        </ul>
        
        <h2 class="section-title">Acknowledgments</h2>
        
        <p class="academic-text">
            This handbook builds upon decades of computer science research and the collective wisdom of the programming community. Special thanks to the authors of foundational texts like "Introduction to Algorithms" by Cormen et al., "Competitive Programming" by Steven Halim, and countless online resources that have made algorithmic knowledge accessible to all.
        </p>
        
        <p class="academic-text">
            Whether you're just starting your programming journey or looking to sharpen your algorithmic skills, I hope this handbook serves as a valuable companion in your learning adventure.
        </p>
        
        <p class="academic-text" style="margin-top: 40px;">
            <em>Happy coding!</em><br>
            <strong>Shohag Miah</strong><br>
            October 2024
        </p>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="how-to-use">
        
    <div class="academic-content">
        <h1 class="chapter-title">How to Use This Book</h1>
        
        <p class="academic-text">
            This handbook is designed to be both a learning resource and a quick reference guide. Here's how to make the most of it:
        </p>
        
        <h2 class="section-title">Structure and Organization</h2>
        
        <p class="academic-text">
            The book is organized into 13 parts, each covering a specific category of algorithms:
        </p>
        
        <div class="definition-box">
            <strong>Parts I-II:</strong> Fundamental algorithms (searching and sorting)<br>
            <strong>Parts III-V:</strong> Data structure algorithms (trees, graphs, dynamic programming)<br>
            <strong>Parts VI-VIII:</strong> Specialized algorithms (mathematical, string, greedy)<br>
            <strong>Parts IX-XIII:</strong> Advanced techniques (backtracking, divide & conquer, bit manipulation, geometry, advanced data structures)
        </div>
        
        <h2 class="section-title">Algorithm Presentation Format</h2>
        
        <p class="academic-text">
            Each algorithm follows a consistent format:
        </p>
        
        <ul>
            <li><strong>Problem Statement:</strong> Clear description of what the algorithm solves</li>
            <li><strong>Approach:</strong> High-level strategy and intuition</li>
            <li><strong>Algorithm Steps:</strong> Detailed step-by-step breakdown</li>
            <li><strong>Implementation:</strong> Complete C++ code with comments</li>
            <li><strong>Complexity Analysis:</strong> Time and space complexity</li>
            <li><strong>Example:</strong> Worked example with trace</li>
            <li><strong>Applications:</strong> Real-world use cases</li>
            <li><strong>Variations:</strong> Common modifications and extensions</li>
        </ul>
        
        <h2 class="section-title">Reading Strategies</h2>
        
        <h3>For Complete Beginners</h3>
        <p class="academic-text">
            Start with Part I (Searching) and Part II (Sorting). These provide the foundation for understanding more complex algorithms. Don't skip the complexity analysis sections – understanding Big O notation is crucial.
        </p>
        
        <h3>For Interview Preparation</h3>
        <p class="academic-text">
            Focus on these high-priority sections:
        </p>
        <ul>
            <li>Part V: Dynamic Programming (most important for interviews)</li>
            <li>Part IV: Graph Algorithms</li>
            <li>Part VII: String Algorithms</li>
            <li>Part III: Tree Algorithms</li>
            <li>Part XIII: Advanced Data Structures (LRU Cache, Union-Find)</li>
        </ul>
        
        <h3>For Competitive Programming</h3>
        <p class="academic-text">
            Emphasize these areas:
        </p>
        <ul>
            <li>Part VI: Mathematical & Number Theory</li>
            <li>Part XI: Bit Manipulation</li>
            <li>Part XII: Computational Geometry</li>
            <li>Advanced variations in each section</li>
        </ul>
        
        <h3>As a Reference Guide</h3>
        <p class="academic-text">
            Use the Algorithm Complexity Cheat Sheet to quickly find algorithms by their time/space complexity. Each algorithm includes a summary box for quick reference.
        </p>
        
        <h2 class="section-title">Code Examples</h2>
        
        <p class="academic-text">
            All code examples are written in C++ for consistency, but the concepts apply to any programming language. Key features of the code:
        </p>
        
        <ul>
            <li><strong>Modern C++:</strong> Uses C++17 features where appropriate</li>
            <li><strong>STL Integration:</strong> Leverages Standard Template Library when beneficial</li>
            <li><strong>Clear Naming:</strong> Variable and function names are descriptive</li>
            <li><strong>Comprehensive Comments:</strong> Every non-trivial line is explained</li>
            <li><strong>Error Handling:</strong> Includes basic input validation</li>
        </ul>
        
        <h2 class="section-title">Practice Recommendations</h2>
        
        <div class="definition-box">
            <strong>Active Learning:</strong> Don't just read the code – implement it yourself. Try to write the algorithm from memory after understanding it.
        </div>
        
        <p class="academic-text">
            For each algorithm:
        </p>
        
        <ol>
            <li><strong>Understand the Problem:</strong> Make sure you grasp what the algorithm is trying to solve</li>
            <li><strong>Trace Through Examples:</strong> Work through the provided examples step by step</li>
            <li><strong>Implement from Scratch:</strong> Try coding it without looking at the solution</li>
            <li><strong>Test with Edge Cases:</strong> Consider empty inputs, single elements, duplicates, etc.</li>
            <li><strong>Analyze Complexity:</strong> Verify the time and space complexity claims</li>
            <li><strong>Explore Variations:</strong> Try the suggested modifications</li>
        </ol>
        
        <h2 class="section-title">Additional Resources</h2>
        
        <p class="academic-text">
            While this handbook is comprehensive, consider these supplementary resources:
        </p>
        
        <ul>
            <li><strong>Online Judges:</strong> LeetCode, Codeforces, AtCoder for practice problems</li>
            <li><strong>Visualization Tools:</strong> VisuAlgo, Algorithm Visualizer for interactive learning</li>
            <li><strong>Community:</strong> Stack Overflow, Reddit r/algorithms for discussions</li>
            <li><strong>Advanced Texts:</strong> CLRS, Skiena's Algorithm Design Manual for deeper theory</li>
        </ul>
        
        <h2 class="section-title">Symbols and Conventions</h2>
        
        <p class="academic-text">
            Throughout this book, we use these conventions:
        </p>
        
        <ul>
            <li><strong>n:</strong> Input size (number of elements)</li>
            <li><strong>O(f(n)):</strong> Big O notation for time/space complexity</li>
            <li><strong>log n:</strong> Logarithm base 2 (unless otherwise specified)</li>
            <li><strong>💡:</strong> Key insights and tips</li>
            <li><strong>⚠️:</strong> Common pitfalls and gotchas</li>
            <li><strong>🎯:</strong> Interview-specific notes</li>
        </ul>
        
        <p class="academic-text">
            Remember: algorithms are tools for solving problems. Focus on understanding when and why to use each algorithm, not just how to implement it.
        </p>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="complexity">
        
    <div class="academic-content">
        <h1 class="chapter-title">Algorithm Complexity Cheat Sheet</h1>
        
        <p class="academic-text">
            This cheat sheet provides a quick reference for the time and space complexities of all 70 algorithms covered in this handbook. Use it to quickly identify the most efficient algorithm for your specific constraints.
        </p>
        
        <h2 class="section-title">Complexity Growth Rates</h2>
        
        <div class="definition-box">
            <strong>From Best to Worst:</strong><br>
            O(1) < O(log n) < O(n) < O(n log n) < O(n²) < O(n³) < O(2ⁿ) < O(n!)
        </div>
        
        <h2 class="section-title">Part I: Searching Algorithms</h2>
        
        <table style="width: 100%; border-collapse: collapse; margin: 20px 0;">
            <tr style="background-color: #f8f9fa; border: 1px solid #dee2e6;">
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Algorithm</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Time (Average)</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Time (Worst)</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Space</th>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Linear Search</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Binary Search</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Ternary Search</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log₃ n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log₃ n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Jump Search</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(√n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(√n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Interpolation Search</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Exponential Search</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Fibonacci Search</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
            </tr>
        </table>
        
        <h2 class="section-title">Part II: Sorting Algorithms</h2>
        
        <table style="width: 100%; border-collapse: collapse; margin: 20px 0;">
            <tr style="background-color: #f8f9fa; border: 1px solid #dee2e6;">
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Algorithm</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Time (Best)</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Time (Average)</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Time (Worst)</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Space</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Stable</th>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Bubble Sort</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n²)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n²)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">Yes</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Selection Sort</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n²)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n²)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n²)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">No</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Insertion Sort</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n²)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n²)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">Yes</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Merge Sort</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">Yes</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Quick Sort</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n²)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">No</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Heap Sort</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">No</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Counting Sort</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n + k)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n + k)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n + k)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(k)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">Yes</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Radix Sort</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(d(n + k))</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(d(n + k))</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(d(n + k))</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n + k)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">Yes</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Bucket Sort</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n + k)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n + k)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n²)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">Yes</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Shell Sort</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n^1.25)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n²)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(1)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">No</td>
            </tr>
        </table>
        
        <h2 class="section-title">Part III: Tree Algorithms</h2>
        
        <table style="width: 100%; border-collapse: collapse; margin: 20px 0;">
            <tr style="background-color: #f8f9fa; border: 1px solid #dee2e6;">
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Algorithm</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Search</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Insert</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Delete</th>
                <th style="padding: 12px; text-align: left; border: 1px solid #dee2e6;">Space</th>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">BST (Average)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">BST (Worst)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">AVL Tree</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Red-Black Tree</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">B-Tree</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Segment Tree</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Fenwick Tree</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(log n)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(n)</td>
            </tr>
            <tr style="border: 1px solid #dee2e6;">
                <td style="padding: 8px; border: 1px solid #dee2e6;">Trie</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(m)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(m)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(m)</td>
                <td style="padding: 8px; border: 1px solid #dee2e6;">O(ALPHABET_SIZE * N * M)</td>
            </tr>
        </table>
        
        <p class="academic-text" style="font-size: 10pt; color: #666;">
            <em>Note: m = length of string, N = number of strings, k = range of input, d = number of digits</em>
        </p>
        
        <h2 class="section-title">Quick Selection Guide</h2>
        
        <div class="definition-box">
            <strong>Need O(1) operations?</strong> Hash Table, Array Access<br>
            <strong>Need O(log n) operations?</strong> Binary Search, Balanced Trees, Heaps<br>
            <strong>Need O(n) is acceptable?</strong> Linear Search, Hash Table (worst case)<br>
            <strong>Working with strings?</strong> Trie, KMP, Rabin-Karp<br>
            <strong>Working with graphs?</strong> BFS/DFS O(V+E), Dijkstra O(E log V)<br>
            <strong>Need sorting?</strong> Quick/Merge Sort O(n log n), Counting Sort O(n+k)
        </div>
        
        <h2 class="section-title">Memory vs Time Trade-offs</h2>
        
        <p class="academic-text">
            Common patterns in algorithm design:
        </p>
        
        <ul>
            <li><strong>More Memory → Faster Time:</strong> Hash tables, memoization, precomputed tables</li>
            <li><strong>Less Memory → Slower Time:</strong> In-place algorithms, recursive solutions</li>
            <li><strong>Preprocessing:</strong> Sort once, search many times (O(n log n) + O(log n) per query)</li>
            <li><strong>Amortized Analysis:</strong> Dynamic arrays, Union-Find with path compression</li>
        </ul>
        
        <p class="academic-text">
            Use this cheat sheet as a quick reference, but always consider the specific constraints and requirements of your problem when choosing an algorithm.
        </p>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="cpp-ref">
        
    <div class="academic-content">
        <h1 class="chapter-title">C++ Standard Library Quick Reference</h1>
        
        <p class="academic-text">
            This reference covers the most commonly used C++ Standard Template Library (STL) components that appear throughout this handbook. Mastering these will significantly improve your algorithm implementation speed.
        </p>
        
        <h2 class="section-title">Essential Headers</h2>
        
        <div class="code-block">
#include &lt;iostream&gt;     // Input/output operations
#include &lt;vector&gt;       // Dynamic arrays
#include &lt;algorithm&gt;    // Algorithms (sort, binary_search, etc.)
#include &lt;string&gt;       // String operations
#include &lt;queue&gt;        // Queue and priority_queue
#include &lt;stack&gt;        // Stack operations
#include &lt;map&gt;          // Ordered key-value pairs
#include &lt;unordered_map&gt; // Hash table
#include &lt;set&gt;          // Ordered unique elements
#include &lt;unordered_set&gt; // Hash set
#include &lt;climits&gt;      // INT_MAX, INT_MIN, etc.
#include &lt;cmath&gt;        // Mathematical functions
        </div>
        
        <h2 class="section-title">Containers</h2>
        
        <h3>Vector (Dynamic Array)</h3>
        <div class="code-block">
vector&lt;int&gt; v;              // Empty vector
vector&lt;int&gt; v(n);          // Vector of size n
vector&lt;int&gt; v(n, val);     // Vector of size n, all elements = val

// Common operations
v.push_back(x);            // Add element to end - O(1) amortized
v.pop_back();              // Remove last element - O(1)
v.size();                  // Number of elements - O(1)
v.empty();                 // Check if empty - O(1)
v[i];                      // Access element at index i - O(1)
v.front(), v.back();       // First and last elements - O(1)
v.clear();                 // Remove all elements - O(n)
v.resize(n);               // Change size to n - O(n)
        </div>
        
        <h3>String</h3>
        <div class="code-block">
string s = "hello";
s.length(), s.size();      // Length of string - O(1)
s.substr(pos, len);        // Substring starting at pos - O(len)
s.find(substr);            // Find first occurrence - O(n*m)
s.push_back(ch);           // Add character to end - O(1) amortized
s.pop_back();              // Remove last character - O(1)
s += "world";              // Concatenation - O(m)
        </div>
        
        <h3>Queue and Stack</h3>
        <div class="code-block">
// Queue (FIFO)
queue&lt;int&gt; q;
q.push(x);                 // Add to back - O(1)
q.pop();                   // Remove from front - O(1)
q.front();                 // Access front element - O(1)
q.empty(), q.size();       // Status checks - O(1)

// Stack (LIFO)
stack&lt;int&gt; st;
st.push(x);                // Add to top - O(1)
st.pop();                  // Remove from top - O(1)
st.top();                  // Access top element - O(1)
st.empty(), st.size();     // Status checks - O(1)
        </div>
        
        <h3>Priority Queue (Heap)</h3>
        <div class="code-block">
// Max heap by default
priority_queue&lt;int&gt; pq;
pq.push(x);                // Insert element - O(log n)
pq.pop();                  // Remove max element - O(log n)
pq.top();                  // Access max element - O(1)

// Min heap
priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; min_pq;

// Custom comparator
auto cmp = [](const pair&lt;int,int&gt;&amp; a, const pair&lt;int,int&gt;&amp; b) {
    return a.second > b.second; // Min heap based on second element
};
priority_queue&lt;pair&lt;int,int&gt;, vector&lt;pair&lt;int,int&gt;&gt;, decltype(cmp)&gt; pq(cmp);
        </div>
        
        <h3>Map and Set</h3>
        <div class="code-block">
// Ordered map (Red-Black Tree)
map&lt;int, string&gt; m;
m[key] = value;            // Insert/update - O(log n)
m.find(key);               // Find element - O(log n)
m.count(key);              // Check existence - O(log n)
m.erase(key);              // Remove element - O(log n)

// Hash map (faster average case)
unordered_map&lt;int, string&gt; um;
um[key] = value;           // Insert/update - O(1) average, O(n) worst
um.find(key);              // Find element - O(1) average, O(n) worst

// Ordered set
set&lt;int&gt; s;
s.insert(x);               // Insert element - O(log n)
s.erase(x);                // Remove element - O(log n)
s.find(x);                 // Find element - O(log n)
s.count(x);                // Check existence (0 or 1) - O(log n)

// Hash set
unordered_set&lt;int&gt; us;
us.insert(x);              // Insert element - O(1) average
        </div>
        
        <h2 class="section-title">Algorithms</h2>
        
        <h3>Sorting and Searching</h3>
        <div class="code-block">
vector&lt;int&gt; v = {3, 1, 4, 1, 5};

// Sorting
sort(v.begin(), v.end());                    // Ascending order - O(n log n)
sort(v.begin(), v.end(), greater&lt;int&gt;());    // Descending order
sort(v.begin(), v.end(), [](int a, int b) { // Custom comparator
    return a > b;
});

// Searching (requires sorted array)
binary_search(v.begin(), v.end(), x);       // Returns bool - O(log n)
lower_bound(v.begin(), v.end(), x);         // First position >= x - O(log n)
upper_bound(v.begin(), v.end(), x);         // First position > x - O(log n)

// Finding min/max
auto it = min_element(v.begin(), v.end());  // Iterator to min element - O(n)
auto it = max_element(v.begin(), v.end());  // Iterator to max element - O(n)
        </div>
        
        <h3>Useful Algorithms</h3>
        <div class="code-block">
// Reverse
reverse(v.begin(), v.end());               // Reverse container - O(n)

// Unique (requires sorted array)
sort(v.begin(), v.end());
v.erase(unique(v.begin(), v.end()), v.end()); // Remove duplicates - O(n)

// Next/Previous permutation
next_permutation(v.begin(), v.end());      // Generate next permutation - O(n)
prev_permutation(v.begin(), v.end());      // Generate previous permutation - O(n)

// Fill
fill(v.begin(), v.end(), value);           // Fill with value - O(n)

// Count
count(v.begin(), v.end(), value);          // Count occurrences - O(n)
        </div>
        
        <h2 class="section-title">Iterators</h2>
        
        <div class="code-block">
vector&lt;int&gt; v = {1, 2, 3, 4, 5};

// Iterator types
vector&lt;int&gt;::iterator it;           // Mutable iterator
vector&lt;int&gt;::const_iterator cit;   // Immutable iterator
auto it = v.begin();               // Auto type deduction

// Common operations
it++;                              // Move to next element
it--;                              // Move to previous element
*it;                               // Dereference (get value)
it + n;                            // Move n positions forward
distance(it1, it2);                // Distance between iterators

// Range-based for loop (C++11)
for (int x : v) {                  // Copy each element
    cout << x << " ";
}
for (int&amp; x : v) {                 // Reference to each element
    x *= 2;
}
        </div>
        
        <h2 class="section-title">Pairs and Tuples</h2>
        
        <div class="code-block">
// Pair
pair&lt;int, string&gt; p = {1, "hello"};
pair&lt;int, string&gt; p = make_pair(1, "hello");
cout << p.first << " " << p.second;

// Tuple (C++11)
tuple&lt;int, string, double&gt; t = make_tuple(1, "hello", 3.14);
cout << get&lt;0&gt;(t) << " " << get&lt;1&gt;(t) << " " << get&lt;2&gt;(t);

// Structured bindings (C++17)
auto [x, y, z] = t;
        </div>
        
        <h2 class="section-title">Lambda Functions (C++11)</h2>
        
        <div class="code-block">
// Basic lambda
auto add = [](int a, int b) { return a + b; };

// Capture by value
int multiplier = 2;
auto multiply = [multiplier](int x) { return x * multiplier; };

// Capture by reference
auto increment = [&multiplier]() { multiplier++; };

// Capture all by value/reference
auto lambda1 = [=](int x) { /* capture all by value */ };
auto lambda2 = [&](int x) { /* capture all by reference */ };

// Use with STL algorithms
sort(v.begin(), v.end(), [](int a, int b) { return a > b; });
        </div>
        
        <h2 class="section-title">Common Patterns</h2>
        
        <h3>Two Pointers</h3>
        <div class="code-block">
int left = 0, right = v.size() - 1;
while (left < right) {
    if (condition) {
        left++;
    } else {
        right--;
    }
}
        </div>
        
        <h3>Sliding Window</h3>
        <div class="code-block">
int left = 0;
for (int right = 0; right < n; right++) {
    // Add v[right] to window
    while (window_invalid) {
        // Remove v[left] from window
        left++;
    }
    // Update answer with current window [left, right]
}
        </div>
        
        <h3>Frequency Counting</h3>
        <div class="code-block">
unordered_map&lt;int, int&gt; freq;
for (int x : v) {
    freq[x]++;
}
        </div>
        
        <h2 class="section-title">Input/Output Tips</h2>
        
        <div class="code-block">
// Fast I/O
ios_base::sync_with_stdio(false);
cin.tie(NULL);

// Reading until EOF
int x;
while (cin >> x) {
    // Process x
}

// Reading a line
string line;
getline(cin, line);

// Formatted output
cout << fixed << setprecision(2) << 3.14159; // Output: 3.14
        </div>
        
        <h2 class="section-title">Constants and Limits</h2>
        
        <div class="code-block">
#include &lt;climits&gt;
INT_MAX, INT_MIN           // 32-bit integer limits
LLONG_MAX, LLONG_MIN       // 64-bit integer limits

#include &lt;cmath&gt;
INFINITY                   // Positive infinity
M_PI                       // Pi (may not be available on all systems)

// Safe infinity values
const int INF = 1e9;
const long long LLINF = 1e18;
        </div>
        
        <div class="definition-box">
            <strong>💡 Pro Tips:</strong><br>
            • Use <code>auto</code> for complex iterator types<br>
            • Prefer range-based for loops when possible<br>
            • Use <code>emplace_back()</code> instead of <code>push_back()</code> for complex objects<br>
            • Remember that <code>map</code> and <code>set</code> are ordered, <code>unordered_map</code> and <code>unordered_set</code> are not<br>
            • Always check if iterators are valid before dereferencing
        </div>
        
        <p class="academic-text">
            This reference covers the most essential STL components. For complete documentation, refer to <a href="https://cppreference.com">cppreference.com</a>.
        </p>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="toc">
        
    <div class="academic-content">
        <h1 class="chapter-title">Table of Contents</h1>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">FRONT MATTER</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Preface</div>
                <div>How to Use This Book</div>
                <div>Algorithm Complexity Cheat Sheet</div>
                <div>C++ Standard Library Quick Reference</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART I: SEARCHING ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 1: Linear Search</div>
                <div>Chapter 2: Binary Search</div>
                <div>Chapter 3: Ternary Search</div>
                <div>Chapter 4: Jump Search</div>
                <div>Chapter 5: Interpolation Search</div>
                <div>Chapter 6: Exponential Search</div>
                <div>Chapter 7: Fibonacci Search</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART II: SORTING ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 8: Bubble Sort</div>
                <div>Chapter 9: Selection Sort</div>
                <div>Chapter 10: Insertion Sort</div>
                <div>Chapter 11: Merge Sort</div>
                <div>Chapter 12: Quick Sort</div>
                <div>Chapter 13: Heap Sort</div>
                <div>Chapter 14: Counting Sort</div>
                <div>Chapter 15: Radix Sort</div>
                <div>Chapter 16: Bucket Sort</div>
                <div>Chapter 17: Shell Sort</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART III: TREE ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 18: Binary Search Tree Operations</div>
                <div>Chapter 19: AVL Tree</div>
                <div>Chapter 20: Red-Black Tree</div>
                <div>Chapter 21: B-Tree Operations</div>
                <div>Chapter 22: Segment Tree</div>
                <div>Chapter 23: Fenwick Tree (Binary Indexed Tree)</div>
                <div>Chapter 24: Trie (Prefix Tree)</div>
                <div>Chapter 25: Suffix Tree/Array</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART IV: GRAPH ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 26: Breadth-First Search (BFS)</div>
                <div>Chapter 27: Depth-First Search (DFS)</div>
                <div>Chapter 28: Dijkstra's Shortest Path</div>
                <div>Chapter 29: Bellman-Ford Algorithm</div>
                <div>Chapter 30: Floyd-Warshall Algorithm</div>
                <div>Chapter 31: Prim's Algorithm (MST)</div>
                <div>Chapter 32: Kruskal's Algorithm (MST)</div>
                <div>Chapter 33: Topological Sort</div>
                <div>Chapter 34: Tarjan's Algorithm (Strongly Connected Components)</div>
                <div>Chapter 35: Kosaraju's Algorithm (SCC)</div>
                <div>Chapter 36: Articulation Points and Bridges</div>
                <div>Chapter 37: A* Search Algorithm</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART V: DYNAMIC PROGRAMMING ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 38: Longest Common Subsequence (LCS)</div>
                <div>Chapter 39: Longest Increasing Subsequence (LIS)</div>
                <div>Chapter 40: 0/1 Knapsack Problem</div>
                <div>Chapter 41: Unbounded Knapsack</div>
                <div>Chapter 42: Coin Change Problem (Min Coins & Ways)</div>
                <div>Chapter 43: Matrix Chain Multiplication</div>
                <div>Chapter 44: Edit Distance (Levenshtein Distance)</div>
                <div>Chapter 45: Subset Sum Problem</div>
                <div>Chapter 46: Partition Problem</div>
                <div>Chapter 47: Rod Cutting Problem</div>
                <div>Chapter 48: Egg Dropping Problem</div>
                <div>Chapter 49: Palindrome Partitioning</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART VI: MATHEMATICAL & NUMBER THEORY ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 50: Euclidean Algorithm (GCD/LCM)</div>
                <div>Chapter 51: Extended Euclidean Algorithm</div>
                <div>Chapter 52: Sieve of Eratosthenes</div>
                <div>Chapter 53: Segmented Sieve</div>
                <div>Chapter 54: Modular Exponentiation (Binary Exponentiation)</div>
                <div>Chapter 55: Fast Fourier Transform (FFT)</div>
                <div>Chapter 56: Kadane's Algorithm (Maximum Subarray)</div>
                <div>Chapter 57: Miller-Rabin Primality Test</div>
                <div>Chapter 58: Chinese Remainder Theorem</div>
                <div>Chapter 59: Catalan Numbers Computation</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART VII: STRING ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 60: KMP (Knuth-Morris-Pratt) Algorithm</div>
                <div>Chapter 61: Rabin-Karp Algorithm</div>
                <div>Chapter 62: Boyer-Moore Algorithm</div>
                <div>Chapter 63: Z Algorithm</div>
                <div>Chapter 64: Manacher's Algorithm</div>
                <div>Chapter 65: Aho-Corasick Algorithm</div>
                <div>Chapter 66: Suffix Array Construction</div>
                <div>Chapter 67: Longest Common Prefix (LCP) Array</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART VIII: GREEDY ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 68: Huffman Coding</div>
                <div>Chapter 69: Activity Selection Problem</div>
                <div>Chapter 70: Fractional Knapsack</div>
                <div>Chapter 71: Job Sequencing with Deadlines</div>
                <div>Chapter 72: Minimum Platforms Problem</div>
                <div>Chapter 73: Egyptian Fraction</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART IX: BACKTRACKING ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 74: N-Queens Problem</div>
                <div>Chapter 75: Sudoku Solver</div>
                <div>Chapter 76: Hamiltonian Path/Cycle</div>
                <div>Chapter 77: Graph Coloring Problem</div>
                <div>Chapter 78: Rat in a Maze</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART X: DIVIDE AND CONQUER ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 79: Merge Sort (revisited with analysis)</div>
                <div>Chapter 80: Quick Sort (revisited with analysis)</div>
                <div>Chapter 81: Closest Pair of Points</div>
                <div>Chapter 82: Strassen's Matrix Multiplication</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART XI: BIT MANIPULATION ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 83: Count Set Bits (Brian Kernighan's Algorithm)</div>
                <div>Chapter 84: Power of Two Check</div>
                <div>Chapter 85: Find Single Number (XOR technique)</div>
                <div>Chapter 86: Subset Generation using Bits</div>
                <div>Chapter 87: Bit Masking for DP</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART XII: COMPUTATIONAL GEOMETRY ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 88: Convex Hull (Graham Scan)</div>
                <div>Chapter 89: Line Segment Intersection</div>
                <div>Chapter 90: Point in Polygon Test</div>
                <div>Chapter 91: Closest Pair of Points</div>
            </div>
        </div>
        
        <div style="margin: 40px 0;">
            <h2 style="font-size: 18px; margin-bottom: 20px; color: #1a202c;">PART XIII: ADVANCED DATA STRUCTURE ALGORITHMS</h2>
            <div style="margin-left: 20px; line-height: 1.8;">
                <div>Chapter 92: Union-Find (Disjoint Set Union)</div>
                <div>Chapter 93: LRU Cache Implementation</div>
                <div>Chapter 94: Skip List</div>
                <div>Chapter 95: Bloom Filter</div>
                <div>Chapter 96: Reservoir Sampling</div>
                <div>Chapter 97: Morris Traversal (Inorder without recursion/stack)</div>
            </div>
        </div>
        
        <div style="margin: 60px 0 40px 0; padding-top: 20px; border-top: 2px solid #e2e8f0;">
            <h2 style="font-size: 16px; margin-bottom: 15px; color: #4a5568;">SUMMARY</h2>
            <div style="margin-left: 20px; line-height: 1.6; color: #2d3748;">
                <div><strong>Total Algorithms:</strong> 70</div>
                <div><strong>Total Chapters:</strong> 97</div>
                <div><strong>Categories:</strong> 13 Parts</div>
                <div><strong>Focus Areas:</strong> Interview Preparation, Competitive Programming, Software Engineering</div>
            </div>
        </div>
        
        <div class="definition-box" style="margin-top: 40px;">
            <strong>Navigation Tips:</strong><br>
            • Each algorithm includes complexity analysis and real-world applications<br>
            • Code examples are provided in C++ with detailed explanations<br>
            • Cross-references highlight relationships between algorithms<br>
            • Practice problems and variations are suggested for each topic
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch1">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 1</div>
        <h1 class="chapter-title">Linear Search</h1>
        
        <p class="academic-text">
            Linear search, also known as sequential search, is the simplest searching algorithm. It examines each element in a collection sequentially until the target element is found or the entire collection has been searched.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given an array of n elements and a target value, find the index of the target value in the array. If the target is not present, return -1.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Array arr[] of size n, target value x<br>
            <strong>Output:</strong> Index of x in arr[], or -1 if not found<br>
            <strong>Constraint:</strong> Array can be sorted or unsorted
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            The linear search algorithm follows a straightforward approach:
        </p>
        
        <ol>
            <li>Start from the first element of the array</li>
            <li>Compare the current element with the target value</li>
            <li>If they match, return the current index</li>
            <li>If they don't match, move to the next element</li>
            <li>Repeat until the target is found or the array is exhausted</li>
            <li>If the array is exhausted without finding the target, return -1</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: LinearSearch(arr, n, x)
1. for i = 0 to n-1 do
2.     if arr[i] == x then
3.         return i
4.     end if
5. end for
6. return -1
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include &lt;iostream&gt;
#include &lt;vector&gt;
using namespace std;

/**
 * Linear Search Algorithm
 * Searches for a target element in an array sequentially
 * 
 * @param arr: input array
 * @param target: element to search for
 * @return: index of target element, -1 if not found
 */
int linearSearch(const vector&lt;int&gt;&amp; arr, int target) {
    int n = arr.size();
    
    // Traverse the array from left to right
    for (int i = 0; i &lt; n; i++) {
        // Check if current element matches target
        if (arr[i] == target) {
            return i;  // Return index if found
        }
    }
    
    return -1;  // Return -1 if target not found
}

/**
 * Linear Search with early termination for sorted arrays
 * Optimized version that stops early if target is smaller than current element
 */
int linearSearchOptimized(const vector&lt;int&gt;&amp; arr, int target) {
    int n = arr.size();
    
    for (int i = 0; i &lt; n; i++) {
        if (arr[i] == target) {
            return i;
        }
        // Early termination for sorted arrays
        if (arr[i] > target) {
            break;
        }
    }
    
    return -1;
}

/**
 * Linear Search from both ends (bidirectional)
 * Searches from both ends simultaneously
 */
int linearSearchBidirectional(const vector&lt;int&gt;&amp; arr, int target) {
    int left = 0;
    int right = arr.size() - 1;
    
    while (left &lt;= right) {
        // Check left end
        if (arr[left] == target) {
            return left;
        }
        
        // Check right end
        if (arr[right] == target) {
            return right;
        }
        
        left++;
        right--;
    }
    
    return -1;
}

// Example usage and testing
int main() {
    vector&lt;int&gt; arr = {64, 34, 25, 12, 22, 11, 90};
    int target = 22;
    
    cout &lt;&lt; "Array: ";
    for (int x : arr) {
        cout &lt;&lt; x &lt;&lt; " ";
    }
    cout &lt;&lt; endl;
    
    int result = linearSearch(arr, target);
    
    if (result != -1) {
        cout &lt;&lt; "Element " &lt;&lt; target &lt;&lt; " found at index " &lt;&lt; result &lt;&lt; endl;
    } else {
        cout &lt;&lt; "Element " &lt;&lt; target &lt;&lt; " not found" &lt;&lt; endl;
    }
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(1) - Target is the first element</li>
                <li><strong>Average Case:</strong> O(n) - Target is in the middle</li>
                <li><strong>Worst Case:</strong> O(n) - Target is the last element or not present</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(1) - Only uses a constant amount of extra space</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through the algorithm with the array [64, 34, 25, 12, 22, 11, 90] searching for target = 22:
        </p>
        
        <div class="code-block">
Array: [64, 34, 25, 12, 22, 11, 90]
Target: 22

Step 1: i=0, arr[0]=64, 64 ≠ 22, continue
Step 2: i=1, arr[1]=34, 34 ≠ 22, continue  
Step 3: i=2, arr[2]=25, 25 ≠ 22, continue
Step 4: i=3, arr[3]=12, 12 ≠ 22, continue
Step 5: i=4, arr[4]=22, 22 = 22, FOUND! Return index 4

Result: Element found at index 4
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Linear search is useful in the following scenarios:
        </p>
        
        <ul>
            <li><strong>Unsorted Data:</strong> When the data is not sorted and sorting would be too expensive</li>
            <li><strong>Small Datasets:</strong> For small arrays where the overhead of more complex algorithms isn't justified</li>
            <li><strong>Linked Lists:</strong> When random access is not available (e.g., linked lists)</li>
            <li><strong>Real-time Systems:</strong> When predictable performance is more important than optimal performance</li>
            <li><strong>Finding All Occurrences:</strong> When you need to find all instances of a value</li>
            <li><strong>Database Table Scans:</strong> When no suitable index exists</li>
        </ul>
        
        <h2 class="section-title">Variations</h2>
        
        <h3>1. Find All Occurrences</h3>
        <div class="code-block">
vector&lt;int&gt; findAllOccurrences(const vector&lt;int&gt;&amp; arr, int target) {
    vector&lt;int&gt; indices;
    
    for (int i = 0; i &lt; arr.size(); i++) {
        if (arr[i] == target) {
            indices.push_back(i);
        }
    }
    
    return indices;
}
        </div>
        
        <h3>2. Linear Search with Sentinel</h3>
        <div class="code-block">
int linearSearchSentinel(vector&lt;int&gt;&amp; arr, int target) {
    int n = arr.size();
    int last = arr[n-1];  // Store last element
    arr[n-1] = target;    // Set sentinel
    
    int i = 0;
    while (arr[i] != target) {
        i++;
    }
    
    arr[n-1] = last;  // Restore last element
    
    if (i &lt; n-1 || arr[n-1] == target) {
        return i;
    }
    return -1;
}
        </div>
        
        <h2 class="section-title">Advantages and Disadvantages</h2>
        
        <div class="definition-box">
            <strong>Advantages:</strong><br>
            • Simple to understand and implement<br>
            • Works on both sorted and unsorted arrays<br>
            • No preprocessing required<br>
            • Memory efficient (O(1) space)<br>
            • Stable performance characteristics<br><br>
            
            <strong>Disadvantages:</strong><br>
            • Inefficient for large datasets (O(n) time)<br>
            • Cannot take advantage of sorted data<br>
            • Not suitable for frequently searched data
        </div>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>When to Use:</strong> Mention that linear search is optimal for unsorted data or when you need to find all occurrences</li>
            <li><strong>Optimization:</strong> Discuss the bidirectional search variant for potentially better average case</li>
            <li><strong>Trade-offs:</strong> Compare with binary search - linear search works on unsorted data but is slower</li>
            <li><strong>Edge Cases:</strong> Handle empty arrays, single element arrays, and null inputs</li>
            <li><strong>Follow-up:</strong> Be prepared to implement variations like finding the last occurrence or counting occurrences</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Linear search is the foundation of all searching algorithms</li>
                <li>Time complexity is O(n), space complexity is O(1)</li>
                <li>Best choice for unsorted data and small datasets</li>
                <li>Simple implementation makes it reliable and predictable</li>
                <li>Can be optimized with early termination and bidirectional searching</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch2">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 2</div>
        <h1 class="chapter-title">Binary Search</h1>
        
        <p class="academic-text">
            Binary search is a highly efficient searching algorithm that works on sorted arrays by repeatedly dividing the search interval in half. It's one of the most fundamental algorithms in computer science and forms the basis for many other algorithms.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given a sorted array of n elements and a target value, find the index of the target value in the array. If the target is not present, return -1.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Sorted array arr[] of size n, target value x<br>
            <strong>Output:</strong> Index of x in arr[], or -1 if not found<br>
            <strong>Prerequisite:</strong> Array must be sorted in ascending order
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Binary search uses the divide-and-conquer strategy:
        </p>
        
        <ol>
            <li>Compare the target with the middle element of the array</li>
            <li>If the target equals the middle element, return its index</li>
            <li>If the target is less than the middle element, search the left half</li>
            <li>If the target is greater than the middle element, search the right half</li>
            <li>Repeat until the target is found or the search space is empty</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: BinarySearch(arr, left, right, x)
1. if right >= left then
2.     mid = left + (right - left) / 2
3.     if arr[mid] == x then
4.         return mid
5.     else if arr[mid] > x then
6.         return BinarySearch(arr, left, mid-1, x)
7.     else
8.         return BinarySearch(arr, mid+1, right, x)
9.     end if
10. end if
11. return -1
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include &lt;iostream&gt;
#include &lt;vector&gt;
using namespace std;

/**
 * Binary Search - Iterative Implementation
 * Searches for target in a sorted array using binary search
 * 
 * @param arr: sorted input array
 * @param target: element to search for
 * @return: index of target element, -1 if not found
 */
int binarySearch(const vector&lt;int&gt;&amp; arr, int target) {
    int left = 0;
    int right = arr.size() - 1;
    
    while (left &lt;= right) {
        // Calculate middle index (avoids integer overflow)
        int mid = left + (right - left) / 2;
        
        // Check if target is at mid
        if (arr[mid] == target) {
            return mid;
        }
        
        // If target is smaller, search left half
        if (arr[mid] > target) {
            right = mid - 1;
        }
        // If target is larger, search right half
        else {
            left = mid + 1;
        }
    }
    
    return -1;  // Target not found
}

/**
 * Binary Search - Recursive Implementation
 * Recursive version of binary search
 */
int binarySearchRecursive(const vector&lt;int&gt;&amp; arr, int left, int right, int target) {
    // Base case: search space is empty
    if (left > right) {
        return -1;
    }
    
    int mid = left + (right - left) / 2;
    
    // Target found
    if (arr[mid] == target) {
        return mid;
    }
    
    // Search left half
    if (arr[mid] > target) {
        return binarySearchRecursive(arr, left, mid - 1, target);
    }
    
    // Search right half
    return binarySearchRecursive(arr, mid + 1, right, target);
}

/**
 * Find First Occurrence (Lower Bound)
 * Finds the first occurrence of target in a sorted array with duplicates
 */
int findFirstOccurrence(const vector&lt;int&gt;&amp; arr, int target) {
    int left = 0;
    int right = arr.size() - 1;
    int result = -1;
    
    while (left &lt;= right) {
        int mid = left + (right - left) / 2;
        
        if (arr[mid] == target) {
            result = mid;
            right = mid - 1;  // Continue searching left for first occurrence
        }
        else if (arr[mid] > target) {
            right = mid - 1;
        }
        else {
            left = mid + 1;
        }
    }
    
    return result;
}

/**
 * Find Last Occurrence (Upper Bound)
 * Finds the last occurrence of target in a sorted array with duplicates
 */
int findLastOccurrence(const vector&lt;int&gt;&amp; arr, int target) {
    int left = 0;
    int right = arr.size() - 1;
    int result = -1;
    
    while (left &lt;= right) {
        int mid = left + (right - left) / 2;
        
        if (arr[mid] == target) {
            result = mid;
            left = mid + 1;  // Continue searching right for last occurrence
        }
        else if (arr[mid] > target) {
            right = mid - 1;
        }
        else {
            left = mid + 1;
        }
    }
    
    return result;
}

/**
 * Search Insert Position
 * Finds the position where target should be inserted to maintain sorted order
 */
int searchInsertPosition(const vector&lt;int&gt;&amp; arr, int target) {
    int left = 0;
    int right = arr.size() - 1;
    
    while (left &lt;= right) {
        int mid = left + (right - left) / 2;
        
        if (arr[mid] == target) {
            return mid;
        }
        else if (arr[mid] > target) {
            right = mid - 1;
        }
        else {
            left = mid + 1;
        }
    }
    
    return left;  // Insert position
}

// Example usage and testing
int main() {
    vector&lt;int&gt; arr = {2, 3, 4, 10, 40, 50, 80};
    int target = 10;
    
    cout &lt;&lt; "Sorted Array: ";
    for (int x : arr) {
        cout &lt;&lt; x &lt;&lt; " ";
    }
    cout &lt;&lt; endl;
    
    // Test iterative binary search
    int result = binarySearch(arr, target);
    if (result != -1) {
        cout &lt;&lt; "Element " &lt;&lt; target &lt;&lt; " found at index " &lt;&lt; result &lt;&lt; endl;
    } else {
        cout &lt;&lt; "Element " &lt;&lt; target &lt;&lt; " not found" &lt;&lt; endl;
    }
    
    // Test recursive binary search
    int recursiveResult = binarySearchRecursive(arr, 0, arr.size() - 1, target);
    cout &lt;&lt; "Recursive result: " &lt;&lt; recursiveResult &lt;&lt; endl;
    
    // Test with duplicates
    vector&lt;int&gt; arrWithDuplicates = {1, 2, 2, 2, 3, 4, 4, 5};
    int duplicateTarget = 2;
    
    cout &lt;&lt; "\\nArray with duplicates: ";
    for (int x : arrWithDuplicates) {
        cout &lt;&lt; x &lt;&lt; " ";
    }
    cout &lt;&lt; endl;
    
    cout &lt;&lt; "First occurrence of " &lt;&lt; duplicateTarget &lt;&lt; ": " 
         &lt;&lt; findFirstOccurrence(arrWithDuplicates, duplicateTarget) &lt;&lt; endl;
    cout &lt;&lt; "Last occurrence of " &lt;&lt; duplicateTarget &lt;&lt; ": " 
         &lt;&lt; findLastOccurrence(arrWithDuplicates, duplicateTarget) &lt;&lt; endl;
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(1) - Target is the middle element</li>
                <li><strong>Average Case:</strong> O(log n) - Target requires log n comparisons</li>
                <li><strong>Worst Case:</strong> O(log n) - Target is at the end of search path</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Iterative:</strong> O(1) - Constant extra space</li>
                <li><strong>Recursive:</strong> O(log n) - Due to recursion stack</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through binary search on array [2, 3, 4, 10, 40, 50, 80] searching for target = 10:
        </p>
        
        <div class="code-block">
Array: [2, 3, 4, 10, 40, 50, 80]  (indices 0-6)
Target: 10

Iteration 1:
  left=0, right=6, mid=3
  arr[3]=10, target=10
  10 == 10, FOUND! Return index 3

Result: Element found at index 3
        </div>
        
        <p class="academic-text">
            Let's trace another example searching for target = 50:
        </p>
        
        <div class="code-block">
Array: [2, 3, 4, 10, 40, 50, 80]
Target: 50

Iteration 1:
  left=0, right=6, mid=3
  arr[3]=10, target=50
  10 < 50, search right half
  left=4, right=6

Iteration 2:
  left=4, right=6, mid=5
  arr[5]=50, target=50
  50 == 50, FOUND! Return index 5

Result: Element found at index 5
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Binary search has numerous applications:
        </p>
        
        <ul>
            <li><strong>Database Indexing:</strong> B-trees use binary search principles</li>
            <li><strong>Library Functions:</strong> std::binary_search, std::lower_bound, std::upper_bound</li>
            <li><strong>Finding Square Root:</strong> Binary search on answer space</li>
            <li><strong>Peak Finding:</strong> Finding local maxima in arrays</li>
            <li><strong>Rotated Array Search:</strong> Modified binary search for rotated sorted arrays</li>
            <li><strong>Range Queries:</strong> Finding elements in a specific range</li>
            <li><strong>Optimization Problems:</strong> Binary search on answer (BSOA)</li>
        </ul>
        
        <h2 class="section-title">Advanced Variations</h2>
        
        <h3>1. Binary Search on Answer</h3>
        <div class="code-block">
/**
 * Example: Find minimum capacity to ship packages within D days
 * Binary search on the answer space
 */
bool canShip(const vector&lt;int&gt;&amp; weights, int capacity, int days) {
    int currentWeight = 0;
    int daysNeeded = 1;
    
    for (int weight : weights) {
        if (currentWeight + weight > capacity) {
            daysNeeded++;
            currentWeight = weight;
        } else {
            currentWeight += weight;
        }
    }
    
    return daysNeeded &lt;= days;
}

int shipWithinDays(vector&lt;int&gt;&amp; weights, int days) {
    int left = *max_element(weights.begin(), weights.end());
    int right = accumulate(weights.begin(), weights.end(), 0);
    
    while (left < right) {
        int mid = left + (right - left) / 2;
        
        if (canShip(weights, mid, days)) {
            right = mid;
        } else {
            left = mid + 1;
        }
    }
    
    return left;
}
        </div>
        
        <h3>2. Search in Rotated Sorted Array</h3>
        <div class="code-block">
int searchRotated(const vector&lt;int&gt;&amp; arr, int target) {
    int left = 0;
    int right = arr.size() - 1;
    
    while (left &lt;= right) {
        int mid = left + (right - left) / 2;
        
        if (arr[mid] == target) {
            return mid;
        }
        
        // Left half is sorted
        if (arr[left] &lt;= arr[mid]) {
            if (target >= arr[left] &amp;&amp; target < arr[mid]) {
                right = mid - 1;
            } else {
                left = mid + 1;
            }
        }
        // Right half is sorted
        else {
            if (target > arr[mid] &amp;&amp; target &lt;= arr[right]) {
                left = mid + 1;
            } else {
                right = mid - 1;
            }
        }
    }
    
    return -1;
}
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Integer Overflow:</strong> Use <code>mid = left + (right - left) / 2</code> instead of <code>(left + right) / 2</code></li>
            <li><strong>Infinite Loop:</strong> Ensure loop termination with proper boundary updates</li>
            <li><strong>Off-by-One Errors:</strong> Be careful with <code>&lt;</code> vs <code>&lt;=</code> in loop condition</li>
            <li><strong>Unsorted Input:</strong> Binary search only works on sorted data</li>
            <li><strong>Empty Array:</strong> Handle edge case of empty input</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Template:</strong> Master the standard binary search template and its variations</li>
            <li><strong>Boundary Conditions:</strong> Always clarify how to handle duplicates and edge cases</li>
            <li><strong>Variants:</strong> Be prepared to implement lower_bound, upper_bound, and search insert position</li>
            <li><strong>Applications:</strong> Discuss binary search on answer space for optimization problems</li>
            <li><strong>Comparison:</strong> Explain when to use binary search vs linear search</li>
        </ul>
        
        <div class="definition-box">
            <strong>Binary Search Template:</strong><br>
            The key insight is that binary search maintains the invariant that the answer (if it exists) is always within the current search range [left, right].
        </div>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Binary search reduces search time from O(n) to O(log n)</li>
                <li>Requires sorted input data as a prerequisite</li>
                <li>Master both iterative and recursive implementations</li>
                <li>Understanding variants like lower_bound and upper_bound is crucial</li>
                <li>Can be applied to optimization problems through "binary search on answer"</li>
                <li>Avoid integer overflow and off-by-one errors</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch3">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 3</div>
        <h1 class="chapter-title">Ternary Search</h1>
        
        <p class="academic-text">
            Ternary search is a divide-and-conquer algorithm that divides the search space into three parts instead of two (like binary search). It's particularly useful for finding the maximum or minimum of a unimodal function, but can also be used for searching in sorted arrays.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given a sorted array of n elements and a target value, find the index of the target value. Additionally, ternary search can find the maximum/minimum of a unimodal function over a continuous range.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Sorted array arr[] of size n, target value x<br>
            <strong>Output:</strong> Index of x in arr[], or -1 if not found<br>
            <strong>Alternative Use:</strong> Find extremum of unimodal function f(x) in range [left, right]
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Ternary search works by dividing the search space into three equal parts using two midpoints:
        </p>
        
        <ol>
            <li>Calculate two midpoints: mid1 and mid2 that divide the range into three parts</li>
            <li>Compare the target with elements at both midpoints</li>
            <li>Eliminate one-third of the search space based on comparisons</li>
            <li>Repeat until the target is found or search space is exhausted</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: TernarySearch(arr, left, right, x)
1. if right >= left then
2.     mid1 = left + (right - left) / 3
3.     mid2 = right - (right - left) / 3
4.     
5.     if arr[mid1] == x then
6.         return mid1
7.     if arr[mid2] == x then
8.         return mid2
9.     
10.    if x < arr[mid1] then
11.        return TernarySearch(arr, left, mid1-1, x)
12.    else if x > arr[mid2] then
13.        return TernarySearch(arr, mid2+1, right, x)
14.    else
15.        return TernarySearch(arr, mid1+1, mid2-1, x)
16. end if
17. return -1
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <cmath>
#include <algorithm>
using namespace std;

/**
 * Ternary Search - Iterative Implementation
 * Searches for target in a sorted array using ternary search
 * 
 * @param arr: sorted input array
 * @param target: element to search for
 * @return: index of target element, -1 if not found
 */
int ternarySearch(const vector<int>& arr, int target) {
    int left = 0;
    int right = arr.size() - 1;
    
    while (left <= right) {
        // Calculate two midpoints
        int mid1 = left + (right - left) / 3;
        int mid2 = right - (right - left) / 3;
        
        // Check if target is at either midpoint
        if (arr[mid1] == target) {
            return mid1;
        }
        if (arr[mid2] == target) {
            return mid2;
        }
        
        // Determine which third to search
        if (target < arr[mid1]) {
            // Target is in the left third
            right = mid1 - 1;
        }
        else if (target > arr[mid2]) {
            // Target is in the right third
            left = mid2 + 1;
        }
        else {
            // Target is in the middle third
            left = mid1 + 1;
            right = mid2 - 1;
        }
    }
    
    return -1;  // Target not found
}

/**
 * Ternary Search - Recursive Implementation
 * Recursive version of ternary search
 */
int ternarySearchRecursive(const vector<int>& arr, int left, int right, int target) {
    // Base case: search space is empty
    if (left > right) {
        return -1;
    }
    
    // Calculate two midpoints
    int mid1 = left + (right - left) / 3;
    int mid2 = right - (right - left) / 3;
    
    // Check if target is found
    if (arr[mid1] == target) {
        return mid1;
    }
    if (arr[mid2] == target) {
        return mid2;
    }
    
    // Recursive calls based on target location
    if (target < arr[mid1]) {
        return ternarySearchRecursive(arr, left, mid1 - 1, target);
    }
    else if (target > arr[mid2]) {
        return ternarySearchRecursive(arr, mid2 + 1, right, target);
    }
    else {
        return ternarySearchRecursive(arr, mid1 + 1, mid2 - 1, target);
    }
}

/**
 * Ternary Search for Maximum of Unimodal Function
 * Finds the maximum value of a unimodal function in given range
 * 
 * @param f: unimodal function
 * @param left: left boundary
 * @param right: right boundary
 * @param eps: precision epsilon
 * @return: x value where f(x) is maximum
 */
double ternarySearchMax(function<double(double)> f, double left, double right, double eps = 1e-9) {
    while (right - left > eps) {
        double mid1 = left + (right - left) / 3.0;
        double mid2 = right - (right - left) / 3.0;
        
        if (f(mid1) < f(mid2)) {
            // Maximum is in the right 2/3
            left = mid1;
        } else {
            // Maximum is in the left 2/3
            right = mid2;
        }
    }
    
    return (left + right) / 2.0;
}

/**
 * Ternary Search for Minimum of Unimodal Function
 * Finds the minimum value of a unimodal function in given range
 */
double ternarySearchMin(function<double(double)> f, double left, double right, double eps = 1e-9) {
    while (right - left > eps) {
        double mid1 = left + (right - left) / 3.0;
        double mid2 = right - (right - left) / 3.0;
        
        if (f(mid1) > f(mid2)) {
            // Minimum is in the right 2/3
            left = mid1;
        } else {
            // Minimum is in the left 2/3
            right = mid2;
        }
    }
    
    return (left + right) / 2.0;
}

/**
 * Example: Find peak element in array using ternary search concept
 * A peak element is greater than or equal to its neighbors
 */
int findPeakElement(const vector<int>& arr) {
    int left = 0;
    int right = arr.size() - 1;
    
    while (left < right) {
        int mid1 = left + (right - left) / 3;
        int mid2 = right - (right - left) / 3;
        
        if (arr[mid1] < arr[mid2]) {
            // Peak is more likely in the right part
            left = mid1 + 1;
        } else {
            // Peak is more likely in the left part
            right = mid2 - 1;
        }
    }
    
    return left;
}

// Example usage and testing
int main() {
    // Test ternary search on sorted array
    vector<int> arr = {1, 3, 5, 7, 9, 11, 13, 15, 17, 19};
    int target = 11;
    
    cout << "Sorted Array: ";
    for (int x : arr) {
        cout << x << " ";
    }
    cout << endl;
    
    int result = ternarySearch(arr, target);
    if (result != -1) {
        cout << "Element " << target << " found at index " << result << endl;
    } else {
        cout << "Element " << target << " not found" << endl;
    }
    
    // Test recursive version
    int recursiveResult = ternarySearchRecursive(arr, 0, arr.size() - 1, target);
    cout << "Recursive result: " << recursiveResult << endl;
    
    // Test ternary search for function maximum
    // Example: f(x) = -(x-5)^2 + 25 (parabola with maximum at x=5)
    auto quadraticFunction = [](double x) {
        return -(x - 5) * (x - 5) + 25;
    };
    
    double maxX = ternarySearchMax(quadraticFunction, 0.0, 10.0);
    cout << "\nMaximum of f(x) = -(x-5)^2 + 25 occurs at x = " << maxX << endl;
    cout << "Maximum value = " << quadraticFunction(maxX) << endl;
    
    // Test peak finding
    vector<int> peakArray = {1, 3, 20, 4, 1, 0};
    int peakIndex = findPeakElement(peakArray);
    cout << "\nPeak element in array: ";
    for (int x : peakArray) {
        cout << x << " ";
    }
    cout << "\nPeak found at index " << peakIndex << " with value " << peakArray[peakIndex] << endl;
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(1) - Target is at one of the midpoints</li>
                <li><strong>Average Case:</strong> O(log₃ n) - Eliminates 1/3 of search space each iteration</li>
                <li><strong>Worst Case:</strong> O(log₃ n) - Same as average case</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Iterative:</strong> O(1) - Constant extra space</li>
                <li><strong>Recursive:</strong> O(log₃ n) - Due to recursion stack</li>
            </ul>
            
            <h3>Comparison with Binary Search</h3>
            <ul>
                <li><strong>Ternary Search:</strong> ~1.26 * log₂ n comparisons</li>
                <li><strong>Binary Search:</strong> log₂ n comparisons</li>
                <li><strong>Verdict:</strong> Binary search is more efficient for searching</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through ternary search on array [1, 3, 5, 7, 9, 11, 13, 15, 17, 19] searching for target = 11:
        </p>
        
        <div class="code-block">
Array: [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]  (indices 0-9)
Target: 11

Iteration 1:
  left=0, right=9
  mid1 = 0 + (9-0)/3 = 3, arr[3] = 7
  mid2 = 9 - (9-0)/3 = 6, arr[6] = 13
  target=11: 7 < 11 < 13, search middle third
  left=4, right=5

Iteration 2:
  left=4, right=5
  mid1 = 4 + (5-4)/3 = 4, arr[4] = 9
  mid2 = 5 - (5-4)/3 = 5, arr[5] = 11
  arr[5] == target, FOUND! Return index 5

Result: Element found at index 5
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Ternary search has several important applications:
        </p>
        
        <ul>
            <li><strong>Unimodal Function Optimization:</strong> Finding maximum/minimum of functions with single peak/valley</li>
            <li><strong>Mathematical Optimization:</strong> Solving optimization problems in continuous domains</li>
            <li><strong>Computer Graphics:</strong> Finding optimal parameters in rendering algorithms</li>
            <li><strong>Machine Learning:</strong> Hyperparameter optimization for unimodal cost functions</li>
            <li><strong>Physics Simulations:</strong> Finding equilibrium points in physical systems</li>
            <li><strong>Game Theory:</strong> Finding optimal strategies in certain game scenarios</li>
        </ul>
        
        <h2 class="section-title">Advanced Variations</h2>
        
        <h3>1. Ternary Search with Custom Comparator</h3>
        <div class="code-block">
template<typename T, typename Compare>
int ternarySearchCustom(const vector<T>& arr, const T& target, Compare comp) {
    int left = 0;
    int right = arr.size() - 1;
    
    while (left <= right) {
        int mid1 = left + (right - left) / 3;
        int mid2 = right - (right - left) / 3;
        
        if (arr[mid1] == target) return mid1;
        if (arr[mid2] == target) return mid2;
        
        if (comp(target, arr[mid1])) {
            right = mid1 - 1;
        }
        else if (comp(arr[mid2], target)) {
            left = mid2 + 1;
        }
        else {
            left = mid1 + 1;
            right = mid2 - 1;
        }
    }
    
    return -1;
}
        </div>
        
        <h3>2. Discrete Ternary Search for Integer Functions</h3>
        <div class="code-block">
/**
 * Ternary search for discrete unimodal functions
 * Useful when function domain is integers
 */
int discreteTernarySearch(function<int(int)> f, int left, int right) {
    while (right - left > 2) {
        int mid1 = left + (right - left) / 3;
        int mid2 = right - (right - left) / 3;
        
        if (f(mid1) < f(mid2)) {
            left = mid1;
        } else {
            right = mid2;
        }
    }
    
    // Check remaining candidates
    int maxVal = f(left);
    int maxPos = left;
    
    for (int i = left + 1; i <= right; i++) {
        if (f(i) > maxVal) {
            maxVal = f(i);
            maxPos = i;
        }
    }
    
    return maxPos;
}
        </div>
        
        <h3>3. Parallel Ternary Search</h3>
        <div class="code-block">
/**
 * Parallel evaluation of function at both midpoints
 * Useful for expensive function evaluations
 */
double parallelTernarySearch(function<double(double)> f, double left, double right, double eps = 1e-9) {
    while (right - left > eps) {
        double mid1 = left + (right - left) / 3.0;
        double mid2 = right - (right - left) / 3.0;
        
        // These can be computed in parallel
        double f1 = f(mid1);
        double f2 = f(mid2);
        
        if (f1 < f2) {
            left = mid1;
        } else {
            right = mid2;
        }
    }
    
    return (left + right) / 2.0;
}
        </div>
        
        <h2 class="section-title">When to Use Ternary Search</h2>
        
        <div class="definition-box">
            <strong>Use Ternary Search When:</strong><br>
            • Finding extrema of unimodal functions<br>
            • Working with continuous optimization problems<br>
            • Function evaluation is expensive (fewer evaluations than golden section search)<br>
            • You need to find maximum/minimum in a specific range<br><br>
            
            <strong>Don't Use Ternary Search When:</strong><br>
            • Simple array searching (binary search is more efficient)<br>
            • Function has multiple peaks/valleys<br>
            • Working with discrete data where binary search applies
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Non-Unimodal Functions:</strong> Ternary search only works on unimodal functions</li>
            <li><strong>Precision Issues:</strong> Use appropriate epsilon for floating-point comparisons</li>
            <li><strong>Integer Overflow:</strong> Be careful with midpoint calculations for large ranges</li>
            <li><strong>Boundary Conditions:</strong> Handle edge cases where search space becomes very small</li>
            <li><strong>Function Evaluation Cost:</strong> Consider the cost of function evaluations vs. search efficiency</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Understand the Difference:</strong> Explain when to use ternary vs binary search</li>
            <li><strong>Unimodal Functions:</strong> Be able to identify and work with unimodal functions</li>
            <li><strong>Optimization Problems:</strong> Recognize when a problem can be solved using ternary search</li>
            <li><strong>Implementation Details:</strong> Handle both discrete and continuous cases</li>
            <li><strong>Complexity Analysis:</strong> Explain why binary search is better for simple searching</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Ternary search divides search space into three parts instead of two</li>
                <li>Time complexity is O(log₃ n), which is slightly worse than binary search for searching</li>
                <li>Excellent for finding extrema of unimodal functions</li>
                <li>Can work with both discrete and continuous domains</li>
                <li>Requires fewer function evaluations than some other optimization methods</li>
                <li>Not suitable for multimodal functions or general array searching</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch4">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 4</div>
        <h1 class="chapter-title">Jump Search</h1>
        
        <p class="academic-text">
            Jump search (also known as block search) is a searching algorithm that works on sorted arrays by jumping ahead by fixed steps and then performing a linear search within the identified block. It provides a balance between linear search and binary search.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given a sorted array of n elements and a target value, find the index of the target value in the array using jump search technique. If the target is not present, return -1.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Sorted array arr[] of size n, target value x<br>
            <strong>Output:</strong> Index of x in arr[], or -1 if not found<br>
            <strong>Optimal Jump Size:</strong> √n for minimum number of comparisons
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Jump search works in two phases:
        </p>
        
        <ol>
            <li><strong>Jumping Phase:</strong> Jump ahead by fixed steps until we find a block where the target might exist</li>
            <li><strong>Linear Search Phase:</strong> Perform linear search within the identified block</li>
        </ol>
        
        <p class="academic-text">
            The optimal jump size is √n, which minimizes the total number of comparisons.
        </p>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: JumpSearch(arr, n, x)
1. step = √n
2. prev = 0
3. 
4. // Jumping phase
5. while arr[min(step, n)-1] < x do
6.     prev = step
7.     step += √n
8.     if prev >= n then
9.         return -1
10.    end if
11. end while
12.
13. // Linear search phase
14. while arr[prev] < x do
15.     prev++
16.     if prev == min(step, n) then
17.         return -1
18.     end if
19. end while
20.
21. if arr[prev] == x then
22.     return prev
23. end if
24. return -1
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <cmath>
#include <algorithm>
using namespace std;

/**
 * Jump Search - Standard Implementation
 * Searches for target in a sorted array using jump search
 * 
 * @param arr: sorted input array
 * @param target: element to search for
 * @return: index of target element, -1 if not found
 */
int jumpSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    
    // Calculate optimal jump size
    int step = sqrt(n);
    int prev = 0;
    
    // Jumping phase: find the block where element may be present
    while (arr[min(step, n) - 1] < target) {
        prev = step;
        step += sqrt(n);
        
        // If we've gone beyond the array
        if (prev >= n) {
            return -1;
        }
    }
    
    // Linear search phase: search within the identified block
    while (arr[prev] < target) {
        prev++;
        
        // If we've reached the end of current block or array
        if (prev == min(step, n)) {
            return -1;
        }
    }
    
    // Check if element is found
    if (arr[prev] == target) {
        return prev;
    }
    
    return -1;  // Element not found
}

/**
 * Jump Search with Custom Step Size
 * Allows specification of custom jump size
 */
int jumpSearchCustomStep(const vector<int>& arr, int target, int stepSize) {
    int n = arr.size();
    if (n == 0) return -1;
    
    int step = stepSize;
    int prev = 0;
    
    // Jumping phase
    while (arr[min(step, n) - 1] < target) {
        prev = step;
        step += stepSize;
        
        if (prev >= n) {
            return -1;
        }
    }
    
    // Linear search phase
    while (arr[prev] < target) {
        prev++;
        
        if (prev == min(step, n)) {
            return -1;
        }
    }
    
    if (arr[prev] == target) {
        return prev;
    }
    
    return -1;
}

/**
 * Jump Search with Block Information
 * Returns both index and block information for analysis
 */
struct JumpSearchResult {
    int index;
    int blockStart;
    int blockEnd;
    int jumps;
    int linearSteps;
};

JumpSearchResult jumpSearchDetailed(const vector<int>& arr, int target) {
    JumpSearchResult result = {-1, -1, -1, 0, 0};
    int n = arr.size();
    
    if (n == 0) return result;
    
    int step = sqrt(n);
    int prev = 0;
    
    // Jumping phase
    while (arr[min(step, n) - 1] < target) {
        prev = step;
        step += sqrt(n);
        result.jumps++;
        
        if (prev >= n) {
            return result;
        }
    }
    
    result.blockStart = prev;
    result.blockEnd = min(step, n) - 1;
    
    // Linear search phase
    while (arr[prev] < target) {
        prev++;
        result.linearSteps++;
        
        if (prev == min(step, n)) {
            return result;
        }
    }
    
    if (arr[prev] == target) {
        result.index = prev;
    }
    
    return result;
}

/**
 * Adaptive Jump Search
 * Adjusts jump size based on array characteristics
 */
int adaptiveJumpSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    
    // Start with smaller jumps for better cache performance
    int step = max(1, (int)sqrt(n) / 2);
    int prev = 0;
    
    // Jumping phase with adaptive step size
    while (prev < n && arr[min(prev + step, n) - 1] < target) {
        prev += step;
        
        // Increase step size as we go further
        step = min(step * 2, (int)sqrt(n));
        
        if (prev >= n) {
            return -1;
        }
    }
    
    // Linear search phase
    int end = min(prev + step, n);
    for (int i = prev; i < end; i++) {
        if (arr[i] == target) {
            return i;
        }
        if (arr[i] > target) {
            break;
        }
    }
    
    return -1;
}

/**
 * Jump Search for Finding All Occurrences
 * Finds all indices where target appears
 */
vector<int> jumpSearchAll(const vector<int>& arr, int target) {
    vector<int> indices;
    int n = arr.size();
    
    if (n == 0) return indices;
    
    int step = sqrt(n);
    int prev = 0;
    
    // Find the first occurrence using standard jump search
    while (arr[min(step, n) - 1] < target) {
        prev = step;
        step += sqrt(n);
        
        if (prev >= n) {
            return indices;
        }
    }
    
    // Find all occurrences in the identified block
    int end = min(step, n);
    for (int i = prev; i < end; i++) {
        if (arr[i] == target) {
            indices.push_back(i);
        } else if (arr[i] > target) {
            break;  // No more occurrences possible
        }
    }
    
    return indices;
}

// Example usage and testing
int main() {
    vector<int> arr = {0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610};
    int target = 55;
    
    cout << "Sorted Array: ";
    for (int x : arr) {
        cout << x << " ";
    }
    cout << endl;
    cout << "Array size: " << arr.size() << ", Optimal jump size: " << (int)sqrt(arr.size()) << endl;
    
    // Test standard jump search
    int result = jumpSearch(arr, target);
    if (result != -1) {
        cout << "Element " << target << " found at index " << result << endl;
    } else {
        cout << "Element " << target << " not found" << endl;
    }
    
    // Test detailed jump search
    JumpSearchResult detailed = jumpSearchDetailed(arr, target);
    if (detailed.index != -1) {
        cout << "\nDetailed Analysis:" << endl;
        cout << "Found at index: " << detailed.index << endl;
        cout << "Block range: [" << detailed.blockStart << ", " << detailed.blockEnd << "]" << endl;
        cout << "Number of jumps: " << detailed.jumps << endl;
        cout << "Linear search steps: " << detailed.linearSteps << endl;
        cout << "Total comparisons: " << (detailed.jumps + detailed.linearSteps + 1) << endl;
    }
    
    // Test with different step sizes
    cout << "\nTesting different step sizes:" << endl;
    vector<int> stepSizes = {2, 4, 6, 8};
    for (int step : stepSizes) {
        int result = jumpSearchCustomStep(arr, target, step);
        cout << "Step size " << step << ": " << (result != -1 ? "Found" : "Not found") << endl;
    }
    
    // Test finding all occurrences
    vector<int> arrWithDuplicates = {1, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9};
    int duplicateTarget = 2;
    vector<int> allIndices = jumpSearchAll(arrWithDuplicates, duplicateTarget);
    
    cout << "\nArray with duplicates: ";
    for (int x : arrWithDuplicates) {
        cout << x << " ";
    }
    cout << endl;
    
    cout << "All occurrences of " << duplicateTarget << ": ";
    for (int idx : allIndices) {
        cout << idx << " ";
    }
    cout << endl;
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(1) - Target is at the first position checked</li>
                <li><strong>Average Case:</strong> O(√n) - Optimal jump size minimizes comparisons</li>
                <li><strong>Worst Case:</strong> O(√n) - Target is at the end of a block</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(1) - Only uses constant extra space</li>
            </ul>
            
            <h3>Comparison with Other Algorithms</h3>
            <ul>
                <li><strong>Linear Search:</strong> O(n) - Jump search is faster</li>
                <li><strong>Binary Search:</strong> O(log n) - Binary search is faster</li>
                <li><strong>Jump Search:</strong> O(√n) - Good balance for certain scenarios</li>
            </ul>
        </div>
        
        <h2 class="section-title">Mathematical Analysis</h2>
        
        <p class="academic-text">
            Let's derive why √n is the optimal jump size:
        </p>
        
        <div class="code-block">
Let jump size = m
- Number of jumps in worst case = n/m
- Linear search steps in worst case = m-1
- Total comparisons = n/m + m-1

To minimize total comparisons, take derivative and set to 0:
d/dm (n/m + m-1) = -n/m² + 1 = 0
=> n/m² = 1
=> m² = n
=> m = √n

Therefore, optimal jump size is √n, giving O(√n) complexity.
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through jump search on array [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610] searching for target = 55:
        </p>
        
        <div class="code-block">
Array: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]
Indices:[0, 1, 2, 3, 4, 5, 6, 7,  8,  9,  10, 11, 12,  13,  14,  15]
Array size: 16, Jump size: √16 = 4
Target: 55

Jumping Phase:
Step 1: prev=0, step=4, check arr[3]=2, 2 < 55, continue
Step 2: prev=4, step=8, check arr[7]=13, 13 < 55, continue  
Step 3: prev=8, step=12, check arr[11]=89, 89 > 55, stop jumping

Linear Search Phase:
Block to search: indices 8 to 11 [21, 34, 55, 89]
- Check arr[8]=21, 21 < 55, continue
- Check arr[9]=34, 34 < 55, continue
- Check arr[10]=55, 55 == 55, FOUND!

Result: Element found at index 10
Total comparisons: 3 (jumping) + 3 (linear) = 6 comparisons
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Jump search is particularly useful in the following scenarios:
        </p>
        
        <ul>
            <li><strong>Systems with Expensive Random Access:</strong> When jumping costs less than random access (like binary search)</li>
            <li><strong>Cache-Friendly Searching:</strong> Sequential access patterns are cache-friendly</li>
            <li><strong>Linked Lists with Skip Pointers:</strong> When you have skip pointers at regular intervals</li>
            <li><strong>Database Index Scanning:</strong> When you can't use binary search but need better than linear</li>
            <li><strong>Embedded Systems:</strong> When memory access patterns matter more than theoretical complexity</li>
            <li><strong>Large Datasets on Disk:</strong> When sequential reads are much faster than random seeks</li>
        </ul>
        
        <h2 class="section-title">Advanced Variations</h2>
        
        <h3>1. Exponential Jump Search</h3>
        <div class="code-block">
/**
 * Exponential Jump Search
 * Uses exponentially increasing jump sizes
 */
int exponentialJumpSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    
    if (arr[0] == target) return 0;
    
    // Find range for binary search by repeated doubling
    int i = 1;
    while (i < n && arr[i] <= target) {
        if (arr[i] == target) return i;
        i *= 2;
    }
    
    // Perform linear search in the found range
    int start = i / 2;
    int end = min(i, n);
    
    for (int j = start; j < end; j++) {
        if (arr[j] == target) return j;
        if (arr[j] > target) break;
    }
    
    return -1;
}
        </div>
        
        <h3>2. Fibonacci Jump Search</h3>
        <div class="code-block">
/**
 * Fibonacci Jump Search
 * Uses Fibonacci numbers as jump sizes
 */
int fibonacciJumpSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    
    // Generate Fibonacci numbers
    int fib2 = 0;  // (m-2)'th Fibonacci number
    int fib1 = 1;  // (m-1)'th Fibonacci number
    int fib = fib2 + fib1;  // m'th Fibonacci number
    
    // Find smallest Fibonacci number >= n
    while (fib < n) {
        fib2 = fib1;
        fib1 = fib;
        fib = fib2 + fib1;
    }
    
    int offset = -1;
    
    while (fib > 1) {
        int i = min(offset + fib2, n - 1);
        
        if (arr[i] < target) {
            fib = fib1;
            fib1 = fib2;
            fib2 = fib - fib1;
            offset = i;
        }
        else if (arr[i] > target) {
            fib = fib2;
            fib1 = fib1 - fib2;
            fib2 = fib - fib1;
        }
        else {
            return i;
        }
    }
    
    if (fib1 && offset + 1 < n && arr[offset + 1] == target) {
        return offset + 1;
    }
    
    return -1;
}
        </div>
        
        <h2 class="section-title">When to Use Jump Search</h2>
        
        <div class="definition-box">
            <strong>Use Jump Search When:</strong><br>
            • Array is sorted but binary search is not feasible<br>
            • Sequential access is much faster than random access<br>
            • Working with systems where cache performance matters<br>
            • You need a balance between simplicity and efficiency<br>
            • Memory access patterns are more important than theoretical complexity<br><br>
            
            <strong>Don't Use Jump Search When:</strong><br>
            • Random access is as fast as sequential access (use binary search)<br>
            • Array is unsorted (use linear search or sort first)<br>
            • You need the absolute best time complexity<br>
            • Working with very small arrays (overhead not worth it)
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Wrong Jump Size:</strong> Using non-optimal jump size reduces efficiency</li>
            <li><strong>Boundary Conditions:</strong> Handle cases where jump goes beyond array bounds</li>
            <li><strong>Empty Array:</strong> Check for empty input arrays</li>
            <li><strong>Single Element:</strong> Handle edge case of single-element arrays</li>
            <li><strong>Integer Overflow:</strong> Be careful with jump size calculations for very large arrays</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Optimal Jump Size:</strong> Explain why √n is optimal and derive it mathematically</li>
            <li><strong>Comparison:</strong> Compare jump search with linear and binary search</li>
            <li><strong>Use Cases:</strong> Discuss scenarios where jump search is preferred</li>
            <li><strong>Implementation:</strong> Be able to implement both phases clearly</li>
            <li><strong>Variations:</strong> Mention exponential and Fibonacci jump search variants</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Jump search provides O(√n) time complexity, between linear and binary search</li>
                <li>Optimal jump size is √n, derived from minimizing total comparisons</li>
                <li>Consists of two phases: jumping and linear search within block</li>
                <li>Cache-friendly due to sequential access patterns</li>
                <li>Useful when random access is expensive compared to sequential access</li>
                <li>Can be adapted with different jump size strategies</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch5">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 5</div>
        <h1 class="chapter-title">Interpolation Search</h1>
        
        <p class="academic-text">
            Interpolation search is an improved variant of binary search that works on uniformly distributed sorted arrays. Instead of always checking the middle element, it estimates the position of the target based on the values at the endpoints, similar to how we search in a phone book or dictionary.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given a sorted array of n uniformly distributed elements and a target value, find the index of the target value using interpolation to estimate the likely position of the target.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Sorted array arr[] of size n with uniformly distributed values, target value x<br>
            <strong>Output:</strong> Index of x in arr[], or -1 if not found<br>
            <strong>Prerequisite:</strong> Array must be sorted and preferably uniformly distributed
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Interpolation search uses the formula for linear interpolation to estimate where the target might be located:
        </p>
        
        <div class="code-block">
pos = low + [(target - arr[low]) / (arr[high] - arr[low])] * (high - low)
        </div>
        
        <p class="academic-text">
            This formula assumes that the data is uniformly distributed and estimates the position proportionally based on the target value.
        </p>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: InterpolationSearch(arr, low, high, x)
1. if low <= high AND x >= arr[low] AND x <= arr[high] then
2.     if low == high then
3.         if arr[low] == x then return low
4.         else return -1
5.     end if
6.     
7.     // Calculate position using interpolation formula
8.     pos = low + [(x - arr[low]) / (arr[high] - arr[low])] * (high - low)
9.     
10.    if arr[pos] == x then
11.        return pos
12.    else if arr[pos] < x then
13.        return InterpolationSearch(arr, pos+1, high, x)
14.    else
15.        return InterpolationSearch(arr, low, pos-1, x)
16.    end if
17. end if
18. return -1
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
#include <cmath>
using namespace std;

/**
 * Interpolation Search - Recursive Implementation
 * Searches for target using interpolation to estimate position
 * 
 * @param arr: sorted array with uniform distribution
 * @param low: starting index
 * @param high: ending index
 * @param target: element to search for
 * @return: index of target element, -1 if not found
 */
int interpolationSearch(const vector<int>& arr, int low, int high, int target) {
    // Base cases
    if (low <= high && target >= arr[low] && target <= arr[high]) {
        // If the range has only one element
        if (low == high) {
            return (arr[low] == target) ? low : -1;
        }
        
        // Avoid division by zero
        if (arr[high] == arr[low]) {
            return (arr[low] == target) ? low : -1;
        }
        
        // Calculate position using interpolation formula
        int pos = low + (double)(target - arr[low]) / (arr[high] - arr[low]) * (high - low);
        
        // Ensure pos is within bounds
        pos = max(low, min(pos, high));
        
        // Check if target is found
        if (arr[pos] == target) {
            return pos;
        }
        
        // If target is larger, search right subarray
        if (arr[pos] < target) {
            return interpolationSearch(arr, pos + 1, high, target);
        }
        
        // If target is smaller, search left subarray
        return interpolationSearch(arr, low, pos - 1, target);
    }
    
    return -1;  // Target not found
}

/**
 * Interpolation Search - Iterative Implementation
 * Iterative version for better space complexity
 */
int interpolationSearchIterative(const vector<int>& arr, int target) {
    int low = 0;
    int high = arr.size() - 1;
    
    while (low <= high && target >= arr[low] && target <= arr[high]) {
        // If the range has only one element
        if (low == high) {
            return (arr[low] == target) ? low : -1;
        }
        
        // Avoid division by zero
        if (arr[high] == arr[low]) {
            return (arr[low] == target) ? low : -1;
        }
        
        // Calculate position using interpolation formula
        int pos = low + (double)(target - arr[low]) / (arr[high] - arr[low]) * (high - low);
        
        // Ensure pos is within bounds
        pos = max(low, min(pos, high));
        
        // Check if target is found
        if (arr[pos] == target) {
            return pos;
        }
        
        // Update search range
        if (arr[pos] < target) {
            low = pos + 1;
        } else {
            high = pos - 1;
        }
    }
    
    return -1;  // Target not found
}

/**
 * Robust Interpolation Search
 * Handles edge cases and falls back to binary search when needed
 */
int robustInterpolationSearch(const vector<int>& arr, int target) {
    if (arr.empty()) return -1;
    
    int low = 0;
    int high = arr.size() - 1;
    int iterations = 0;
    const int MAX_ITERATIONS = log2(arr.size()) + 1;  // Fallback threshold
    
    while (low <= high && target >= arr[low] && target <= arr[high]) {
        iterations++;
        
        // Fallback to binary search if too many iterations
        if (iterations > MAX_ITERATIONS) {
            int mid = low + (high - low) / 2;
            if (arr[mid] == target) return mid;
            if (arr[mid] < target) low = mid + 1;
            else high = mid - 1;
            continue;
        }
        
        if (low == high) {
            return (arr[low] == target) ? low : -1;
        }
        
        if (arr[high] == arr[low]) {
            return (arr[low] == target) ? low : -1;
        }
        
        // Interpolation formula with bounds checking
        double ratio = (double)(target - arr[low]) / (arr[high] - arr[low]);
        int pos = low + (int)(ratio * (high - low));
        
        // Ensure pos is within bounds
        pos = max(low, min(pos, high));
        
        if (arr[pos] == target) {
            return pos;
        }
        
        if (arr[pos] < target) {
            low = pos + 1;
        } else {
            high = pos - 1;
        }
    }
    
    return -1;
}

/**
 * Interpolation Search with Statistics
 * Tracks performance metrics during search
 */
struct InterpolationStats {
    int index;
    int comparisons;
    int iterations;
    vector<int> positions;
};

InterpolationStats interpolationSearchWithStats(const vector<int>& arr, int target) {
    InterpolationStats stats = {-1, 0, 0, {}};
    
    if (arr.empty()) return stats;
    
    int low = 0;
    int high = arr.size() - 1;
    
    while (low <= high && target >= arr[low] && target <= arr[high]) {
        stats.iterations++;
        
        if (low == high) {
            stats.comparisons++;
            if (arr[low] == target) {
                stats.index = low;
            }
            break;
        }
        
        if (arr[high] == arr[low]) {
            stats.comparisons++;
            if (arr[low] == target) {
                stats.index = low;
            }
            break;
        }
        
        // Calculate interpolated position
        double ratio = (double)(target - arr[low]) / (arr[high] - arr[low]);
        int pos = low + (int)(ratio * (high - low));
        pos = max(low, min(pos, high));
        
        stats.positions.push_back(pos);
        stats.comparisons++;
        
        if (arr[pos] == target) {
            stats.index = pos;
            break;
        }
        
        stats.comparisons++;
        if (arr[pos] < target) {
            low = pos + 1;
        } else {
            high = pos - 1;
        }
    }
    
    return stats;
}

/**
 * Adaptive Interpolation Search
 * Adapts based on data distribution characteristics
 */
int adaptiveInterpolationSearch(const vector<int>& arr, int target) {
    if (arr.empty()) return -1;
    
    int low = 0;
    int high = arr.size() - 1;
    int consecutiveBadGuesses = 0;
    
    while (low <= high && target >= arr[low] && target <= arr[high]) {
        if (low == high) {
            return (arr[low] == target) ? low : -1;
        }
        
        if (arr[high] == arr[low]) {
            return (arr[low] == target) ? low : -1;
        }
        
        int pos;
        
        // Switch to binary search if interpolation is performing poorly
        if (consecutiveBadGuesses >= 2) {
            pos = low + (high - low) / 2;  // Binary search
        } else {
            // Interpolation search
            double ratio = (double)(target - arr[low]) / (arr[high] - arr[low]);
            pos = low + (int)(ratio * (high - low));
            pos = max(low, min(pos, high));
        }
        
        if (arr[pos] == target) {
            return pos;
        }
        
        // Check if the guess was reasonable
        int expectedRange = (high - low) / 4;  // Within 25% is considered good
        bool goodGuess = false;
        
        if (arr[pos] < target) {
            int optimalPos = low + (high - low) * 3 / 4;  // Should be in upper part
            goodGuess = abs(pos - optimalPos) <= expectedRange;
            low = pos + 1;
        } else {
            int optimalPos = low + (high - low) / 4;  // Should be in lower part
            goodGuess = abs(pos - optimalPos) <= expectedRange;
            high = pos - 1;
        }
        
        if (!goodGuess) {
            consecutiveBadGuesses++;
        } else {
            consecutiveBadGuesses = 0;
        }
    }
    
    return -1;
}

// Example usage and testing
int main() {
    // Test with uniformly distributed array
    vector<int> uniformArray = {10, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 33, 35, 42, 47};
    int target = 18;
    
    cout << "Uniformly distributed array: ";
    for (int x : uniformArray) {
        cout << x << " ";
    }
    cout << endl;
    
    // Test recursive implementation
    int result = interpolationSearch(uniformArray, 0, uniformArray.size() - 1, target);
    if (result != -1) {
        cout << "Recursive: Element " << target << " found at index " << result << endl;
    } else {
        cout << "Recursive: Element " << target << " not found" << endl;
    }
    
    // Test iterative implementation
    result = interpolationSearchIterative(uniformArray, target);
    if (result != -1) {
        cout << "Iterative: Element " << target << " found at index " << result << endl;
    } else {
        cout << "Iterative: Element " << target << " not found" << endl;
    }
    
    // Test with statistics
    InterpolationStats stats = interpolationSearchWithStats(uniformArray, target);
    cout << "\nDetailed Statistics:" << endl;
    cout << "Found at index: " << stats.index << endl;
    cout << "Iterations: " << stats.iterations << endl;
    cout << "Comparisons: " << stats.comparisons << endl;
    cout << "Positions checked: ";
    for (int pos : stats.positions) {
        cout << pos << " ";
    }
    cout << endl;
    
    // Test with non-uniform distribution
    vector<int> nonUniformArray = {1, 2, 3, 4, 100, 200, 300, 400, 500, 1000};
    cout << "\nNon-uniform array: ";
    for (int x : nonUniformArray) {
        cout << x << " ";
    }
    cout << endl;
    
    int nonUniformTarget = 300;
    result = robustInterpolationSearch(nonUniformArray, nonUniformTarget);
    cout << "Robust search result: " << (result != -1 ? "Found at " + to_string(result) : "Not found") << endl;
    
    result = adaptiveInterpolationSearch(nonUniformArray, nonUniformTarget);
    cout << "Adaptive search result: " << (result != -1 ? "Found at " + to_string(result) : "Not found") << endl;
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(1) - Target is found at the interpolated position</li>
                <li><strong>Average Case:</strong> O(log log n) - For uniformly distributed data</li>
                <li><strong>Worst Case:</strong> O(n) - When data is not uniformly distributed</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Recursive:</strong> O(log log n) - Due to recursion stack in average case</li>
                <li><strong>Iterative:</strong> O(1) - Constant extra space</li>
            </ul>
            
            <h3>Performance Comparison</h3>
            <ul>
                <li><strong>Uniform Distribution:</strong> Significantly faster than binary search</li>
                <li><strong>Non-uniform Distribution:</strong> Can be slower than binary search</li>
                <li><strong>Worst Case:</strong> Degrades to linear search performance</li>
            </ul>
        </div>
        
        <h2 class="section-title">Mathematical Foundation</h2>
        
        <p class="academic-text">
            The interpolation formula is based on linear interpolation:
        </p>
        
        <div class="code-block">
Given two points (low, arr[low]) and (high, arr[high]),
the linear interpolation formula for finding x-coordinate
given y-coordinate (target) is:

x = low + (target - arr[low]) * (high - low) / (arr[high] - arr[low])

This assumes a linear relationship between indices and values,
which holds true for uniformly distributed data.
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through interpolation search on array [10, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 33, 35, 42, 47] searching for target = 18:
        </p>
        
        <div class="code-block">
Array: [10, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 33, 35, 42, 47]
Indices:[0, 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]
Target: 18

Iteration 1:
  low=0, high=14, arr[low]=10, arr[high]=47
  pos = 0 + (18-10)/(47-10) * (14-0) = 0 + 8/37 * 14 ≈ 3.03 → 3
  arr[3]=16, 16 < 18, search right
  low=4, high=14

Iteration 2:
  low=4, high=14, arr[low]=18, arr[high]=47
  arr[4]=18, 18 == 18, FOUND!

Result: Element found at index 4 in just 2 iterations
(Binary search would need 4 iterations: 7→3→5→4)
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Interpolation search is particularly effective in these scenarios:
        </p>
        
        <ul>
            <li><strong>Phone Books/Dictionaries:</strong> Names and words are roughly uniformly distributed</li>
            <li><strong>Numerical Databases:</strong> When numeric data is uniformly distributed</li>
            <li><strong>Time Series Data:</strong> Timestamps are naturally uniform</li>
            <li><strong>Scientific Data:</strong> Measurement data with uniform sampling</li>
            <li><strong>Financial Data:</strong> Stock prices, trading volumes over time</li>
            <li><strong>Geographic Data:</strong> Coordinates, postal codes in sorted order</li>
        </ul>
        
        <h2 class="section-title">Advanced Variations</h2>
        
        <h3>1. Quadratic Interpolation Search</h3>
        <div class="code-block">
/**
 * Quadratic Interpolation Search
 * Uses three points for quadratic interpolation
 */
int quadraticInterpolationSearch(const vector<int>& arr, int target) {
    int low = 0;
    int high = arr.size() - 1;
    
    while (low <= high && target >= arr[low] && target <= arr[high]) {
        if (low == high) {
            return (arr[low] == target) ? low : -1;
        }
        
        // Use three points for quadratic interpolation
        int mid = (low + high) / 2;
        
        if (arr[mid] == target) return mid;
        
        // Calculate position using quadratic interpolation
        // This is a simplified version - full implementation requires
        // solving quadratic equation
        double ratio = (double)(target - arr[low]) / (arr[high] - arr[low]);
        int pos = low + (int)(ratio * (high - low));
        
        // Adjust based on middle point
        if (arr[mid] != arr[low] && arr[mid] != arr[high]) {
            double midRatio = (double)(mid - low) / (high - low);
            double expectedMidValue = arr[low] + midRatio * (arr[high] - arr[low]);
            double deviation = arr[mid] - expectedMidValue;
            
            // Adjust position based on deviation
            pos += (int)(deviation * 0.1);  // Simple adjustment factor
        }
        
        pos = max(low, min(pos, high));
        
        if (arr[pos] == target) return pos;
        
        if (arr[pos] < target) {
            low = pos + 1;
        } else {
            high = pos - 1;
        }
    }
    
    return -1;
}
        </div>
        
        <h3>2. Hybrid Interpolation-Binary Search</h3>
        <div class="code-block">
/**
 * Hybrid search that switches between interpolation and binary search
 * based on data distribution characteristics
 */
int hybridSearch(const vector<int>& arr, int target) {
    int low = 0;
    int high = arr.size() - 1;
    int interpolationAttempts = 0;
    const int MAX_INTERPOLATION_ATTEMPTS = 3;
    
    while (low <= high) {
        if (low == high) {
            return (arr[low] == target) ? low : -1;
        }
        
        int pos;
        bool useInterpolation = false;
        
        // Use interpolation if data seems uniform and within attempt limit
        if (interpolationAttempts < MAX_INTERPOLATION_ATTEMPTS && 
            target >= arr[low] && target <= arr[high] && 
            arr[high] != arr[low]) {
            
            // Check if data in current range seems uniform
            int range = high - low;
            if (range >= 4) {
                int quarter = low + range / 4;
                int threeQuarter = low + 3 * range / 4;
                
                double expectedQuarter = arr[low] + 0.25 * (arr[high] - arr[low]);
                double expectedThreeQuarter = arr[low] + 0.75 * (arr[high] - arr[low]);
                
                double quarterError = abs(arr[quarter] - expectedQuarter) / (arr[high] - arr[low]);
                double threeQuarterError = abs(arr[threeQuarter] - expectedThreeQuarter) / (arr[high] - arr[low]);
                
                if (quarterError < 0.2 && threeQuarterError < 0.2) {
                    useInterpolation = true;
                }
            } else {
                useInterpolation = true;  // Small range, try interpolation
            }
        }
        
        if (useInterpolation) {
            double ratio = (double)(target - arr[low]) / (arr[high] - arr[low]);
            pos = low + (int)(ratio * (high - low));
            pos = max(low, min(pos, high));
            interpolationAttempts++;
        } else {
            pos = low + (high - low) / 2;  // Binary search
        }
        
        if (arr[pos] == target) {
            return pos;
        }
        
        if (arr[pos] < target) {
            low = pos + 1;
        } else {
            high = pos - 1;
        }
    }
    
    return -1;
}
        </div>
        
        <h2 class="section-title">When to Use Interpolation Search</h2>
        
        <div class="definition-box">
            <strong>Use Interpolation Search When:</strong><br>
            • Data is sorted and uniformly distributed<br>
            • Array size is large (benefits are more pronounced)<br>
            • You're searching in numerical data with known distribution<br>
            • Performance improvement over binary search is critical<br><br>
            
            <strong>Don't Use Interpolation Search When:</strong><br>
            • Data distribution is unknown or highly non-uniform<br>
            • Array is small (overhead not worth it)<br>
            • Data has many duplicate values<br>
            • Worst-case performance guarantees are required
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Division by Zero:</strong> Handle case when arr[high] == arr[low]</li>
            <li><strong>Integer Overflow:</strong> Use appropriate data types for calculations</li>
            <li><strong>Bounds Checking:</strong> Ensure interpolated position is within array bounds</li>
            <li><strong>Non-uniform Data:</strong> Performance degrades significantly with skewed data</li>
            <li><strong>Floating Point Precision:</strong> Be careful with floating-point arithmetic in position calculation</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Key Insight:</strong> Explain the interpolation formula and its assumptions</li>
            <li><strong>Complexity:</strong> Discuss O(log log n) average case and O(n) worst case</li>
            <li><strong>Use Cases:</strong> Give examples of when interpolation search is beneficial</li>
            <li><strong>Comparison:</strong> Compare with binary search in different scenarios</li>
            <li><strong>Robustness:</strong> Mention hybrid approaches for handling non-uniform data</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Interpolation search achieves O(log log n) average time for uniform data</li>
                <li>Uses linear interpolation to estimate target position</li>
                <li>Performs excellently on uniformly distributed data</li>
                <li>Can degrade to O(n) on non-uniform data</li>
                <li>Requires careful implementation to handle edge cases</li>
                <li>Hybrid approaches can combine benefits of both interpolation and binary search</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch6">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 6</div>
        <h1 class="chapter-title">Exponential Search</h1>
        
        <p class="academic-text">
            Exponential search (also known as doubling search or galloping search) is a searching algorithm that finds the range where the target element might exist by exponentially increasing the search bound, then performs binary search within that range. It's particularly useful when the size of the array is unknown or infinite.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given a sorted array of unknown or infinite size and a target value, find the index of the target value. The algorithm first finds a suitable range and then performs binary search within that range.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Sorted array arr[] (possibly infinite), target value x<br>
            <strong>Output:</strong> Index of x in arr[], or -1 if not found<br>
            <strong>Use Case:</strong> Particularly effective when target is close to the beginning
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Exponential search works in two phases:
        </p>
        
        <ol>
            <li><strong>Range Finding:</strong> Start with index 1 and keep doubling until we find a value greater than target</li>
            <li><strong>Binary Search:</strong> Perform binary search in the identified range [i/2, i]</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: ExponentialSearch(arr, n, x)
1. if arr[0] == x then
2.     return 0
3. end if
4. 
5. // Find range for binary search by repeated doubling
6. i = 1
7. while i < n AND arr[i] <= x do
8.     i = i * 2
9. end while
10.
11. // Perform binary search in range [i/2, min(i, n-1)]
12. return BinarySearch(arr, i/2, min(i, n-1), x)
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
#include <climits>
using namespace std;

/**
 * Binary Search Helper Function
 * Used in the second phase of exponential search
 */
int binarySearch(const vector<int>& arr, int left, int right, int target) {
    while (left <= right) {
        int mid = left + (right - left) / 2;
        
        if (arr[mid] == target) {
            return mid;
        }
        
        if (arr[mid] < target) {
            left = mid + 1;
        } else {
            right = mid - 1;
        }
    }
    
    return -1;
}

/**
 * Exponential Search - Standard Implementation
 * Finds range exponentially, then uses binary search
 * 
 * @param arr: sorted input array
 * @param target: element to search for
 * @return: index of target element, -1 if not found
 */
int exponentialSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    
    // Check if target is at first position
    if (arr[0] == target) {
        return 0;
    }
    
    // Find range for binary search by repeated doubling
    int i = 1;
    while (i < n && arr[i] <= target) {
        i *= 2;
    }
    
    // Perform binary search in the identified range
    return binarySearch(arr, i / 2, min(i, n - 1), target);
}

/**
 * Exponential Search with Detailed Statistics
 * Tracks the search process for analysis
 */
struct ExponentialSearchStats {
    int index;
    int exponentialSteps;
    int binarySteps;
    int rangeStart;
    int rangeEnd;
    vector<int> exponentialPositions;
};

ExponentialSearchStats exponentialSearchWithStats(const vector<int>& arr, int target) {
    ExponentialSearchStats stats = {-1, 0, 0, -1, -1, {}};
    int n = arr.size();
    
    if (n == 0) return stats;
    
    if (arr[0] == target) {
        stats.index = 0;
        return stats;
    }
    
    // Exponential phase
    int i = 1;
    while (i < n && arr[i] <= target) {
        stats.exponentialPositions.push_back(i);
        stats.exponentialSteps++;
        i *= 2;
    }
    
    // Set range for binary search
    stats.rangeStart = i / 2;
    stats.rangeEnd = min(i, n - 1);
    
    // Binary search phase with step counting
    int left = stats.rangeStart;
    int right = stats.rangeEnd;
    
    while (left <= right) {
        stats.binarySteps++;
        int mid = left + (right - left) / 2;
        
        if (arr[mid] == target) {
            stats.index = mid;
            break;
        }
        
        if (arr[mid] < target) {
            left = mid + 1;
        } else {
            right = mid - 1;
        }
    }
    
    return stats;
}

/**
 * Exponential Search for Infinite Array
 * Simulates search in an infinite array using bounds checking
 */
int exponentialSearchInfinite(const vector<int>& arr, int target) {
    // Check first element
    if (arr[0] == target) {
        return 0;
    }
    
    // Find range for binary search by repeated doubling
    int i = 1;
    try {
        while (arr.at(i) <= target) {  // Using at() for bounds checking
            i *= 2;
        }
    } catch (const out_of_range&) {
        // We've gone beyond array bounds
        i = arr.size();
    }
    
    // Perform binary search in the identified range
    return binarySearch(arr, i / 2, min(i, (int)arr.size()) - 1, target);
}

/**
 * Optimized Exponential Search
 * Uses early termination and optimized doubling
 */
int optimizedExponentialSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    
    if (arr[0] == target) return 0;
    if (n == 1) return -1;
    
    // Quick check for small arrays
    if (n <= 4) {
        for (int i = 1; i < n; i++) {
            if (arr[i] == target) return i;
        }
        return -1;
    }
    
    // Exponential search with early termination
    int i = 1;
    while (i < n) {
        if (arr[i] == target) {
            return i;  // Found during exponential phase
        }
        if (arr[i] > target) {
            break;  // Target must be in previous range
        }
        i *= 2;
    }
    
    // Binary search in the identified range
    return binarySearch(arr, i / 2, min(i, n - 1), target);
}

/**
 * Exponential Search with Custom Growth Factor
 * Allows different growth rates instead of doubling
 */
int exponentialSearchCustomGrowth(const vector<int>& arr, int target, double growthFactor = 2.0) {
    int n = arr.size();
    if (n == 0) return -1;
    
    if (arr[0] == target) return 0;
    
    // Find range using custom growth factor
    int i = 1;
    while (i < n && arr[i] <= target) {
        i = (int)(i * growthFactor);
        if (i <= 0) i = n;  // Prevent infinite loop
    }
    
    int start = (int)(i / growthFactor);
    return binarySearch(arr, start, min(i, n - 1), target);
}

/**
 * Bidirectional Exponential Search
 * Searches from both ends when target position is unknown
 */
int bidirectionalExponentialSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    
    // Check endpoints
    if (arr[0] == target) return 0;
    if (arr[n-1] == target) return n-1;
    
    // Decide direction based on target value relative to middle
    int mid = n / 2;
    if (target <= arr[mid]) {
        // Search from beginning
        return exponentialSearch(arr, target);
    } else {
        // Search from end (reverse exponential search)
        int i = 1;
        while (i < n && arr[n-1-i] >= target) {
            i *= 2;
        }
        
        int start = max(0, n - i);
        int end = n - 1 - i/2;
        return binarySearch(arr, start, end, target);
    }
}

// Example usage and testing
int main() {
    vector<int> arr = {2, 3, 4, 10, 40, 50, 80, 100, 120, 140, 160, 180, 200, 220, 240};
    int target = 120;
    
    cout << "Sorted Array: ";
    for (int x : arr) {
        cout << x << " ";
    }
    cout << endl;
    cout << "Array size: " << arr.size() << endl;
    
    // Test standard exponential search
    int result = exponentialSearch(arr, target);
    if (result != -1) {
        cout << "Standard: Element " << target << " found at index " << result << endl;
    } else {
        cout << "Standard: Element " << target << " not found" << endl;
    }
    
    // Test with detailed statistics
    ExponentialSearchStats stats = exponentialSearchWithStats(arr, target);
    cout << "\nDetailed Analysis:" << endl;
    cout << "Found at index: " << stats.index << endl;
    cout << "Exponential steps: " << stats.exponentialSteps << endl;
    cout << "Binary search steps: " << stats.binarySteps << endl;
    cout << "Search range: [" << stats.rangeStart << ", " << stats.rangeEnd << "]" << endl;
    cout << "Exponential positions checked: ";
    for (int pos : stats.exponentialPositions) {
        cout << pos << " ";
    }
    cout << endl;
    cout << "Total operations: " << (stats.exponentialSteps + stats.binarySteps) << endl;
    
    // Compare with pure binary search
    int binaryResult = binarySearch(arr, 0, arr.size() - 1, target);
    cout << "Binary search result: " << binaryResult << endl;
    
    // Test different growth factors
    cout << "\nTesting different growth factors:" << endl;
    vector<double> growthFactors = {1.5, 2.0, 3.0, 4.0};
    for (double factor : growthFactors) {
        int result = exponentialSearchCustomGrowth(arr, target, factor);
        cout << "Growth factor " << factor << ": " << (result != -1 ? "Found" : "Not found") << endl;
    }
    
    // Test edge cases
    cout << "\nEdge Cases:" << endl;
    
    // Search for first element
    int firstResult = exponentialSearch(arr, arr[0]);
    cout << "First element (" << arr[0] << "): " << (firstResult != -1 ? "Found at " + to_string(firstResult) : "Not found") << endl;
    
    // Search for last element
    int lastResult = exponentialSearch(arr, arr.back());
    cout << "Last element (" << arr.back() << "): " << (lastResult != -1 ? "Found at " + to_string(lastResult) : "Not found") << endl;
    
    // Search for non-existent element
    int nonExistentResult = exponentialSearch(arr, 999);
    cout << "Non-existent element (999): " << (nonExistentResult != -1 ? "Found at " + to_string(nonExistentResult) : "Not found") << endl;
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(1) - Target is at the first position</li>
                <li><strong>Average Case:</strong> O(log i) where i is the position of target</li>
                <li><strong>Worst Case:</strong> O(log n) - Same as binary search</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(1) - Only uses constant extra space</li>
            </ul>
            
            <h3>Key Insight</h3>
            <ul>
                <li><strong>Performance:</strong> Better than binary search when target is near the beginning</li>
                <li><strong>Exponential Phase:</strong> Takes O(log i) time to find the range</li>
                <li><strong>Binary Phase:</strong> Takes O(log i) time to search within range</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through exponential search on array [2, 3, 4, 10, 40, 50, 80, 100, 120, 140, 160, 180, 200, 220, 240] searching for target = 120:
        </p>
        
        <div class="code-block">
Array: [2, 3, 4, 10, 40, 50, 80, 100, 120, 140, 160, 180, 200, 220, 240]
Indices:[0, 1, 2, 3,  4,  5,  6,  7,   8,   9,  10,  11,  12,  13,  14]
Target: 120

Exponential Phase:
Step 1: i=1, arr[1]=3, 3 <= 120, continue
Step 2: i=2, arr[2]=4, 4 <= 120, continue
Step 3: i=4, arr[4]=40, 40 <= 120, continue
Step 4: i=8, arr[8]=120, 120 <= 120, continue
Step 5: i=16, i >= n(15), stop

Range identified: [8, 14] (i/2 to min(i, n-1))

Binary Search Phase in range [8, 14]:
Step 1: left=8, right=14, mid=11, arr[11]=180, 180 > 120, search left
Step 2: left=8, right=10, mid=9, arr[9]=140, 140 > 120, search left
Step 3: left=8, right=8, mid=8, arr[8]=120, 120 == 120, FOUND!

Result: Element found at index 8
Total operations: 4 (exponential) + 3 (binary) = 7 operations
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Exponential search is particularly useful in these scenarios:
        </p>
        
        <ul>
            <li><strong>Infinite or Unknown-Size Arrays:</strong> When array size is not known beforehand</li>
            <li><strong>Streaming Data:</strong> Searching in continuously growing datasets</li>
            <li><strong>Memory-Mapped Files:</strong> When accessing later parts of file is expensive</li>
            <li><strong>Network-Based Arrays:</strong> When accessing remote elements has high latency</li>
            <li><strong>Cache-Optimized Search:</strong> When sequential access is faster than random access</li>
            <li><strong>Real-time Systems:</strong> When target is likely to be near the beginning</li>
        </ul>
        
        <h2 class="section-title">Advanced Variations</h2>
        
        <h3>1. Fibonacci Exponential Search</h3>
        <div class="code-block">
/**
 * Uses Fibonacci numbers instead of powers of 2
 * Can be more cache-friendly for certain data patterns
 */
int fibonacciExponentialSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    if (arr[0] == target) return 0;
    
    // Generate Fibonacci numbers
    int fib1 = 1, fib2 = 1;
    int i = fib2;
    
    while (i < n && arr[i] <= target) {
        int nextFib = fib1 + fib2;
        fib1 = fib2;
        fib2 = nextFib;
        i = fib2;
    }
    
    return binarySearch(arr, fib1, min(i, n - 1), target);
}
        </div>
        
        <h3>2. Adaptive Exponential Search</h3>
        <div class="code-block">
/**
 * Adapts growth rate based on data distribution
 */
int adaptiveExponentialSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    if (arr[0] == target) return 0;
    
    double growthRate = 2.0;
    int i = 1;
    int prevI = 0;
    
    while (i < n && arr[i] <= target) {
        // Analyze local data distribution
        if (i > 1) {
            double expectedValue = arr[prevI] + (double)(arr[i] - arr[prevI]) * 0.5;
            int midIndex = (prevI + i) / 2;
            
            if (midIndex < n) {
                double actualValue = arr[midIndex];
                double ratio = actualValue / expectedValue;
                
                // Adjust growth rate based on distribution
                if (ratio > 1.5) {
                    growthRate = min(growthRate * 1.2, 4.0);  // Increase growth rate
                } else if (ratio < 0.7) {
                    growthRate = max(growthRate * 0.8, 1.5);  // Decrease growth rate
                }
            }
        }
        
        prevI = i;
        i = (int)(i * growthRate);
    }
    
    return binarySearch(arr, prevI, min(i, n - 1), target);
}
        </div>
        
        <h3>3. Parallel Exponential Search</h3>
        <div class="code-block">
/**
 * Parallel version that can check multiple positions simultaneously
 * Useful for systems with multiple cores or when array access is expensive
 */
int parallelExponentialSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    if (arr[0] == target) return 0;
    
    // Find range using parallel checking
    vector<int> positions = {1, 2, 4, 8, 16, 32, 64, 128};
    int rangeStart = 0, rangeEnd = n - 1;
    
    for (int pos : positions) {
        if (pos >= n) break;
        
        if (arr[pos] == target) {
            return pos;
        } else if (arr[pos] > target) {
            rangeEnd = pos;
            break;
        } else {
            rangeStart = pos;
        }
    }
    
    return binarySearch(arr, rangeStart, rangeEnd, target);
}
        </div>
        
        <h2 class="section-title">When to Use Exponential Search</h2>
        
        <div class="definition-box">
            <strong>Use Exponential Search When:</strong><br>
            • Array size is unknown or infinite<br>
            • Target is likely to be near the beginning<br>
            • Sequential access is faster than random access<br>
            • Working with streaming or growing data<br>
            • Memory access patterns matter more than theoretical complexity<br><br>
            
            <strong>Don't Use Exponential Search When:</strong><br>
            • Array size is known and small<br>
            • Target is likely to be uniformly distributed<br>
            • Random access is as fast as sequential access<br>
            • You need guaranteed O(log n) performance
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Integer Overflow:</strong> Doubling can cause overflow for large arrays</li>
            <li><strong>Boundary Conditions:</strong> Handle cases where doubling exceeds array size</li>
            <li><strong>Empty Array:</strong> Check for empty input arrays</li>
            <li><strong>Single Element:</strong> Handle edge case of single-element arrays</li>
            <li><strong>Performance Assumptions:</strong> Verify that sequential access is actually faster</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Two-Phase Approach:</strong> Clearly explain the exponential and binary search phases</li>
            <li><strong>Use Cases:</strong> Discuss scenarios where exponential search is optimal</li>
            <li><strong>Complexity:</strong> Explain why it's O(log i) where i is the target position</li>
            <li><strong>Comparison:</strong> Compare with binary search and explain trade-offs</li>
            <li><strong>Infinite Arrays:</strong> Discuss how it handles unknown-size arrays</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Exponential search combines exponential range finding with binary search</li>
                <li>Time complexity is O(log i) where i is the position of target element</li>
                <li>Particularly effective when target is near the beginning of array</li>
                <li>Excellent for infinite or unknown-size arrays</li>
                <li>Cache-friendly due to sequential access in exponential phase</li>
                <li>Can be adapted with different growth rates and strategies</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch7">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 7</div>
        <h1 class="chapter-title">Fibonacci Search</h1>
        
        <p class="academic-text">
            Fibonacci search is a comparison-based technique that uses Fibonacci numbers to divide the array into unequal parts. Unlike binary search which divides the array into two equal halves, Fibonacci search divides the array according to Fibonacci numbers, which can be more efficient in certain scenarios, especially when division is expensive.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given a sorted array of n elements and a target value, find the index of the target value using Fibonacci numbers to determine the division points. This algorithm is particularly useful when the cost of division is high or when working with systems that favor addition over division.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Sorted array arr[] of size n, target value x<br>
            <strong>Output:</strong> Index of x in arr[], or -1 if not found<br>
            <strong>Advantage:</strong> Uses only addition and subtraction, no division or multiplication
        </div>
        
        <h2 class="section-title">Fibonacci Numbers Background</h2>
        
        <p class="academic-text">
            The Fibonacci sequence is: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, ...
        </p>
        
        <p class="academic-text">
            Each number is the sum of the two preceding ones: F(n) = F(n-1) + F(n-2)
        </p>
        
        <p class="academic-text">
            The key property used in Fibonacci search is that any Fibonacci number can be expressed as the sum of two smaller Fibonacci numbers, allowing us to divide the array into two parts whose sizes are Fibonacci numbers.
        </p>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: FibonacciSearch(arr, n, x)
1. Find smallest Fibonacci number >= n
2. Initialize Fibonacci numbers: fibM, fibM1, fibM2
3. offset = -1
4. 
5. while fibM > 1 do
6.     i = min(offset + fibM2, n-1)
7.     
8.     if arr[i] < x then
9.         fibM = fibM1
10.        fibM1 = fibM2
11.        fibM2 = fibM - fibM1
12.        offset = i
13.    else if arr[i] > x then
14.        fibM = fibM2
15.        fibM1 = fibM1 - fibM2
16.        fibM2 = fibM - fibM1
17.    else
18.        return i
19.    end if
20. end while
21.
22. if fibM1 AND arr[offset+1] == x then
23.     return offset+1
24. end if
25. return -1
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
using namespace std;

/**
 * Fibonacci Search - Standard Implementation
 * Uses Fibonacci numbers to divide the search space
 * 
 * @param arr: sorted input array
 * @param target: element to search for
 * @return: index of target element, -1 if not found
 */
int fibonacciSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    
    // Initialize Fibonacci numbers
    int fibM2 = 0;  // (m-2)'th Fibonacci number
    int fibM1 = 1;  // (m-1)'th Fibonacci number
    int fibM = fibM2 + fibM1;  // m'th Fibonacci number
    
    // Find the smallest Fibonacci number greater than or equal to n
    while (fibM < n) {
        fibM2 = fibM1;
        fibM1 = fibM;
        fibM = fibM2 + fibM1;
    }
    
    // Marks the eliminated range from front
    int offset = -1;
    
    // While there are elements to be inspected
    while (fibM > 1) {
        // Check if fibM2 is a valid location
        int i = min(offset + fibM2, n - 1);
        
        // If target is greater than the value at index fibM2, cut the subarray from offset to i
        if (arr[i] < target) {
            fibM = fibM1;
            fibM1 = fibM2;
            fibM2 = fibM - fibM1;
            offset = i;
        }
        // If target is less than the value at index fibM2, cut the subarray after i+1
        else if (arr[i] > target) {
            fibM = fibM2;
            fibM1 = fibM1 - fibM2;
            fibM2 = fibM - fibM1;
        }
        // Element found, return index
        else {
            return i;
        }
    }
    
    // Comparing the last element with target
    if (fibM1 && offset + 1 < n && arr[offset + 1] == target) {
        return offset + 1;
    }
    
    return -1;  // Element not found
}

/**
 * Fibonacci Search with Detailed Statistics
 * Tracks the search process for analysis
 */
struct FibonacciSearchStats {
    int index;
    int iterations;
    int comparisons;
    vector<int> fibonacciNumbers;
    vector<int> positionsChecked;
    vector<int> offsetHistory;
};

FibonacciSearchStats fibonacciSearchWithStats(const vector<int>& arr, int target) {
    FibonacciSearchStats stats = {-1, 0, 0, {}, {}, {}};
    int n = arr.size();
    
    if (n == 0) return stats;
    
    // Generate Fibonacci numbers
    int fibM2 = 0, fibM1 = 1, fibM = 1;
    stats.fibonacciNumbers = {fibM2, fibM1};
    
    while (fibM < n) {
        fibM2 = fibM1;
        fibM1 = fibM;
        fibM = fibM2 + fibM1;
        stats.fibonacciNumbers.push_back(fibM);
    }
    
    int offset = -1;
    
    while (fibM > 1) {
        stats.iterations++;
        stats.offsetHistory.push_back(offset);
        
        int i = min(offset + fibM2, n - 1);
        stats.positionsChecked.push_back(i);
        stats.comparisons++;
        
        if (arr[i] < target) {
            fibM = fibM1;
            fibM1 = fibM2;
            fibM2 = fibM - fibM1;
            offset = i;
        }
        else if (arr[i] > target) {
            fibM = fibM2;
            fibM1 = fibM1 - fibM2;
            fibM2 = fibM - fibM1;
        }
        else {
            stats.index = i;
            return stats;
        }
    }
    
    // Check last element
    if (fibM1 && offset + 1 < n) {
        stats.comparisons++;
        if (arr[offset + 1] == target) {
            stats.index = offset + 1;
        }
    }
    
    return stats;
}

/**
 * Optimized Fibonacci Search
 * Pre-computes Fibonacci numbers and uses optimizations
 */
class OptimizedFibonacciSearch {
private:
    vector<int> fibNumbers;
    
    void generateFibonacci(int maxN) {
        fibNumbers.clear();
        fibNumbers.push_back(0);
        fibNumbers.push_back(1);
        
        while (fibNumbers.back() < maxN) {
            int next = fibNumbers[fibNumbers.size()-1] + fibNumbers[fibNumbers.size()-2];
            fibNumbers.push_back(next);
        }
    }
    
public:
    int search(const vector<int>& arr, int target) {
        int n = arr.size();
        if (n == 0) return -1;
        
        // Generate Fibonacci numbers if not already done or if array is larger
        if (fibNumbers.empty() || fibNumbers.back() < n) {
            generateFibonacci(n * 2);  // Generate extra for safety
        }
        
        // Find the smallest Fibonacci number >= n
        int fibIndex = 0;
        while (fibIndex < fibNumbers.size() && fibNumbers[fibIndex] < n) {
            fibIndex++;
        }
        
        if (fibIndex < 2) return (n > 0 && arr[0] == target) ? 0 : -1;
        
        int fibM = fibNumbers[fibIndex];
        int fibM1 = fibNumbers[fibIndex - 1];
        int fibM2 = fibNumbers[fibIndex - 2];
        int offset = -1;
        
        while (fibM > 1) {
            int i = min(offset + fibM2, n - 1);
            
            if (arr[i] < target) {
                fibM = fibM1;
                fibM1 = fibM2;
                fibM2 = fibM - fibM1;
                offset = i;
            }
            else if (arr[i] > target) {
                fibM = fibM2;
                fibM1 = fibM1 - fibM2;
                fibM2 = fibM - fibM1;
            }
            else {
                return i;
            }
        }
        
        if (fibM1 && offset + 1 < n && arr[offset + 1] == target) {
            return offset + 1;
        }
        
        return -1;
    }
};

/**
 * Fibonacci Search for Finding All Occurrences
 * Finds all indices where target appears
 */
vector<int> fibonacciSearchAll(const vector<int>& arr, int target) {
    vector<int> indices;
    int n = arr.size();
    
    if (n == 0) return indices;
    
    // First find any occurrence using standard Fibonacci search
    int firstIndex = fibonacciSearch(arr, target);
    if (firstIndex == -1) return indices;
    
    // Find all occurrences around the first found index
    int left = firstIndex, right = firstIndex;
    
    // Expand left
    while (left > 0 && arr[left - 1] == target) {
        left--;
    }
    
    // Expand right
    while (right < n - 1 && arr[right + 1] == target) {
        right++;
    }
    
    // Collect all indices
    for (int i = left; i <= right; i++) {
        indices.push_back(i);
    }
    
    return indices;
}

/**
 * Fibonacci Search with Early Termination
 * Optimized version with various early termination conditions
 */
int fibonacciSearchOptimized(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    
    // Handle small arrays directly
    if (n <= 3) {
        for (int i = 0; i < n; i++) {
            if (arr[i] == target) return i;
        }
        return -1;
    }
    
    // Quick boundary checks
    if (target < arr[0] || target > arr[n-1]) {
        return -1;
    }
    
    if (arr[0] == target) return 0;
    if (arr[n-1] == target) return n-1;
    
    // Standard Fibonacci search for the rest
    return fibonacciSearch(arr, target);
}

// Example usage and testing
int main() {
    vector<int> arr = {2, 3, 4, 10, 40, 50, 80, 100, 120, 140, 160, 180, 200};
    int target = 120;
    
    cout << "Sorted Array: ";
    for (int x : arr) {
        cout << x << " ";
    }
    cout << endl;
    cout << "Array size: " << arr.size() << endl;
    
    // Test standard Fibonacci search
    int result = fibonacciSearch(arr, target);
    if (result != -1) {
        cout << "Standard: Element " << target << " found at index " << result << endl;
    } else {
        cout << "Standard: Element " << target << " not found" << endl;
    }
    
    // Test with detailed statistics
    FibonacciSearchStats stats = fibonacciSearchWithStats(arr, target);
    cout << "\nDetailed Analysis:" << endl;
    cout << "Found at index: " << stats.index << endl;
    cout << "Iterations: " << stats.iterations << endl;
    cout << "Comparisons: " << stats.comparisons << endl;
    cout << "Fibonacci numbers used: ";
    for (int fib : stats.fibonacciNumbers) {
        cout << fib << " ";
    }
    cout << endl;
    cout << "Positions checked: ";
    for (int pos : stats.positionsChecked) {
        cout << pos << " ";
    }
    cout << endl;
    
    // Test optimized version
    OptimizedFibonacciSearch optimized;
    int optimizedResult = optimized.search(arr, target);
    cout << "Optimized: Element " << target << " found at index " << optimizedResult << endl;
    
    // Test finding all occurrences
    vector<int> arrWithDuplicates = {1, 2, 2, 2, 3, 4, 4, 5, 6, 7, 8, 9};
    int duplicateTarget = 2;
    vector<int> allIndices = fibonacciSearchAll(arrWithDuplicates, duplicateTarget);
    
    cout << "\nArray with duplicates: ";
    for (int x : arrWithDuplicates) {
        cout << x << " ";
    }
    cout << endl;
    
    cout << "All occurrences of " << duplicateTarget << ": ";
    for (int idx : allIndices) {
        cout << idx << " ";
    }
    cout << endl;
    
    // Performance comparison with different array sizes
    cout << "\nPerformance Analysis:" << endl;
    vector<int> sizes = {10, 50, 100, 500};
    
    for (int size : sizes) {
        vector<int> testArr(size);
        for (int i = 0; i < size; i++) {
            testArr[i] = i * 2;  // Even numbers
        }
        
        int testTarget = (size / 2) * 2;  // Middle element
        FibonacciSearchStats testStats = fibonacciSearchWithStats(testArr, testTarget);
        
        cout << "Array size " << size << ": " << testStats.comparisons << " comparisons, " 
             << testStats.iterations << " iterations" << endl;
    }
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(1) - Target is found at the first Fibonacci position checked</li>
                <li><strong>Average Case:</strong> O(log n) - Similar to binary search</li>
                <li><strong>Worst Case:</strong> O(log n) - Slightly better constant factor than binary search</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(1) - Only uses constant extra space</li>
            </ul>
            
            <h3>Comparison with Binary Search</h3>
            <ul>
                <li><strong>Operations:</strong> Uses only addition/subtraction (no division)</li>
                <li><strong>Comparisons:</strong> Slightly fewer comparisons on average</li>
                <li><strong>Cache Performance:</strong> Better locality due to Fibonacci division</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through Fibonacci search on array [2, 3, 4, 10, 40, 50, 80, 100, 120, 140, 160, 180, 200] searching for target = 120:
        </p>
        
        <div class="code-block">
Array: [2, 3, 4, 10, 40, 50, 80, 100, 120, 140, 160, 180, 200]
Indices:[0, 1, 2, 3,  4,  5,  6,  7,   8,   9,  10,  11,  12]
Array size: 13
Target: 120

Fibonacci numbers: 0, 1, 1, 2, 3, 5, 8, 13, 21...
Smallest Fibonacci >= 13 is 21
fibM = 21, fibM1 = 13, fibM2 = 8

Iteration 1:
  offset = -1
  i = min(-1 + 8, 12) = 7
  arr[7] = 100, 100 < 120
  Move to right part: fibM = 13, fibM1 = 8, fibM2 = 5, offset = 7

Iteration 2:
  offset = 7
  i = min(7 + 5, 12) = 12
  arr[12] = 200, 200 > 120
  Move to left part: fibM = 5, fibM1 = 3, fibM2 = 2

Iteration 3:
  offset = 7
  i = min(7 + 2, 12) = 9
  arr[9] = 140, 140 > 120
  Move to left part: fibM = 2, fibM1 = 1, fibM2 = 1

Iteration 4:
  offset = 7
  i = min(7 + 1, 12) = 8
  arr[8] = 120, 120 == 120, FOUND!

Result: Element found at index 8
Total comparisons: 4
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Fibonacci search is particularly useful in these scenarios:
        </p>
        
        <ul>
            <li><strong>Systems Without Division:</strong> When division operation is expensive or unavailable</li>
            <li><strong>Embedded Systems:</strong> Microcontrollers where arithmetic operations are limited</li>
            <li><strong>Cache-Sensitive Applications:</strong> Better memory access patterns than binary search</li>
            <li><strong>Mathematical Computing:</strong> When working with golden ratio-based algorithms</li>
            <li><strong>Parallel Processing:</strong> Fibonacci division can be more parallelizable</li>
            <li><strong>Historical Systems:</strong> Older computers where multiplication/division was slow</li>
        </ul>
        
        <h2 class="section-title">Mathematical Properties</h2>
        
        <div class="definition-box">
            <strong>Golden Ratio Connection:</strong><br>
            Fibonacci numbers are closely related to the golden ratio φ = (1 + √5)/2 ≈ 1.618<br>
            F(n) ≈ φⁿ/√5 for large n<br><br>
            
            <strong>Division Property:</strong><br>
            Any Fibonacci number F(n) = F(n-1) + F(n-2)<br>
            This allows natural division of arrays into two parts whose sizes are also Fibonacci numbers
        </div>
        
        <h2 class="section-title">Advanced Variations</h2>
        
        <h3>1. Generalized Fibonacci Search</h3>
        <div class="code-block">
/**
 * Generalized Fibonacci Search using custom recurrence relation
 * F(n) = a*F(n-1) + b*F(n-2) where a and b are parameters
 */
class GeneralizedFibonacciSearch {
private:
    vector<int> sequence;
    int a, b;
    
    void generateSequence(int maxN, int a, int b) {
        sequence.clear();
        sequence.push_back(0);
        sequence.push_back(1);
        
        while (sequence.back() < maxN) {
            int next = a * sequence[sequence.size()-1] + b * sequence[sequence.size()-2];
            if (next <= sequence.back()) break;  // Prevent infinite loop
            sequence.push_back(next);
        }
    }
    
public:
    GeneralizedFibonacciSearch(int a = 1, int b = 1) : a(a), b(b) {}
    
    int search(const vector<int>& arr, int target) {
        int n = arr.size();
        if (n == 0) return -1;
        
        generateSequence(n * 2, a, b);
        
        // Find appropriate sequence number
        int seqIndex = 0;
        while (seqIndex < sequence.size() && sequence[seqIndex] < n) {
            seqIndex++;
        }
        
        if (seqIndex < 2) return (n > 0 && arr[0] == target) ? 0 : -1;
        
        int seqM = sequence[seqIndex];
        int seqM1 = sequence[seqIndex - 1];
        int seqM2 = sequence[seqIndex - 2];
        int offset = -1;
        
        while (seqM > 1) {
            int i = min(offset + seqM2, n - 1);
            
            if (arr[i] < target) {
                seqM = seqM1;
                seqM1 = seqM2;
                seqM2 = seqM - seqM1;
                offset = i;
            }
            else if (arr[i] > target) {
                seqM = seqM2;
                seqM1 = seqM1 - seqM2;
                seqM2 = seqM - seqM1;
            }
            else {
                return i;
            }
        }
        
        if (seqM1 && offset + 1 < n && arr[offset + 1] == target) {
            return offset + 1;
        }
        
        return -1;
    }
};
        </div>
        
        <h3>2. Interpolated Fibonacci Search</h3>
        <div class="code-block">
/**
 * Combines Fibonacci search with interpolation for uniform data
 */
int interpolatedFibonacciSearch(const vector<int>& arr, int target) {
    int n = arr.size();
    if (n == 0) return -1;
    
    // Quick boundary checks
    if (target < arr[0] || target > arr[n-1]) return -1;
    if (arr[0] == target) return 0;
    if (arr[n-1] == target) return n-1;
    
    // Use interpolation to get initial estimate
    double ratio = (double)(target - arr[0]) / (arr[n-1] - arr[0]);
    int estimatedPos = (int)(ratio * (n - 1));
    
    // Find Fibonacci numbers around the estimated position
    int fibM2 = 0, fibM1 = 1, fibM = 1;
    while (fibM < n) {
        fibM2 = fibM1;
        fibM1 = fibM;
        fibM = fibM2 + fibM1;
    }
    
    // Adjust starting position based on interpolation
    int offset = max(-1, estimatedPos - fibM1);
    
    // Continue with standard Fibonacci search
    while (fibM > 1) {
        int i = min(offset + fibM2, n - 1);
        
        if (arr[i] < target) {
            fibM = fibM1;
            fibM1 = fibM2;
            fibM2 = fibM - fibM1;
            offset = i;
        }
        else if (arr[i] > target) {
            fibM = fibM2;
            fibM1 = fibM1 - fibM2;
            fibM2 = fibM - fibM1;
        }
        else {
            return i;
        }
    }
    
    if (fibM1 && offset + 1 < n && arr[offset + 1] == target) {
        return offset + 1;
    }
    
    return -1;
}
        </div>
        
        <h2 class="section-title">When to Use Fibonacci Search</h2>
        
        <div class="definition-box">
            <strong>Use Fibonacci Search When:</strong><br>
            • Division operations are expensive or unavailable<br>
            • Working with embedded systems or microcontrollers<br>
            • Cache performance is critical<br>
            • You want to avoid floating-point arithmetic<br>
            • Working with systems that favor addition over division<br><br>
            
            <strong>Don't Use Fibonacci Search When:</strong><br>
            • Division is as fast as addition (modern processors)<br>
            • Array is very small (overhead not worth it)<br>
            • You need the absolute simplest implementation<br>
            • Working with non-uniform data (interpolation search better)
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Fibonacci Generation:</strong> Ensure Fibonacci numbers don't overflow</li>
            <li><strong>Boundary Conditions:</strong> Handle edge cases carefully, especially the final check</li>
            <li><strong>Index Calculations:</strong> Be careful with offset and Fibonacci number arithmetic</li>
            <li><strong>Empty Arrays:</strong> Handle empty input arrays</li>
            <li><strong>Single Element:</strong> Handle edge case of single-element arrays</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Fibonacci Properties:</strong> Explain the mathematical foundation and golden ratio connection</li>
            <li><strong>Division Avoidance:</strong> Emphasize that it uses only addition and subtraction</li>
            <li><strong>Use Cases:</strong> Discuss scenarios where Fibonacci search is preferred</li>
            <li><strong>Implementation:</strong> Be careful with the three Fibonacci number tracking</li>
            <li><strong>Comparison:</strong> Compare with binary search in terms of operations and performance</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Fibonacci search uses Fibonacci numbers to divide the search space</li>
                <li>Time complexity is O(log n) with slightly better constants than binary search</li>
                <li>Uses only addition and subtraction, no division operations</li>
                <li>Better cache performance due to Fibonacci-based memory access patterns</li>
                <li>Particularly useful in systems where division is expensive</li>
                <li>Can be generalized to other recurrence relations</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch8">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 8</div>
        <h1 class="chapter-title">Bubble Sort</h1>
        
        <p class="academic-text">
            Bubble sort is one of the simplest sorting algorithms to understand and implement. It works by repeatedly stepping through the list, comparing adjacent elements and swapping them if they are in the wrong order. The pass through the list is repeated until the list is sorted. The algorithm gets its name because smaller elements "bubble" to the top of the list.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given an array of n elements, sort the array in ascending order using the bubble sort algorithm. The algorithm should arrange elements such that arr[0] ≤ arr[1] ≤ arr[2] ≤ ... ≤ arr[n-1].
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Array arr[] of size n with comparable elements<br>
            <strong>Output:</strong> Same array sorted in ascending order<br>
            <strong>Stability:</strong> Stable sorting algorithm (maintains relative order of equal elements)
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Bubble sort works through the following process:
        </p>
        
        <ol>
            <li>Compare adjacent elements in the array</li>
            <li>If they are in the wrong order (left > right for ascending), swap them</li>
            <li>Continue this process for the entire array</li>
            <li>After each complete pass, the largest element "bubbles up" to its correct position</li>
            <li>Repeat the process for the remaining unsorted portion</li>
            <li>Continue until no swaps are needed (array is sorted)</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: BubbleSort(arr, n)
1. for i = 0 to n-2 do
2.     swapped = false
3.     for j = 0 to n-2-i do
4.         if arr[j] > arr[j+1] then
5.             swap(arr[j], arr[j+1])
6.             swapped = true
7.         end if
8.     end for
9.     if swapped == false then
10.        break  // Array is already sorted
11.    end if
12. end for
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
using namespace std;

/**
 * Bubble Sort - Basic Implementation
 * Sorts array in ascending order using bubble sort algorithm
 * 
 * @param arr: input array to be sorted
 */
void bubbleSort(vector<int>& arr) {
    int n = arr.size();
    
    // Traverse through all array elements
    for (int i = 0; i < n - 1; i++) {
        // Last i elements are already in place
        for (int j = 0; j < n - i - 1; j++) {
            // Traverse the array from 0 to n-i-1
            // Swap if the element found is greater than the next element
            if (arr[j] > arr[j + 1]) {
                swap(arr[j], arr[j + 1]);
            }
        }
    }
}

/**
 * Optimized Bubble Sort
 * Includes early termination when array becomes sorted
 */
void optimizedBubbleSort(vector<int>& arr) {
    int n = arr.size();
    bool swapped;
    
    for (int i = 0; i < n - 1; i++) {
        swapped = false;
        
        // Last i elements are already sorted
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                swap(arr[j], arr[j + 1]);
                swapped = true;
            }
        }
        
        // If no swapping occurred, array is sorted
        if (!swapped) {
            break;
        }
    }
}

/**
 * Bubble Sort with Statistics
 * Tracks comparisons and swaps for analysis
 */
struct BubbleSortStats {
    int comparisons;
    int swaps;
    int passes;
    vector<vector<int>> stateHistory;
};

BubbleSortStats bubbleSortWithStats(vector<int>& arr) {
    BubbleSortStats stats = {0, 0, 0, {}};
    int n = arr.size();
    
    // Save initial state
    stats.stateHistory.push_back(arr);
    
    for (int i = 0; i < n - 1; i++) {
        stats.passes++;
        bool swapped = false;
        
        for (int j = 0; j < n - i - 1; j++) {
            stats.comparisons++;
            
            if (arr[j] > arr[j + 1]) {
                swap(arr[j], arr[j + 1]);
                stats.swaps++;
                swapped = true;
            }
        }
        
        // Save state after each pass
        stats.stateHistory.push_back(arr);
        
        if (!swapped) {
            break;
        }
    }
    
    return stats;
}

/**
 * Cocktail Shaker Sort (Bidirectional Bubble Sort)
 * Optimized version that sorts in both directions
 */
void cocktailShakerSort(vector<int>& arr) {
    int n = arr.size();
    bool swapped = true;
    int start = 0;
    int end = n - 1;
    
    while (swapped) {
        swapped = false;
        
        // Forward pass (left to right)
        for (int i = start; i < end; i++) {
            if (arr[i] > arr[i + 1]) {
                swap(arr[i], arr[i + 1]);
                swapped = true;
            }
        }
        
        if (!swapped) break;
        
        // Move the end point back by one
        end--;
        swapped = false;
        
        // Backward pass (right to left)
        for (int i = end - 1; i >= start; i--) {
            if (arr[i] > arr[i + 1]) {
                swap(arr[i], arr[i + 1]);
                swapped = true;
            }
        }
        
        // Move the start point forward by one
        start++;
    }
}

/**
 * Recursive Bubble Sort
 * Recursive implementation of bubble sort
 */
void recursiveBubbleSort(vector<int>& arr, int n) {
    // Base case
    if (n == 1) return;
    
    // One pass of bubble sort
    // After this pass, the largest element is moved to end
    for (int i = 0; i < n - 1; i++) {
        if (arr[i] > arr[i + 1]) {
            swap(arr[i], arr[i + 1]);
        }
    }
    
    // Largest element is fixed, recur for remaining array
    recursiveBubbleSort(arr, n - 1);
}

/**
 * Generic Bubble Sort with Custom Comparator
 * Works with any comparable type and custom comparison function
 */
template<typename T, typename Compare>
void bubbleSortGeneric(vector<T>& arr, Compare comp) {
    int n = arr.size();
    
    for (int i = 0; i < n - 1; i++) {
        bool swapped = false;
        
        for (int j = 0; j < n - i - 1; j++) {
            if (comp(arr[j + 1], arr[j])) {  // If arr[j+1] should come before arr[j]
                swap(arr[j], arr[j + 1]);
                swapped = true;
            }
        }
        
        if (!swapped) break;
    }
}

/**
 * Bubble Sort for Linked List
 * Demonstrates bubble sort on linked list structure
 */
struct ListNode {
    int val;
    ListNode* next;
    ListNode(int x) : val(x), next(nullptr) {}
};

ListNode* bubbleSortLinkedList(ListNode* head) {
    if (!head || !head->next) return head;
    
    bool swapped = true;
    
    while (swapped) {
        swapped = false;
        ListNode* current = head;
        
        while (current->next) {
            if (current->val > current->next->val) {
                // Swap values
                swap(current->val, current->next->val);
                swapped = true;
            }
            current = current->next;
        }
    }
    
    return head;
}

// Utility functions for demonstration
void printArray(const vector<int>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << arr[i];
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

void printLinkedList(ListNode* head) {
    cout << "[";
    while (head) {
        cout << head->val;
        if (head->next) cout << ", ";
        head = head->next;
    }
    cout << "]" << endl;
}

// Example usage and testing
int main() {
    // Test basic bubble sort
    vector<int> arr1 = {64, 34, 25, 12, 22, 11, 90};
    cout << "=== Basic Bubble Sort ===" << endl;
    printArray(arr1, "Original");
    
    bubbleSort(arr1);
    printArray(arr1, "Sorted");
    
    // Test optimized bubble sort with statistics
    vector<int> arr2 = {5, 2, 8, 1, 9};
    cout << "\n=== Optimized Bubble Sort with Statistics ===" << endl;
    printArray(arr2, "Original");
    
    BubbleSortStats stats = bubbleSortWithStats(arr2);
    printArray(arr2, "Sorted");
    
    cout << "Statistics:" << endl;
    cout << "  Comparisons: " << stats.comparisons << endl;
    cout << "  Swaps: " << stats.swaps << endl;
    cout << "  Passes: " << stats.passes << endl;
    
    cout << "  State history:" << endl;
    for (int i = 0; i < stats.stateHistory.size(); i++) {
        cout << "    Pass " << i << ": ";
        printArray(stats.stateHistory[i], "");
    }
    
    // Test cocktail shaker sort
    vector<int> arr3 = {2, 3, 1, 4, 5};
    cout << "\n=== Cocktail Shaker Sort ===" << endl;
    printArray(arr3, "Original");
    
    cocktailShakerSort(arr3);
    printArray(arr3, "Sorted");
    
    // Test recursive bubble sort
    vector<int> arr4 = {3, 1, 4, 1, 5, 9, 2, 6};
    cout << "\n=== Recursive Bubble Sort ===" << endl;
    printArray(arr4, "Original");
    
    recursiveBubbleSort(arr4, arr4.size());
    printArray(arr4, "Sorted");
    
    // Test generic bubble sort with custom comparator
    vector<string> words = {"banana", "apple", "cherry", "date"};
    cout << "\n=== Generic Bubble Sort (Strings) ===" << endl;
    cout << "Original: [";
    for (int i = 0; i < words.size(); i++) {
        cout << words[i];
        if (i < words.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    bubbleSortGeneric(words, [](const string& a, const string& b) {
        return a < b;  // Ascending order
    });
    
    cout << "Sorted: [";
    for (int i = 0; i < words.size(); i++) {
        cout << words[i];
        if (i < words.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    // Test linked list bubble sort
    cout << "\n=== Linked List Bubble Sort ===" << endl;
    ListNode* head = new ListNode(4);
    head->next = new ListNode(2);
    head->next->next = new ListNode(1);
    head->next->next->next = new ListNode(3);
    
    cout << "Original: ";
    printLinkedList(head);
    
    head = bubbleSortLinkedList(head);
    cout << "Sorted: ";
    printLinkedList(head);
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(n) - When array is already sorted (with optimization)</li>
                <li><strong>Average Case:</strong> O(n²) - Random order of elements</li>
                <li><strong>Worst Case:</strong> O(n²) - When array is sorted in reverse order</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(1) - Only uses constant extra space</li>
                <li><strong>In-place:</strong> Yes - Sorts the array without using extra space</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Stable:</strong> Yes - Equal elements maintain their relative order</li>
                <li><strong>Adaptive:</strong> Yes - Performs better on partially sorted arrays</li>
                <li><strong>Online:</strong> No - Needs the entire dataset to work</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through bubble sort on array [5, 2, 8, 1, 9]:
        </p>
        
        <div class="code-block">
Initial: [5, 2, 8, 1, 9]

Pass 1:
  Compare 5,2: 5>2, swap → [2, 5, 8, 1, 9]
  Compare 5,8: 5<8, no swap → [2, 5, 8, 1, 9]
  Compare 8,1: 8>1, swap → [2, 5, 1, 8, 9]
  Compare 8,9: 8<9, no swap → [2, 5, 1, 8, 9]
  Largest element (9) is now in correct position

Pass 2:
  Compare 2,5: 2<5, no swap → [2, 5, 1, 8, 9]
  Compare 5,1: 5>1, swap → [2, 1, 5, 8, 9]
  Compare 5,8: 5<8, no swap → [2, 1, 5, 8, 9]
  Second largest (8) is now in correct position

Pass 3:
  Compare 2,1: 2>1, swap → [1, 2, 5, 8, 9]
  Compare 2,5: 2<5, no swap → [1, 2, 5, 8, 9]
  Third largest (5) is now in correct position

Pass 4:
  Compare 1,2: 1<2, no swap → [1, 2, 5, 8, 9]
  No swaps occurred, array is sorted!

Final: [1, 2, 5, 8, 9]
Total comparisons: 10, Total swaps: 4
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Despite its poor time complexity, bubble sort has some practical applications:
        </p>
        
        <ul>
            <li><strong>Educational Purposes:</strong> Teaching sorting concepts and algorithm analysis</li>
            <li><strong>Small Datasets:</strong> When simplicity is more important than efficiency</li>
            <li><strong>Nearly Sorted Data:</strong> Performs well on data that's already mostly sorted</li>
            <li><strong>Memory-Constrained Systems:</strong> When auxiliary space is extremely limited</li>
            <li><strong>Stable Sorting Requirement:</strong> When maintaining relative order of equal elements is crucial</li>
            <li><strong>Interactive Sorting:</strong> For visualizing how sorting algorithms work</li>
        </ul>
        
        <h2 class="section-title">Optimizations and Variations</h2>
        
        <h3>1. Early Termination Optimization</h3>
        <div class="code-block">
// Stop early if no swaps occur in a pass
void optimizedBubbleSort(vector<int>& arr) {
    int n = arr.size();
    for (int i = 0; i < n - 1; i++) {
        bool swapped = false;
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                swap(arr[j], arr[j + 1]);
                swapped = true;
            }
        }
        if (!swapped) break;  // Array is sorted
    }
}
        </div>
        
        <h3>2. Cocktail Shaker Sort (Bidirectional)</h3>
        <div class="code-block">
// Bubble in both directions to move small and large elements faster
void cocktailSort(vector<int>& arr) {
    bool swapped = true;
    int start = 0, end = arr.size() - 1;
    
    while (swapped) {
        swapped = false;
        
        // Forward pass
        for (int i = start; i < end; i++) {
            if (arr[i] > arr[i + 1]) {
                swap(arr[i], arr[i + 1]);
                swapped = true;
            }
        }
        end--;
        
        if (!swapped) break;
        swapped = false;
        
        // Backward pass
        for (int i = end - 1; i >= start; i--) {
            if (arr[i] > arr[i + 1]) {
                swap(arr[i], arr[i + 1]);
                swapped = true;
            }
        }
        start++;
    }
}
        </div>
        
        <h3>3. Odd-Even Sort (Parallel Bubble Sort)</h3>
        <div class="code-block">
// Can be parallelized for concurrent processing
void oddEvenSort(vector<int>& arr) {
    int n = arr.size();
    bool sorted = false;
    
    while (!sorted) {
        sorted = true;
        
        // Odd phase
        for (int i = 1; i < n - 1; i += 2) {
            if (arr[i] > arr[i + 1]) {
                swap(arr[i], arr[i + 1]);
                sorted = false;
            }
        }
        
        // Even phase
        for (int i = 0; i < n - 1; i += 2) {
            if (arr[i] > arr[i + 1]) {
                swap(arr[i], arr[i + 1]);
                sorted = false;
            }
        }
    }
}
        </div>
        
        <h2 class="section-title">When to Use Bubble Sort</h2>
        
        <div class="definition-box">
            <strong>Use Bubble Sort When:</strong><br>
            • Dataset is very small (< 10 elements)<br>
            • Simplicity and readability are more important than performance<br>
            • Memory is extremely constrained<br>
            • Data is already nearly sorted<br>
            • You need a stable sorting algorithm<br>
            • Teaching or demonstrating sorting concepts<br><br>
            
            <strong>Don't Use Bubble Sort When:</strong><br>
            • Dataset is large (> 50 elements)<br>
            • Performance is critical<br>
            • You have access to better sorting algorithms<br>
            • Working with production systems
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Forgetting Optimization:</strong> Always include the early termination check</li>
            <li><strong>Off-by-One Errors:</strong> Be careful with loop bounds (n-1, n-i-1)</li>
            <li><strong>Infinite Loops:</strong> Ensure the inner loop bound decreases with each pass</li>
            <li><strong>Not Handling Edge Cases:</strong> Empty arrays or single-element arrays</li>
            <li><strong>Using for Large Data:</strong> Don't use bubble sort for large datasets</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Mention Optimization:</strong> Always discuss the early termination optimization</li>
            <li><strong>Stability:</strong> Emphasize that bubble sort is stable</li>
            <li><strong>Best Case:</strong> Explain how optimized version achieves O(n) for sorted arrays</li>
            <li><strong>Variations:</strong> Mention cocktail shaker sort as an improvement</li>
            <li><strong>Use Cases:</strong> Discuss when bubble sort might actually be appropriate</li>
            <li><strong>Comparison:</strong> Compare with other O(n²) algorithms like selection and insertion sort</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Bubble sort is the simplest sorting algorithm to understand and implement</li>
                <li>Time complexity is O(n²) in average and worst case, O(n) in best case with optimization</li>
                <li>Space complexity is O(1) - it's an in-place sorting algorithm</li>
                <li>It's stable and adaptive but not suitable for large datasets</li>
                <li>Early termination optimization significantly improves performance on nearly sorted data</li>
                <li>Variations like cocktail shaker sort can provide modest improvements</li>
                <li>Primarily used for educational purposes and very small datasets</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch9">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 9</div>
        <h1 class="chapter-title">Selection Sort</h1>
        
        <p class="academic-text">
            Selection sort is a simple comparison-based sorting algorithm that works by dividing the array into two parts: a sorted portion and an unsorted portion. It repeatedly finds the minimum element from the unsorted portion and moves it to the end of the sorted portion. Despite its simplicity, selection sort is inefficient for large datasets but has some interesting properties that make it useful in specific scenarios.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given an array of n elements, sort the array in ascending order using the selection sort algorithm. The algorithm should find the minimum element in each iteration and place it in its correct position.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Array arr[] of size n with comparable elements<br>
            <strong>Output:</strong> Same array sorted in ascending order<br>
            <strong>Stability:</strong> Not stable (can change relative order of equal elements)
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Selection sort works through the following process:
        </p>
        
        <ol>
            <li>Find the minimum element in the entire array</li>
            <li>Swap it with the first element</li>
            <li>Find the minimum element in the remaining array (excluding the first element)</li>
            <li>Swap it with the second element</li>
            <li>Continue this process until the entire array is sorted</li>
            <li>After k iterations, the first k elements are in their final sorted positions</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: SelectionSort(arr, n)
1. for i = 0 to n-2 do
2.     minIndex = i
3.     for j = i+1 to n-1 do
4.         if arr[j] < arr[minIndex] then
5.             minIndex = j
6.         end if
7.     end for
8.     if minIndex != i then
9.         swap(arr[i], arr[minIndex])
10.    end if
11. end for
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
#include <climits>
using namespace std;

/**
 * Selection Sort - Basic Implementation
 * Sorts array in ascending order using selection sort algorithm
 * 
 * @param arr: input array to be sorted
 */
void selectionSort(vector<int>& arr) {
    int n = arr.size();
    
    // One by one move boundary of unsorted subarray
    for (int i = 0; i < n - 1; i++) {
        // Find the minimum element in remaining unsorted array
        int minIndex = i;
        for (int j = i + 1; j < n; j++) {
            if (arr[j] < arr[minIndex]) {
                minIndex = j;
            }
        }
        
        // Swap the found minimum element with the first element
        if (minIndex != i) {
            swap(arr[i], arr[minIndex]);
        }
    }
}

/**
 * Selection Sort with Statistics
 * Tracks comparisons and swaps for analysis
 */
struct SelectionSortStats {
    int comparisons;
    int swaps;
    int passes;
    vector<vector<int>> stateHistory;
    vector<int> minIndicesFound;
};

SelectionSortStats selectionSortWithStats(vector<int>& arr) {
    SelectionSortStats stats = {0, 0, 0, {}, {}};
    int n = arr.size();
    
    // Save initial state
    stats.stateHistory.push_back(arr);
    
    for (int i = 0; i < n - 1; i++) {
        stats.passes++;
        int minIndex = i;
        
        // Find minimum element in remaining array
        for (int j = i + 1; j < n; j++) {
            stats.comparisons++;
            if (arr[j] < arr[minIndex]) {
                minIndex = j;
            }
        }
        
        stats.minIndicesFound.push_back(minIndex);
        
        // Swap if necessary
        if (minIndex != i) {
            swap(arr[i], arr[minIndex]);
            stats.swaps++;
        }
        
        // Save state after each pass
        stats.stateHistory.push_back(arr);
    }
    
    return stats;
}

/**
 * Stable Selection Sort
 * Modified version that maintains stability
 */
void stableSelectionSort(vector<int>& arr) {
    int n = arr.size();
    
    for (int i = 0; i < n - 1; i++) {
        // Find minimum element in remaining array
        int minIndex = i;
        for (int j = i + 1; j < n; j++) {
            if (arr[j] < arr[minIndex]) {
                minIndex = j;
            }
        }
        
        // Instead of swapping, shift elements to maintain stability
        int minValue = arr[minIndex];
        
        // Shift all elements from i to minIndex-1 one position right
        for (int k = minIndex; k > i; k--) {
            arr[k] = arr[k - 1];
        }
        
        // Place minimum element at position i
        arr[i] = minValue;
    }
}

/**
 * Bidirectional Selection Sort
 * Finds both minimum and maximum in each pass
 */
void bidirectionalSelectionSort(vector<int>& arr) {
    int n = arr.size();
    int left = 0, right = n - 1;
    
    while (left < right) {
        int minIndex = left, maxIndex = left;
        
        // Find both minimum and maximum in current range
        for (int i = left; i <= right; i++) {
            if (arr[i] < arr[minIndex]) {
                minIndex = i;
            }
            if (arr[i] > arr[maxIndex]) {
                maxIndex = i;
            }
        }
        
        // Swap minimum element to left position
        if (minIndex != left) {
            swap(arr[left], arr[minIndex]);
            
            // If maxIndex was at left position, update it
            if (maxIndex == left) {
                maxIndex = minIndex;
            }
        }
        
        // Swap maximum element to right position
        if (maxIndex != right) {
            swap(arr[right], arr[maxIndex]);
        }
        
        left++;
        right--;
    }
}

/**
 * Recursive Selection Sort
 * Recursive implementation of selection sort
 */
void recursiveSelectionSort(vector<int>& arr, int startIndex = 0) {
    int n = arr.size();
    
    // Base case
    if (startIndex >= n - 1) {
        return;
    }
    
    // Find minimum element in remaining array
    int minIndex = startIndex;
    for (int i = startIndex + 1; i < n; i++) {
        if (arr[i] < arr[minIndex]) {
            minIndex = i;
        }
    }
    
    // Swap minimum element with first element of remaining array
    if (minIndex != startIndex) {
        swap(arr[startIndex], arr[minIndex]);
    }
    
    // Recursively sort the remaining array
    recursiveSelectionSort(arr, startIndex + 1);
}

/**
 * Generic Selection Sort with Custom Comparator
 * Works with any comparable type and custom comparison function
 */
template<typename T, typename Compare>
void selectionSortGeneric(vector<T>& arr, Compare comp) {
    int n = arr.size();
    
    for (int i = 0; i < n - 1; i++) {
        int selectedIndex = i;
        
        for (int j = i + 1; j < n; j++) {
            if (comp(arr[j], arr[selectedIndex])) {
                selectedIndex = j;
            }
        }
        
        if (selectedIndex != i) {
            swap(arr[i], arr[selectedIndex]);
        }
    }
}

/**
 * Selection Sort with Early Termination
 * Optimized version that can terminate early in some cases
 */
void optimizedSelectionSort(vector<int>& arr) {
    int n = arr.size();
    
    for (int i = 0; i < n - 1; i++) {
        int minIndex = i;
        bool foundSmaller = false;
        
        // Find minimum element in remaining array
        for (int j = i + 1; j < n; j++) {
            if (arr[j] < arr[minIndex]) {
                minIndex = j;
                foundSmaller = true;
            }
        }
        
        // If no smaller element found, remaining array is already sorted
        if (!foundSmaller) {
            break;
        }
        
        // Swap minimum element with current position
        if (minIndex != i) {
            swap(arr[i], arr[minIndex]);
        }
    }
}

/**
 * Selection Sort for Finding K Smallest Elements
 * Modified to find only k smallest elements
 */
vector<int> findKSmallest(vector<int>& arr, int k) {
    int n = arr.size();
    k = min(k, n);  // Ensure k doesn't exceed array size
    
    // Perform selection sort for first k elements only
    for (int i = 0; i < k; i++) {
        int minIndex = i;
        
        for (int j = i + 1; j < n; j++) {
            if (arr[j] < arr[minIndex]) {
                minIndex = j;
            }
        }
        
        if (minIndex != i) {
            swap(arr[i], arr[minIndex]);
        }
    }
    
    // Return first k elements
    return vector<int>(arr.begin(), arr.begin() + k);
}

/**
 * Selection Sort with Memory Access Optimization
 * Reduces memory writes by avoiding unnecessary swaps
 */
void memoryOptimizedSelectionSort(vector<int>& arr) {
    int n = arr.size();
    
    for (int i = 0; i < n - 1; i++) {
        int minIndex = i;
        
        // Find minimum element in remaining array
        for (int j = i + 1; j < n; j++) {
            if (arr[j] < arr[minIndex]) {
                minIndex = j;
            }
        }
        
        // Only swap if minimum element is not already in correct position
        if (minIndex != i) {
            swap(arr[i], arr[minIndex]);
        }
    }
}

// Utility functions for demonstration
void printArray(const vector<int>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << arr[i];
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

// Example usage and testing
int main() {
    // Test basic selection sort
    vector<int> arr1 = {64, 25, 12, 22, 11};
    cout << "=== Basic Selection Sort ===" << endl;
    printArray(arr1, "Original");
    
    selectionSort(arr1);
    printArray(arr1, "Sorted");
    
    // Test selection sort with statistics
    vector<int> arr2 = {5, 2, 8, 1, 9};
    cout << "\n=== Selection Sort with Statistics ===" << endl;
    printArray(arr2, "Original");
    
    SelectionSortStats stats = selectionSortWithStats(arr2);
    printArray(arr2, "Sorted");
    
    cout << "Statistics:" << endl;
    cout << "  Comparisons: " << stats.comparisons << endl;
    cout << "  Swaps: " << stats.swaps << endl;
    cout << "  Passes: " << stats.passes << endl;
    
    cout << "  State history:" << endl;
    for (int i = 0; i < stats.stateHistory.size(); i++) {
        cout << "    Pass " << i << ": ";
        printArray(stats.stateHistory[i], "");
        if (i > 0 && i <= stats.minIndicesFound.size()) {
            cout << "      (Selected min from index " << stats.minIndicesFound[i-1] << ")" << endl;
        }
    }
    
    // Test stable selection sort
    vector<int> arr3 = {4, 2, 3, 2, 1};
    cout << "\n=== Stable Selection Sort ===" << endl;
    printArray(arr3, "Original");
    
    stableSelectionSort(arr3);
    printArray(arr3, "Sorted (Stable)");
    
    // Test bidirectional selection sort
    vector<int> arr4 = {3, 7, 1, 9, 4, 6, 2, 8};
    cout << "\n=== Bidirectional Selection Sort ===" << endl;
    printArray(arr4, "Original");
    
    bidirectionalSelectionSort(arr4);
    printArray(arr4, "Sorted");
    
    // Test recursive selection sort
    vector<int> arr5 = {9, 5, 1, 4, 3};
    cout << "\n=== Recursive Selection Sort ===" << endl;
    printArray(arr5, "Original");
    
    recursiveSelectionSort(arr5);
    printArray(arr5, "Sorted");
    
    // Test finding k smallest elements
    vector<int> arr6 = {7, 2, 9, 1, 5, 6};
    int k = 3;
    cout << "\n=== Finding " << k << " Smallest Elements ===" << endl;
    printArray(arr6, "Original");
    
    vector<int> kSmallest = findKSmallest(arr6, k);
    printArray(kSmallest, "3 Smallest");
    printArray(arr6, "Array after partial sort");
    
    // Test generic selection sort with custom comparator
    vector<string> words = {"banana", "apple", "cherry", "date"};
    cout << "\n=== Generic Selection Sort (Strings, Descending) ===" << endl;
    cout << "Original: [";
    for (int i = 0; i < words.size(); i++) {
        cout << words[i];
        if (i < words.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    selectionSortGeneric(words, [](const string& a, const string& b) {
        return a > b;  // Descending order
    });
    
    cout << "Sorted (Desc): [";
    for (int i = 0; i < words.size(); i++) {
        cout << words[i];
        if (i < words.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(n²) - Even if array is sorted, still needs to find minimum</li>
                <li><strong>Average Case:</strong> O(n²) - Always performs the same number of comparisons</li>
                <li><strong>Worst Case:</strong> O(n²) - Same as best and average case</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(1) - Only uses constant extra space</li>
                <li><strong>In-place:</strong> Yes - Sorts the array without using extra space</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Stable:</strong> No - Can change relative order of equal elements</li>
                <li><strong>Adaptive:</strong> No - Performance doesn't improve on partially sorted arrays</li>
                <li><strong>Minimum Swaps:</strong> At most n-1 swaps (optimal for minimizing writes)</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through selection sort on array [5, 2, 8, 1, 9]:
        </p>
        
        <div class="code-block">
Initial: [5, 2, 8, 1, 9]

Pass 1 (i=0):
  Find minimum in [5, 2, 8, 1, 9]: minimum is 1 at index 3
  Swap arr[0] and arr[3]: [1, 2, 8, 5, 9]
  Sorted portion: [1]

Pass 2 (i=1):
  Find minimum in [2, 8, 5, 9]: minimum is 2 at index 1
  No swap needed: [1, 2, 8, 5, 9]
  Sorted portion: [1, 2]

Pass 3 (i=2):
  Find minimum in [8, 5, 9]: minimum is 5 at index 3
  Swap arr[2] and arr[3]: [1, 2, 5, 8, 9]
  Sorted portion: [1, 2, 5]

Pass 4 (i=3):
  Find minimum in [8, 9]: minimum is 8 at index 3
  No swap needed: [1, 2, 5, 8, 9]
  Sorted portion: [1, 2, 5, 8]

Final: [1, 2, 5, 8, 9]
Total comparisons: 10, Total swaps: 2
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Selection sort has specific applications where its properties are advantageous:
        </p>
        
        <ul>
            <li><strong>Memory Write Minimization:</strong> When write operations are expensive (flash memory, EEPROM)</li>
            <li><strong>Finding K Smallest/Largest:</strong> Can be stopped after k iterations</li>
            <li><strong>Simple Implementation:</strong> When code simplicity is more important than efficiency</li>
            <li><strong>Small Datasets:</strong> Reasonable performance for very small arrays</li>
            <li><strong>Educational Purposes:</strong> Teaching sorting concepts and algorithm analysis</li>
            <li><strong>Embedded Systems:</strong> When memory is limited and simplicity is valued</li>
        </ul>
        
        <h2 class="section-title">Optimizations and Variations</h2>
        
        <h3>1. Bidirectional Selection Sort</h3>
        <div class="code-block">
// Find both minimum and maximum in each pass
void bidirectionalSelectionSort(vector<int>& arr) {
    int left = 0, right = arr.size() - 1;
    
    while (left < right) {
        int minIndex = left, maxIndex = left;
        
        // Find both min and max in current range
        for (int i = left; i <= right; i++) {
            if (arr[i] < arr[minIndex]) minIndex = i;
            if (arr[i] > arr[maxIndex]) maxIndex = i;
        }
        
        // Place min and max in correct positions
        swap(arr[left], arr[minIndex]);
        if (maxIndex == left) maxIndex = minIndex;
        swap(arr[right], arr[maxIndex]);
        
        left++; right--;
    }
}
        </div>
        
        <h3>2. Heap Selection Sort</h3>
        <div class="code-block">
// Use heap to efficiently find minimum elements
void heapSelectionSort(vector<int>& arr) {
    // Build min heap from array
    make_heap(arr.begin(), arr.end(), greater<int>());
    
    vector<int> result;
    while (!arr.empty()) {
        // Extract minimum element
        pop_heap(arr.begin(), arr.end(), greater<int>());
        result.push_back(arr.back());
        arr.pop_back();
    }
    
    arr = result;
}
        </div>
        
        <h3>3. Stable Selection Sort</h3>
        <div class="code-block">
// Maintain stability by shifting instead of swapping
void stableSelectionSort(vector<int>& arr) {
    for (int i = 0; i < arr.size() - 1; i++) {
        int minIndex = i;
        for (int j = i + 1; j < arr.size(); j++) {
            if (arr[j] < arr[minIndex]) {
                minIndex = j;
            }
        }
        
        // Shift elements to maintain stability
        int minValue = arr[minIndex];
        for (int k = minIndex; k > i; k--) {
            arr[k] = arr[k - 1];
        }
        arr[i] = minValue;
    }
}
        </div>
        
        <h2 class="section-title">When to Use Selection Sort</h2>
        
        <div class="definition-box">
            <strong>Use Selection Sort When:</strong><br>
            • Minimizing memory writes is critical (flash memory, EEPROM)<br>
            • You need to find only k smallest/largest elements<br>
            • Dataset is very small (< 20 elements)<br>
            • Simplicity is more important than efficiency<br>
            • Memory is extremely constrained<br>
            • Teaching sorting algorithm concepts<br><br>
            
            <strong>Don't Use Selection Sort When:</strong><br>
            • Dataset is large (> 50 elements)<br>
            • Performance is critical<br>
            • You need a stable sorting algorithm<br>
            • Data is already partially sorted (no advantage)<br>
            • Working with production systems requiring efficiency
        </div>
        
        <h2 class="section-title">Comparison with Other O(n²) Algorithms</h2>
        
        <div class="code-block">
Algorithm Comparison:

Selection Sort:
- Time: O(n²) always
- Swaps: O(n) - minimum possible
- Stable: No
- Adaptive: No
- Best for: Minimizing writes

Bubble Sort:
- Time: O(n²) worst, O(n) best
- Swaps: O(n²)
- Stable: Yes
- Adaptive: Yes
- Best for: Nearly sorted data

Insertion Sort:
- Time: O(n²) worst, O(n) best
- Swaps: O(n²)
- Stable: Yes
- Adaptive: Yes
- Best for: Small or nearly sorted data
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Assuming Stability:</strong> Selection sort is not stable by default</li>
            <li><strong>Unnecessary Swaps:</strong> Always check if minIndex != i before swapping</li>
            <li><strong>Off-by-One Errors:</strong> Loop should go to n-2, not n-1</li>
            <li><strong>Not Handling Edge Cases:</strong> Empty arrays or single-element arrays</li>
            <li><strong>Using for Large Data:</strong> Don't use selection sort for large datasets</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Minimum Swaps:</strong> Emphasize that selection sort minimizes the number of swaps</li>
            <li><strong>Consistent Performance:</strong> Always O(n²) regardless of input</li>
            <li><strong>Memory Writes:</strong> Discuss scenarios where minimizing writes is important</li>
            <li><strong>Finding K Elements:</strong> Mention that it can find k smallest elements efficiently</li>
            <li><strong>Stability Issues:</strong> Explain why it's not stable and how to make it stable</li>
            <li><strong>Variations:</strong> Discuss bidirectional selection sort as an optimization</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Selection sort consistently performs O(n²) comparisons regardless of input</li>
                <li>Minimizes the number of swaps - at most n-1 swaps total</li>
                <li>Not stable by default but can be made stable with modifications</li>
                <li>Not adaptive - doesn't perform better on partially sorted data</li>
                <li>Excellent when minimizing memory writes is critical</li>
                <li>Can be efficiently used to find k smallest/largest elements</li>
                <li>Simple to implement but inefficient for large datasets</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch10">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 10</div>
        <h1 class="chapter-title">Insertion Sort</h1>
        
        <p class="academic-text">
            Insertion sort is a simple and efficient sorting algorithm that builds the final sorted array one element at a time. It works by taking elements from the unsorted portion and inserting them into their correct position in the sorted portion. Like sorting playing cards in your hand, insertion sort is intuitive, adaptive, and performs exceptionally well on small or nearly sorted datasets.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given an array of n elements, sort the array in ascending order using the insertion sort algorithm. The algorithm should build a sorted sequence by repeatedly taking the next element and inserting it into the correct position among the previously sorted elements.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Array arr[] of size n with comparable elements<br>
            <strong>Output:</strong> Same array sorted in ascending order<br>
            <strong>Stability:</strong> Stable sorting algorithm (maintains relative order of equal elements)
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Insertion sort works through the following process:
        </p>
        
        <ol>
            <li>Start with the second element (index 1) as the first element is trivially sorted</li>
            <li>Compare the current element with the elements in the sorted portion (to its left)</li>
            <li>Shift all larger elements one position to the right</li>
            <li>Insert the current element in its correct position</li>
            <li>Repeat for all remaining elements</li>
            <li>After each iteration, the sorted portion grows by one element</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: InsertionSort(arr, n)
1. for i = 1 to n-1 do
2.     key = arr[i]
3.     j = i - 1
4.     
5.     // Move elements greater than key one position ahead
6.     while j >= 0 AND arr[j] > key do
7.         arr[j + 1] = arr[j]
8.         j = j - 1
9.     end while
10.    
11.    // Place key in its correct position
12.    arr[j + 1] = key
13. end for
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
#include <chrono>
using namespace std;

/**
 * Insertion Sort - Basic Implementation
 * Sorts array in ascending order using insertion sort algorithm
 * 
 * @param arr: input array to be sorted
 */
void insertionSort(vector<int>& arr) {
    int n = arr.size();
    
    // Start from the second element (index 1)
    for (int i = 1; i < n; i++) {
        int key = arr[i];  // Current element to be inserted
        int j = i - 1;     // Index of the last element in sorted portion
        
        // Move elements greater than key one position ahead
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j--;
        }
        
        // Insert key in its correct position
        arr[j + 1] = key;
    }
}

/**
 * Insertion Sort with Statistics
 * Tracks comparisons, shifts, and iterations for analysis
 */
struct InsertionSortStats {
    int comparisons;
    int shifts;
    int iterations;
    vector<vector<int>> stateHistory;
    vector<int> insertionPositions;
};

InsertionSortStats insertionSortWithStats(vector<int>& arr) {
    InsertionSortStats stats = {0, 0, 0, {}, {}};
    int n = arr.size();
    
    // Save initial state
    stats.stateHistory.push_back(arr);
    
    for (int i = 1; i < n; i++) {
        stats.iterations++;
        int key = arr[i];
        int j = i - 1;
        
        // Count comparisons and shifts
        while (j >= 0) {
            stats.comparisons++;
            if (arr[j] > key) {
                arr[j + 1] = arr[j];
                stats.shifts++;
                j--;
            } else {
                break;
            }
        }
        
        // Insert key in correct position
        arr[j + 1] = key;
        stats.insertionPositions.push_back(j + 1);
        
        // Save state after each iteration
        stats.stateHistory.push_back(arr);
    }
    
    return stats;
}

/**
 * Binary Insertion Sort
 * Uses binary search to find insertion position
 */
void binaryInsertionSort(vector<int>& arr) {
    int n = arr.size();
    
    for (int i = 1; i < n; i++) {
        int key = arr[i];
        
        // Find location to insert using binary search
        int left = 0, right = i;
        while (left < right) {
            int mid = left + (right - left) / 2;
            if (arr[mid] > key) {
                right = mid;
            } else {
                left = mid + 1;
            }
        }
        
        // Shift elements to make space for key
        for (int j = i - 1; j >= left; j--) {
            arr[j + 1] = arr[j];
        }
        
        // Insert key at found position
        arr[left] = key;
    }
}

/**
 * Recursive Insertion Sort
 * Recursive implementation of insertion sort
 */
void recursiveInsertionSort(vector<int>& arr, int n) {
    // Base case
    if (n <= 1) return;
    
    // Sort first n-1 elements
    recursiveInsertionSort(arr, n - 1);
    
    // Insert the nth element in its correct position
    int last = arr[n - 1];
    int j = n - 2;
    
    // Move elements greater than last one position ahead
    while (j >= 0 && arr[j] > last) {
        arr[j + 1] = arr[j];
        j--;
    }
    
    arr[j + 1] = last;
}

/**
 * Insertion Sort with Sentinel
 * Uses a sentinel to eliminate boundary checking
 */
void insertionSortWithSentinel(vector<int>& arr) {
    int n = arr.size();
    if (n <= 1) return;
    
    // Find minimum element and place it at the beginning as sentinel
    int minIndex = 0;
    for (int i = 1; i < n; i++) {
        if (arr[i] < arr[minIndex]) {
            minIndex = i;
        }
    }
    swap(arr[0], arr[minIndex]);
    
    // Now perform insertion sort without boundary checking
    for (int i = 2; i < n; i++) {
        int key = arr[i];
        int j = i - 1;
        
        // No need to check j >= 0 because sentinel guarantees termination
        while (arr[j] > key) {
            arr[j + 1] = arr[j];
            j--;
        }
        
        arr[j + 1] = key;
    }
}

/**
 * Generic Insertion Sort with Custom Comparator
 * Works with any comparable type and custom comparison function
 */
template<typename T, typename Compare>
void insertionSortGeneric(vector<T>& arr, Compare comp) {
    int n = arr.size();
    
    for (int i = 1; i < n; i++) {
        T key = arr[i];
        int j = i - 1;
        
        // Move elements that should come after key
        while (j >= 0 && comp(key, arr[j])) {
            arr[j + 1] = arr[j];
            j--;
        }
        
        arr[j + 1] = key;
    }
}

/**
 * Insertion Sort for Linked List
 * Demonstrates insertion sort on linked list structure
 */
struct ListNode {
    int val;
    ListNode* next;
    ListNode(int x) : val(x), next(nullptr) {}
};

ListNode* insertionSortLinkedList(ListNode* head) {
    if (!head || !head->next) return head;
    
    ListNode* sorted = nullptr;  // Head of sorted portion
    ListNode* current = head;    // Current node to be inserted
    
    while (current) {
        ListNode* next = current->next;  // Save next node
        
        // Insert current node into sorted list
        if (!sorted || current->val < sorted->val) {
            // Insert at beginning
            current->next = sorted;
            sorted = current;
        } else {
            // Find correct position to insert
            ListNode* temp = sorted;
            while (temp->next && temp->next->val < current->val) {
                temp = temp->next;
            }
            current->next = temp->next;
            temp->next = current;
        }
        
        current = next;
    }
    
    return sorted;
}

/**
 * Insertion Sort with Early Termination
 * Optimized for nearly sorted arrays
 */
void optimizedInsertionSort(vector<int>& arr) {
    int n = arr.size();
    
    for (int i = 1; i < n; i++) {
        // If current element is already in correct position, skip
        if (arr[i] >= arr[i - 1]) {
            continue;
        }
        
        int key = arr[i];
        int j = i - 1;
        
        // Move elements greater than key
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j--;
        }
        
        arr[j + 1] = key;
    }
}

/**
 * Shell Sort (Advanced Insertion Sort)
 * Uses insertion sort with gap sequences
 */
void shellSort(vector<int>& arr) {
    int n = arr.size();
    
    // Start with a big gap, then reduce the gap
    for (int gap = n / 2; gap > 0; gap /= 2) {
        // Perform insertion sort for elements at gap distance
        for (int i = gap; i < n; i++) {
            int key = arr[i];
            int j = i;
            
            // Shift elements until correct position is found
            while (j >= gap && arr[j - gap] > key) {
                arr[j] = arr[j - gap];
                j -= gap;
            }
            
            arr[j] = key;
        }
    }
}

// Utility functions for demonstration
void printArray(const vector<int>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << arr[i];
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

void printLinkedList(ListNode* head, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    while (head) {
        cout << head->val;
        if (head->next) cout << ", ";
        head = head->next;
    }
    cout << "]" << endl;
}

// Performance testing function
void performanceTest() {
    vector<int> sizes = {100, 500, 1000, 2000};
    
    cout << "\n=== Performance Analysis ===" << endl;
    cout << "Size\tRandom\tSorted\tReverse\tNearly Sorted" << endl;
    
    for (int size : sizes) {
        // Test on different data patterns
        vector<int> random(size), sorted(size), reverse(size), nearlySorted(size);
        
        // Generate test data
        for (int i = 0; i < size; i++) {
            random[i] = rand() % 1000;
            sorted[i] = i;
            reverse[i] = size - i;
            nearlySorted[i] = i;
        }
        
        // Make nearly sorted (90% sorted)
        for (int i = 0; i < size / 10; i++) {
            swap(nearlySorted[rand() % size], nearlySorted[rand() % size]);
        }
        
        // Time each pattern
        auto timeSort = [](vector<int> arr) {
            auto start = chrono::high_resolution_clock::now();
            insertionSort(arr);
            auto end = chrono::high_resolution_clock::now();
            return chrono::duration_cast<chrono::microseconds>(end - start).count();
        };
        
        cout << size << "\t" 
             << timeSort(random) << "\t"
             << timeSort(sorted) << "\t"
             << timeSort(reverse) << "\t"
             << timeSort(nearlySorted) << endl;
    }
}

// Example usage and testing
int main() {
    // Test basic insertion sort
    vector<int> arr1 = {5, 2, 4, 6, 1, 3};
    cout << "=== Basic Insertion Sort ===" << endl;
    printArray(arr1, "Original");
    
    insertionSort(arr1);
    printArray(arr1, "Sorted");
    
    // Test insertion sort with statistics
    vector<int> arr2 = {5, 2, 8, 1, 9};
    cout << "\n=== Insertion Sort with Statistics ===" << endl;
    printArray(arr2, "Original");
    
    InsertionSortStats stats = insertionSortWithStats(arr2);
    printArray(arr2, "Sorted");
    
    cout << "Statistics:" << endl;
    cout << "  Comparisons: " << stats.comparisons << endl;
    cout << "  Shifts: " << stats.shifts << endl;
    cout << "  Iterations: " << stats.iterations << endl;
    
    cout << "  State history:" << endl;
    for (int i = 0; i < stats.stateHistory.size(); i++) {
        cout << "    Step " << i << ": ";
        printArray(stats.stateHistory[i], "");
        if (i > 0 && i <= stats.insertionPositions.size()) {
            cout << "      (Inserted at position " << stats.insertionPositions[i-1] << ")" << endl;
        }
    }
    
    // Test binary insertion sort
    vector<int> arr3 = {4, 3, 2, 10, 12, 1, 5, 6};
    cout << "\n=== Binary Insertion Sort ===" << endl;
    printArray(arr3, "Original");
    
    binaryInsertionSort(arr3);
    printArray(arr3, "Sorted");
    
    // Test recursive insertion sort
    vector<int> arr4 = {9, 5, 1, 4, 3};
    cout << "\n=== Recursive Insertion Sort ===" << endl;
    printArray(arr4, "Original");
    
    recursiveInsertionSort(arr4, arr4.size());
    printArray(arr4, "Sorted");
    
    // Test insertion sort with sentinel
    vector<int> arr5 = {7, 2, 9, 1, 5, 6};
    cout << "\n=== Insertion Sort with Sentinel ===" << endl;
    printArray(arr5, "Original");
    
    insertionSortWithSentinel(arr5);
    printArray(arr5, "Sorted");
    
    // Test generic insertion sort
    vector<string> words = {"banana", "apple", "cherry", "date"};
    cout << "\n=== Generic Insertion Sort (Strings) ===" << endl;
    cout << "Original: [";
    for (int i = 0; i < words.size(); i++) {
        cout << words[i];
        if (i < words.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    insertionSortGeneric(words, [](const string& a, const string& b) {
        return a < b;  // Ascending order
    });
    
    cout << "Sorted: [";
    for (int i = 0; i < words.size(); i++) {
        cout << words[i];
        if (i < words.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    // Test linked list insertion sort
    cout << "\n=== Linked List Insertion Sort ===" << endl;
    ListNode* head = new ListNode(4);
    head->next = new ListNode(2);
    head->next->next = new ListNode(1);
    head->next->next->next = new ListNode(3);
    
    printLinkedList(head, "Original");
    
    head = insertionSortLinkedList(head);
    printLinkedList(head, "Sorted");
    
    // Test Shell sort
    vector<int> arr6 = {9, 5, 1, 4, 3, 8, 2, 7, 6};
    cout << "\n=== Shell Sort ===" << endl;
    printArray(arr6, "Original");
    
    shellSort(arr6);
    printArray(arr6, "Sorted");
    
    // Performance analysis
    performanceTest();
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(n) - When array is already sorted</li>
                <li><strong>Average Case:</strong> O(n²) - Random order of elements</li>
                <li><strong>Worst Case:</strong> O(n²) - When array is sorted in reverse order</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(1) - Only uses constant extra space</li>
                <li><strong>In-place:</strong> Yes - Sorts the array without using extra space</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Stable:</strong> Yes - Equal elements maintain their relative order</li>
                <li><strong>Adaptive:</strong> Yes - Performs better on partially sorted arrays</li>
                <li><strong>Online:</strong> Yes - Can sort elements as they arrive</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through insertion sort on array [5, 2, 4, 6, 1, 3]:
        </p>
        
        <div class="code-block">
Initial: [5, 2, 4, 6, 1, 3]

Iteration 1 (i=1, key=2):
  Compare 2 with 5: 2 < 5, shift 5 right
  Insert 2 at position 0: [2, 5, 4, 6, 1, 3]
  Sorted portion: [2, 5]

Iteration 2 (i=2, key=4):
  Compare 4 with 5: 4 < 5, shift 5 right
  Compare 4 with 2: 4 > 2, insert after 2
  Insert 4 at position 1: [2, 4, 5, 6, 1, 3]
  Sorted portion: [2, 4, 5]

Iteration 3 (i=3, key=6):
  Compare 6 with 5: 6 > 5, no shift needed
  Insert 6 at position 3: [2, 4, 5, 6, 1, 3]
  Sorted portion: [2, 4, 5, 6]

Iteration 4 (i=4, key=1):
  Compare 1 with 6: 1 < 6, shift 6 right
  Compare 1 with 5: 1 < 5, shift 5 right
  Compare 1 with 4: 1 < 4, shift 4 right
  Compare 1 with 2: 1 < 2, shift 2 right
  Insert 1 at position 0: [1, 2, 4, 5, 6, 3]
  Sorted portion: [1, 2, 4, 5, 6]

Iteration 5 (i=5, key=3):
  Compare 3 with 6: 3 < 6, shift 6 right
  Compare 3 with 5: 3 < 5, shift 5 right
  Compare 3 with 4: 3 < 4, shift 4 right
  Compare 3 with 2: 3 > 2, insert after 2
  Insert 3 at position 2: [1, 2, 3, 4, 5, 6]

Final: [1, 2, 3, 4, 5, 6]
Total comparisons: 15, Total shifts: 8
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Insertion sort is particularly effective in these scenarios:
        </p>
        
        <ul>
            <li><strong>Small Datasets:</strong> Excellent performance for arrays with < 50 elements</li>
            <li><strong>Nearly Sorted Data:</strong> Linear time performance on mostly sorted arrays</li>
            <li><strong>Online Algorithms:</strong> Can sort data as it arrives (streaming)</li>
            <li><strong>Hybrid Sorting:</strong> Used as subroutine in advanced algorithms (Timsort, Introsort)</li>
            <li><strong>Linked Lists:</strong> Natural fit for linked list data structures</li>
            <li><strong>Stable Sorting:</strong> When maintaining relative order is important</li>
            <li><strong>Memory-Constrained Systems:</strong> Minimal memory overhead</li>
        </ul>
        
        <h2 class="section-title">Optimizations and Variations</h2>
        
        <h3>1. Binary Insertion Sort</h3>
        <div class="code-block">
// Use binary search to find insertion position
void binaryInsertionSort(vector<int>& arr) {
    for (int i = 1; i < arr.size(); i++) {
        int key = arr[i];
        
        // Binary search for insertion position
        int left = 0, right = i;
        while (left < right) {
            int mid = left + (right - left) / 2;
            if (arr[mid] > key) {
                right = mid;
            } else {
                left = mid + 1;
            }
        }
        
        // Shift and insert
        for (int j = i - 1; j >= left; j--) {
            arr[j + 1] = arr[j];
        }
        arr[left] = key;
    }
}
        </div>
        
        <h3>2. Insertion Sort with Sentinel</h3>
        <div class="code-block">
// Eliminate boundary checking using sentinel
void insertionSortWithSentinel(vector<int>& arr) {
    // Place minimum element at beginning as sentinel
    int minIndex = min_element(arr.begin(), arr.end()) - arr.begin();
    swap(arr[0], arr[minIndex]);
    
    // Sort without boundary checking
    for (int i = 2; i < arr.size(); i++) {
        int key = arr[i];
        int j = i - 1;
        
        while (arr[j] > key) {  // No need to check j >= 0
            arr[j + 1] = arr[j];
            j--;
        }
        arr[j + 1] = key;
    }
}
        </div>
        
        <h3>3. Shell Sort (Gap-based Insertion Sort)</h3>
        <div class="code-block">
// Insertion sort with decreasing gap sizes
void shellSort(vector<int>& arr) {
    int n = arr.size();
    
    // Start with large gap, reduce by half each time
    for (int gap = n / 2; gap > 0; gap /= 2) {
        for (int i = gap; i < n; i++) {
            int key = arr[i];
            int j = i;
            
            while (j >= gap && arr[j - gap] > key) {
                arr[j] = arr[j - gap];
                j -= gap;
            }
            arr[j] = key;
        }
    }
}
        </div>
        
        <h2 class="section-title">When to Use Insertion Sort</h2>
        
        <div class="definition-box">
            <strong>Use Insertion Sort When:</strong><br>
            • Dataset is small (< 50 elements)<br>
            • Data is already nearly sorted<br>
            • You need a stable sorting algorithm<br>
            • Sorting data as it arrives (online algorithm)<br>
            • Memory usage must be minimal<br>
            • Simplicity and readability are important<br>
            • As part of hybrid sorting algorithms<br><br>
            
            <strong>Don't Use Insertion Sort When:</strong><br>
            • Dataset is large (> 100 elements)<br>
            • Data is in random or reverse order<br>
            • Performance is critical for large inputs<br>
            • You need guaranteed O(n log n) performance
        </div>
        
        <h2 class="section-title">Comparison with Other Algorithms</h2>
        
        <div class="code-block">
Performance Comparison on Different Data Patterns:

Random Data (n=1000):
- Insertion Sort: ~125,000 comparisons
- Selection Sort: ~500,000 comparisons  
- Bubble Sort: ~250,000 comparisons

Nearly Sorted Data (n=1000, 90% sorted):
- Insertion Sort: ~5,000 comparisons (excellent!)
- Selection Sort: ~500,000 comparisons (no improvement)
- Bubble Sort: ~50,000 comparisons (some improvement)

Reverse Sorted Data (n=1000):
- Insertion Sort: ~500,000 comparisons (worst case)
- Selection Sort: ~500,000 comparisons (same as always)
- Bubble Sort: ~500,000 comparisons (worst case)
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Starting from Wrong Index:</strong> Remember to start from index 1, not 0</li>
            <li><strong>Boundary Conditions:</strong> Check j >= 0 in the while loop</li>
            <li><strong>Key Assignment:</strong> Don't forget to assign arr[j+1] = key after the loop</li>
            <li><strong>Using on Large Data:</strong> Avoid for datasets larger than 100 elements</li>
            <li><strong>Not Leveraging Adaptivity:</strong> Use for nearly sorted data where it excels</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Adaptive Nature:</strong> Emphasize O(n) performance on nearly sorted data</li>
            <li><strong>Stability:</strong> Highlight that it maintains relative order of equal elements</li>
            <li><strong>Online Algorithm:</strong> Can process elements as they arrive</li>
            <li><strong>Practical Usage:</strong> Mention its use in hybrid algorithms like Timsort</li>
            <li><strong>Binary Optimization:</strong> Discuss binary insertion sort for reducing comparisons</li>
            <li><strong>Real-world Analogy:</strong> Compare to sorting playing cards in hand</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Insertion sort is adaptive with O(n) best case and O(n²) worst case</li>
                <li>Excellent performance on small and nearly sorted datasets</li>
                <li>Stable, in-place, and online sorting algorithm</li>
                <li>Used as building block in advanced hybrid sorting algorithms</li>
                <li>Binary insertion sort reduces comparisons but not shifts</li>
                <li>Shell sort extends insertion sort with gap sequences for better performance</li>
                <li>Natural choice for sorting linked lists and streaming data</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch11">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 11</div>
        <h1 class="chapter-title">Merge Sort</h1>
        
        <p class="academic-text">
            Merge sort is a divide-and-conquer algorithm that divides the array into two halves, recursively sorts them, and then merges the sorted halves. It's one of the most efficient stable sorting algorithms with guaranteed O(n log n) time complexity, making it ideal for large datasets and external sorting scenarios.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given an array of n elements, sort the array in ascending order using the merge sort algorithm. The algorithm should divide the problem into smaller subproblems, solve them recursively, and combine the results.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Array arr[] of size n with comparable elements<br>
            <strong>Output:</strong> Same array sorted in ascending order<br>
            <strong>Stability:</strong> Stable sorting algorithm (maintains relative order of equal elements)
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Merge sort follows the divide-and-conquer paradigm:
        </p>
        
        <ol>
            <li><strong>Divide:</strong> Split the array into two halves</li>
            <li><strong>Conquer:</strong> Recursively sort both halves</li>
            <li><strong>Combine:</strong> Merge the two sorted halves into a single sorted array</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: MergeSort(arr, left, right)
1. if left < right then
2.     mid = (left + right) / 2
3.     MergeSort(arr, left, mid)
4.     MergeSort(arr, mid+1, right)
5.     Merge(arr, left, mid, right)
6. end if

Algorithm: Merge(arr, left, mid, right)
1. Create temporary arrays L[] and R[]
2. Copy data to temp arrays
3. i = 0, j = 0, k = left
4. while i < n1 AND j < n2 do
5.     if L[i] <= R[j] then
6.         arr[k] = L[i]; i++
7.     else
8.         arr[k] = R[j]; j++
9.     end if
10.    k++
11. end while
12. Copy remaining elements
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
using namespace std;

/**
 * Merge function - combines two sorted subarrays
 * Merges arr[left..mid] and arr[mid+1..right]
 */
void merge(vector<int>& arr, int left, int mid, int right) {
    // Calculate sizes of two subarrays
    int n1 = mid - left + 1;
    int n2 = right - mid;
    
    // Create temporary arrays
    vector<int> leftArr(n1), rightArr(n2);
    
    // Copy data to temporary arrays
    for (int i = 0; i < n1; i++)
        leftArr[i] = arr[left + i];
    for (int j = 0; j < n2; j++)
        rightArr[j] = arr[mid + 1 + j];
    
    // Merge the temporary arrays back into arr[left..right]
    int i = 0, j = 0, k = left;
    
    while (i < n1 && j < n2) {
        if (leftArr[i] <= rightArr[j]) {
            arr[k] = leftArr[i];
            i++;
        } else {
            arr[k] = rightArr[j];
            j++;
        }
        k++;
    }
    
    // Copy remaining elements of leftArr[], if any
    while (i < n1) {
        arr[k] = leftArr[i];
        i++;
        k++;
    }
    
    // Copy remaining elements of rightArr[], if any
    while (j < n2) {
        arr[k] = rightArr[j];
        j++;
        k++;
    }
}

/**
 * Merge Sort - Main function
 * Recursively sorts array using divide and conquer
 */
void mergeSort(vector<int>& arr, int left, int right) {
    if (left < right) {
        // Find the middle point
        int mid = left + (right - left) / 2;
        
        // Sort first and second halves
        mergeSort(arr, left, mid);
        mergeSort(arr, mid + 1, right);
        
        // Merge the sorted halves
        merge(arr, left, mid, right);
    }
}

/**
 * Merge Sort with Statistics
 * Tracks recursive calls and merge operations
 */
struct MergeSortStats {
    int recursiveCalls;
    int mergeOperations;
    int comparisons;
    int arrayAccesses;
    vector<vector<int>> stateHistory;
};

MergeSortStats mergeSortWithStats(vector<int>& arr, int left, int right, MergeSortStats& stats) {
    stats.recursiveCalls++;
    
    if (left < right) {
        int mid = left + (right - left) / 2;
        
        mergeSortWithStats(arr, left, mid, stats);
        mergeSortWithStats(arr, mid + 1, right, stats);
        
        // Merge with statistics
        stats.mergeOperations++;
        int n1 = mid - left + 1;
        int n2 = right - mid;
        
        vector<int> leftArr(n1), rightArr(n2);
        
        for (int i = 0; i < n1; i++) {
            leftArr[i] = arr[left + i];
            stats.arrayAccesses++;
        }
        for (int j = 0; j < n2; j++) {
            rightArr[j] = arr[mid + 1 + j];
            stats.arrayAccesses++;
        }
        
        int i = 0, j = 0, k = left;
        while (i < n1 && j < n2) {
            stats.comparisons++;
            if (leftArr[i] <= rightArr[j]) {
                arr[k] = leftArr[i];
                i++;
            } else {
                arr[k] = rightArr[j];
                j++;
            }
            k++;
            stats.arrayAccesses++;
        }
        
        while (i < n1) {
            arr[k] = leftArr[i];
            i++; k++;
            stats.arrayAccesses++;
        }
        while (j < n2) {
            arr[k] = rightArr[j];
            j++; k++;
            stats.arrayAccesses++;
        }
        
        stats.stateHistory.push_back(arr);
    }
    
    return stats;
}

/**
 * Iterative Merge Sort
 * Bottom-up approach without recursion
 */
void iterativeMergeSort(vector<int>& arr) {
    int n = arr.size();
    
    // Merge subarrays in bottom-up manner
    for (int currSize = 1; currSize <= n - 1; currSize = 2 * currSize) {
        // Pick starting point of left sub array
        for (int leftStart = 0; leftStart < n - 1; leftStart += 2 * currSize) {
            // Calculate mid and right points
            int mid = min(leftStart + currSize - 1, n - 1);
            int rightEnd = min(leftStart + 2 * currSize - 1, n - 1);
            
            // Merge subarrays if mid is smaller than rightEnd
            if (mid < rightEnd) {
                merge(arr, leftStart, mid, rightEnd);
            }
        }
    }
}

/**
 * In-place Merge Sort
 * Reduces space complexity using in-place merging
 */
void inPlaceMerge(vector<int>& arr, int start, int mid, int end) {
    int start2 = mid + 1;
    
    // If the direct merge is already sorted
    if (arr[mid] <= arr[start2]) {
        return;
    }
    
    // Two pointers to maintain start of both arrays to merge
    while (start <= mid && start2 <= end) {
        // If element 1 is in right place
        if (arr[start] <= arr[start2]) {
            start++;
        } else {
            int value = arr[start2];
            int index = start2;
            
            // Shift all elements between element 1 and element 2, right by 1
            while (index != start) {
                arr[index] = arr[index - 1];
                index--;
            }
            arr[start] = value;
            
            // Update all the pointers
            start++;
            mid++;
            start2++;
        }
    }
}

void inPlaceMergeSort(vector<int>& arr, int left, int right) {
    if (left < right) {
        int mid = left + (right - left) / 2;
        
        inPlaceMergeSort(arr, left, mid);
        inPlaceMergeSort(arr, mid + 1, right);
        
        inPlaceMerge(arr, left, mid, right);
    }
}

// Example usage and testing
int main() {
    // Test basic merge sort
    vector<int> arr1 = {12, 11, 13, 5, 6, 7};
    cout << "=== Basic Merge Sort ===" << endl;
    cout << "Original: [";
    for (int i = 0; i < arr1.size(); i++) {
        cout << arr1[i];
        if (i < arr1.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    mergeSort(arr1, 0, arr1.size() - 1);
    
    cout << "Sorted: [";
    for (int i = 0; i < arr1.size(); i++) {
        cout << arr1[i];
        if (i < arr1.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    // Test merge sort with statistics
    vector<int> arr2 = {38, 27, 43, 3, 9, 82, 10};
    cout << "\n=== Merge Sort with Statistics ===" << endl;
    cout << "Original: [";
    for (int i = 0; i < arr2.size(); i++) {
        cout << arr2[i];
        if (i < arr2.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    MergeSortStats stats = {0, 0, 0, 0, {}};
    mergeSortWithStats(arr2, 0, arr2.size() - 1, stats);
    
    cout << "Sorted: [";
    for (int i = 0; i < arr2.size(); i++) {
        cout << arr2[i];
        if (i < arr2.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    cout << "Statistics:" << endl;
    cout << "  Recursive calls: " << stats.recursiveCalls << endl;
    cout << "  Merge operations: " << stats.mergeOperations << endl;
    cout << "  Comparisons: " << stats.comparisons << endl;
    cout << "  Array accesses: " << stats.arrayAccesses << endl;
    
    // Test iterative merge sort
    vector<int> arr3 = {64, 34, 25, 12, 22, 11, 90};
    cout << "\n=== Iterative Merge Sort ===" << endl;
    cout << "Original: [";
    for (int i = 0; i < arr3.size(); i++) {
        cout << arr3[i];
        if (i < arr3.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    iterativeMergeSort(arr3);
    
    cout << "Sorted: [";
    for (int i = 0; i < arr3.size(); i++) {
        cout << arr3[i];
        if (i < arr3.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(n log n) - Always divides and merges</li>
                <li><strong>Average Case:</strong> O(n log n) - Consistent performance</li>
                <li><strong>Worst Case:</strong> O(n log n) - Guaranteed performance</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(n) - Temporary arrays for merging</li>
                <li><strong>Recursion Stack:</strong> O(log n) - Due to recursive calls</li>
                <li><strong>Total Space:</strong> O(n) - Dominated by auxiliary space</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Stable:</strong> Yes - Equal elements maintain their relative order</li>
                <li><strong>Adaptive:</strong> No - Always performs the same number of operations</li>
                <li><strong>External Sorting:</strong> Yes - Excellent for sorting large files</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through merge sort on array [38, 27, 43, 3]:
        </p>
        
        <div class="code-block">
Initial: [38, 27, 43, 3]

Step 1: Divide
[38, 27, 43, 3] → [38, 27] and [43, 3]

Step 2: Divide further
[38, 27] → [38] and [27]
[43, 3] → [43] and [3]

Step 3: Merge [38] and [27]
Compare 38 and 27: 27 < 38
Result: [27, 38]

Step 4: Merge [43] and [3]
Compare 43 and 3: 3 < 43
Result: [3, 43]

Step 5: Merge [27, 38] and [3, 43]
Compare 27 and 3: 3 < 27 → [3, ...]
Compare 27 and 43: 27 < 43 → [3, 27, ...]
Compare 38 and 43: 38 < 43 → [3, 27, 38, ...]
Remaining: 43 → [3, 27, 38, 43]

Final: [3, 27, 38, 43]
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Merge sort is particularly useful in these scenarios:
        </p>
        
        <ul>
            <li><strong>Large Datasets:</strong> Guaranteed O(n log n) performance</li>
            <li><strong>External Sorting:</strong> Sorting data that doesn't fit in memory</li>
            <li><strong>Stable Sorting:</strong> When relative order of equal elements matters</li>
            <li><strong>Linked Lists:</strong> Natural fit for linked list sorting</li>
            <li><strong>Parallel Processing:</strong> Can be easily parallelized</li>
            <li><strong>Database Systems:</strong> Used in database sorting operations</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Guaranteed Performance:</strong> Always O(n log n), never degrades</li>
            <li><strong>Stability:</strong> Maintains relative order of equal elements</li>
            <li><strong>Divide and Conquer:</strong> Classic example of the paradigm</li>
            <li><strong>Space Trade-off:</strong> Uses O(n) extra space for guaranteed performance</li>
            <li><strong>External Sorting:</strong> Excellent for sorting large files</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Merge sort guarantees O(n log n) time complexity in all cases</li>
                <li>Stable sorting algorithm that preserves relative order</li>
                <li>Uses O(n) auxiliary space for temporary arrays</li>
                <li>Excellent for external sorting and large datasets</li>
                <li>Can be implemented both recursively and iteratively</li>
                <li>Foundation for many advanced sorting algorithms</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch12">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 12</div>
        <h1 class="chapter-title">Quick Sort</h1>
        
        <p class="academic-text">
            Quick sort is a highly efficient divide-and-conquer sorting algorithm that works by selecting a 'pivot' element and partitioning the array around it. Elements smaller than the pivot go to the left, larger elements go to the right, and the process is recursively applied to the subarrays. Despite having O(n²) worst-case complexity, its average-case O(n log n) performance and in-place nature make it one of the most popular sorting algorithms.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given an array of n elements, sort the array in ascending order using the quick sort algorithm. The algorithm should partition the array around a pivot element and recursively sort the resulting subarrays.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Array arr[] of size n with comparable elements<br>
            <strong>Output:</strong> Same array sorted in ascending order<br>
            <strong>Stability:</strong> Not stable (can change relative order of equal elements)
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Quick sort follows the divide-and-conquer paradigm:
        </p>
        
        <ol>
            <li><strong>Choose Pivot:</strong> Select an element as the pivot</li>
            <li><strong>Partition:</strong> Rearrange array so elements smaller than pivot are on left, larger on right</li>
            <li><strong>Recursively Sort:</strong> Apply quick sort to left and right subarrays</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: QuickSort(arr, low, high)
1. if low < high then
2.     pivotIndex = Partition(arr, low, high)
3.     QuickSort(arr, low, pivotIndex - 1)
4.     QuickSort(arr, pivotIndex + 1, high)
5. end if

Algorithm: Partition(arr, low, high)
1. pivot = arr[high]  // Choose last element as pivot
2. i = low - 1        // Index of smaller element
3. for j = low to high-1 do
4.     if arr[j] <= pivot then
5.         i++
6.         swap(arr[i], arr[j])
7.     end if
8. end for
9. swap(arr[i+1], arr[high])
10. return i + 1
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
#include <random>
using namespace std;

/**
 * Partition function - Lomuto partition scheme
 * Places pivot in correct position and partitions array
 */
int partition(vector<int>& arr, int low, int high) {
    // Choose the rightmost element as pivot
    int pivot = arr[high];
    
    // Index of smaller element (indicates right position of pivot)
    int i = low - 1;
    
    for (int j = low; j <= high - 1; j++) {
        // If current element is smaller than or equal to pivot
        if (arr[j] <= pivot) {
            i++;
            swap(arr[i], arr[j]);
        }
    }
    
    // Place pivot in correct position
    swap(arr[i + 1], arr[high]);
    return i + 1;
}

/**
 * Quick Sort - Main recursive function
 */
void quickSort(vector<int>& arr, int low, int high) {
    if (low < high) {
        // Partition the array and get pivot index
        int pivotIndex = partition(arr, low, high);
        
        // Recursively sort elements before and after partition
        quickSort(arr, low, pivotIndex - 1);
        quickSort(arr, pivotIndex + 1, high);
    }
}

/**
 * Hoare Partition Scheme
 * Alternative partitioning method
 */
int hoarePartition(vector<int>& arr, int low, int high) {
    int pivot = arr[low];  // Choose first element as pivot
    int i = low - 1;
    int j = high + 1;
    
    while (true) {
        // Find element on left that should be on right
        do {
            i++;
        } while (arr[i] < pivot);
        
        // Find element on right that should be on left
        do {
            j--;
        } while (arr[j] > pivot);
        
        // If elements crossed, partitioning is done
        if (i >= j) {
            return j;
        }
        
        swap(arr[i], arr[j]);
    }
}

/**
 * Quick Sort with Hoare Partition
 */
void quickSortHoare(vector<int>& arr, int low, int high) {
    if (low < high) {
        int pivotIndex = hoarePartition(arr, low, high);
        quickSortHoare(arr, low, pivotIndex);
        quickSortHoare(arr, pivotIndex + 1, high);
    }
}

/**
 * Randomized Quick Sort
 * Chooses random pivot to avoid worst-case scenarios
 */
int randomizedPartition(vector<int>& arr, int low, int high) {
    // Generate random index between low and high
    random_device rd;
    mt19937 gen(rd());
    uniform_int_distribution<> dis(low, high);
    int randomIndex = dis(gen);
    
    // Swap random element with last element
    swap(arr[randomIndex], arr[high]);
    
    // Use standard partition
    return partition(arr, low, high);
}

void randomizedQuickSort(vector<int>& arr, int low, int high) {
    if (low < high) {
        int pivotIndex = randomizedPartition(arr, low, high);
        randomizedQuickSort(arr, low, pivotIndex - 1);
        randomizedQuickSort(arr, pivotIndex + 1, high);
    }
}

/**
 * Three-Way Quick Sort (Dutch National Flag)
 * Handles duplicate elements efficiently
 */
void threeWayQuickSort(vector<int>& arr, int low, int high) {
    if (low >= high) return;
    
    int pivot = arr[low];
    int lt = low;      // arr[low..lt-1] < pivot
    int gt = high;     // arr[gt+1..high] > pivot
    int i = low;       // arr[lt..i-1] == pivot
    
    while (i <= gt) {
        if (arr[i] < pivot) {
            swap(arr[lt++], arr[i++]);
        } else if (arr[i] > pivot) {
            swap(arr[i], arr[gt--]);
        } else {
            i++;
        }
    }
    
    // Recursively sort the parts
    threeWayQuickSort(arr, low, lt - 1);
    threeWayQuickSort(arr, gt + 1, high);
}

/**
 * Iterative Quick Sort
 * Uses explicit stack instead of recursion
 */
void iterativeQuickSort(vector<int>& arr, int low, int high) {
    // Create auxiliary stack
    vector<int> stack(high - low + 1);
    int top = -1;
    
    // Push initial values
    stack[++top] = low;
    stack[++top] = high;
    
    while (top >= 0) {
        // Pop high and low
        high = stack[top--];
        low = stack[top--];
        
        // Set pivot element at its correct position
        int pivotIndex = partition(arr, low, high);
        
        // If there are elements on left side of pivot, push left side to stack
        if (pivotIndex - 1 > low) {
            stack[++top] = low;
            stack[++top] = pivotIndex - 1;
        }
        
        // If there are elements on right side of pivot, push right side to stack
        if (pivotIndex + 1 < high) {
            stack[++top] = pivotIndex + 1;
            stack[++top] = high;
        }
    }
}

/**
 * Quick Sort with Statistics
 * Tracks recursive calls, comparisons, and swaps
 */
struct QuickSortStats {
    int recursiveCalls;
    int comparisons;
    int swaps;
    int partitionCalls;
    vector<int> pivotChoices;
};

int partitionWithStats(vector<int>& arr, int low, int high, QuickSortStats& stats) {
    stats.partitionCalls++;
    int pivot = arr[high];
    stats.pivotChoices.push_back(pivot);
    
    int i = low - 1;
    
    for (int j = low; j <= high - 1; j++) {
        stats.comparisons++;
        if (arr[j] <= pivot) {
            i++;
            if (i != j) {
                swap(arr[i], arr[j]);
                stats.swaps++;
            }
        }
    }
    
    if (i + 1 != high) {
        swap(arr[i + 1], arr[high]);
        stats.swaps++;
    }
    
    return i + 1;
}

void quickSortWithStats(vector<int>& arr, int low, int high, QuickSortStats& stats) {
    stats.recursiveCalls++;
    
    if (low < high) {
        int pivotIndex = partitionWithStats(arr, low, high, stats);
        quickSortWithStats(arr, low, pivotIndex - 1, stats);
        quickSortWithStats(arr, pivotIndex + 1, high, stats);
    }
}

/**
 * Hybrid Quick Sort
 * Switches to insertion sort for small subarrays
 */
void insertionSort(vector<int>& arr, int low, int high) {
    for (int i = low + 1; i <= high; i++) {
        int key = arr[i];
        int j = i - 1;
        
        while (j >= low && arr[j] > key) {
            arr[j + 1] = arr[j];
            j--;
        }
        arr[j + 1] = key;
    }
}

void hybridQuickSort(vector<int>& arr, int low, int high, int threshold = 10) {
    if (low < high) {
        // Use insertion sort for small subarrays
        if (high - low + 1 < threshold) {
            insertionSort(arr, low, high);
        } else {
            int pivotIndex = partition(arr, low, high);
            hybridQuickSort(arr, low, pivotIndex - 1, threshold);
            hybridQuickSort(arr, pivotIndex + 1, high, threshold);
        }
    }
}

// Utility functions
void printArray(const vector<int>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << arr[i];
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

// Example usage and testing
int main() {
    // Test basic quick sort
    vector<int> arr1 = {10, 7, 8, 9, 1, 5};
    cout << "=== Basic Quick Sort ===" << endl;
    printArray(arr1, "Original");
    
    quickSort(arr1, 0, arr1.size() - 1);
    printArray(arr1, "Sorted");
    
    // Test quick sort with statistics
    vector<int> arr2 = {64, 34, 25, 12, 22, 11, 90};
    cout << "\n=== Quick Sort with Statistics ===" << endl;
    printArray(arr2, "Original");
    
    QuickSortStats stats = {0, 0, 0, 0, {}};
    quickSortWithStats(arr2, 0, arr2.size() - 1, stats);
    printArray(arr2, "Sorted");
    
    cout << "Statistics:" << endl;
    cout << "  Recursive calls: " << stats.recursiveCalls << endl;
    cout << "  Partition calls: " << stats.partitionCalls << endl;
    cout << "  Comparisons: " << stats.comparisons << endl;
    cout << "  Swaps: " << stats.swaps << endl;
    cout << "  Pivot choices: ";
    for (int pivot : stats.pivotChoices) {
        cout << pivot << " ";
    }
    cout << endl;
    
    // Test randomized quick sort
    vector<int> arr3 = {3, 6, 8, 10, 1, 2, 1};
    cout << "\n=== Randomized Quick Sort ===" << endl;
    printArray(arr3, "Original");
    
    randomizedQuickSort(arr3, 0, arr3.size() - 1);
    printArray(arr3, "Sorted");
    
    // Test three-way quick sort
    vector<int> arr4 = {4, 9, 4, 4, 1, 9, 4, 4, 9, 4, 4, 1, 4};
    cout << "\n=== Three-Way Quick Sort (with duplicates) ===" << endl;
    printArray(arr4, "Original");
    
    threeWayQuickSort(arr4, 0, arr4.size() - 1);
    printArray(arr4, "Sorted");
    
    // Test iterative quick sort
    vector<int> arr5 = {4, 3, 2, 1, 5, 6, 7, 8};
    cout << "\n=== Iterative Quick Sort ===" << endl;
    printArray(arr5, "Original");
    
    iterativeQuickSort(arr5, 0, arr5.size() - 1);
    printArray(arr5, "Sorted");
    
    // Test hybrid quick sort
    vector<int> arr6 = {9, 8, 7, 6, 5, 4, 3, 2, 1, 0};
    cout << "\n=== Hybrid Quick Sort ===" << endl;
    printArray(arr6, "Original");
    
    hybridQuickSort(arr6, 0, arr6.size() - 1);
    printArray(arr6, "Sorted");
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(n log n) - Pivot divides array into equal halves</li>
                <li><strong>Average Case:</strong> O(n log n) - Random pivot selection</li>
                <li><strong>Worst Case:</strong> O(n²) - Pivot is always smallest or largest element</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(log n) - Balanced recursion tree</li>
                <li><strong>Average Case:</strong> O(log n) - Expected recursion depth</li>
                <li><strong>Worst Case:</strong> O(n) - Unbalanced recursion (degenerates to linear)</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Stable:</strong> No - Can change relative order of equal elements</li>
                <li><strong>In-place:</strong> Yes - Sorts with O(log n) extra space</li>
                <li><strong>Adaptive:</strong> No - Performance doesn't improve on partially sorted data</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through quick sort on array [10, 7, 8, 9, 1, 5]:
        </p>
        
        <div class="code-block">
Initial: [10, 7, 8, 9, 1, 5]

Step 1: Partition with pivot = 5 (last element)
Compare: 10 > 5, 7 > 5, 8 > 5, 9 > 5, 1 ≤ 5
Move 1 to left: [1, 7, 8, 9, 10, 5]
Place pivot: [1, 5, 8, 9, 10, 7]
Pivot index: 1

Step 2: Recursively sort left subarray [1]
Single element, already sorted

Step 3: Recursively sort right subarray [8, 9, 10, 7]
Partition with pivot = 7:
Compare: 8 > 7, 9 > 7, 10 > 7
No elements ≤ 7, place pivot: [7, 9, 10, 8]
Pivot index: 0 (relative to subarray)

Step 4: Sort subarray [9, 10, 8]
Partition with pivot = 8:
Compare: 9 > 8, 10 > 8
Place pivot: [8, 10, 9]
Pivot index: 0

Step 5: Sort subarray [10, 9]
Partition with pivot = 9:
Compare: 10 > 9
Place pivot: [9, 10]

Final result: [1, 5, 7, 8, 9, 10]
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Quick sort is widely used in various scenarios:
        </p>
        
        <ul>
            <li><strong>General Purpose Sorting:</strong> Default sorting algorithm in many libraries</li>
            <li><strong>System Programming:</strong> Used in operating systems and compilers</li>
            <li><strong>Database Systems:</strong> Internal sorting in database engines</li>
            <li><strong>Selection Algorithms:</strong> Finding kth smallest/largest element</li>
            <li><strong>Hybrid Algorithms:</strong> Combined with other sorts (Introsort)</li>
            <li><strong>Parallel Processing:</strong> Can be easily parallelized</li>
        </ul>
        
        <h2 class="section-title">Optimizations and Variations</h2>
        
        <h3>1. Median-of-Three Pivot Selection</h3>
        <div class="code-block">
int medianOfThree(vector<int>& arr, int low, int high) {
    int mid = low + (high - low) / 2;
    
    if (arr[mid] < arr[low]) swap(arr[low], arr[mid]);
    if (arr[high] < arr[low]) swap(arr[low], arr[high]);
    if (arr[high] < arr[mid]) swap(arr[mid], arr[high]);
    
    // Place median at end for standard partition
    swap(arr[mid], arr[high]);
    return partition(arr, low, high);
}
        </div>
        
        <h3>2. Tail Recursion Optimization</h3>
        <div class="code-block">
void tailRecursiveQuickSort(vector<int>& arr, int low, int high) {
    while (low < high) {
        int pivotIndex = partition(arr, low, high);
        
        // Recur for smaller partition to limit stack depth
        if (pivotIndex - low < high - pivotIndex) {
            tailRecursiveQuickSort(arr, low, pivotIndex - 1);
            low = pivotIndex + 1;
        } else {
            tailRecursiveQuickSort(arr, pivotIndex + 1, high);
            high = pivotIndex - 1;
        }
    }
}
        </div>
        
        <h2 class="section-title">When to Use Quick Sort</h2>
        
        <div class="definition-box">
            <strong>Use Quick Sort When:</strong><br>
            • Average-case performance is more important than worst-case<br>
            • Memory usage should be minimal (in-place sorting)<br>
            • You can use randomization to avoid worst-case scenarios<br>
            • Working with general-purpose sorting requirements<br>
            • Cache performance is important<br><br>
            
            <strong>Don't Use Quick Sort When:</strong><br>
            • Worst-case performance guarantees are required<br>
            • Stability is needed (use merge sort instead)<br>
            • Working with already sorted or reverse sorted data frequently<br>
            • Stack overflow is a concern (use iterative version)
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Worst-Case Input:</strong> Already sorted arrays can cause O(n²) performance</li>
            <li><strong>Stack Overflow:</strong> Deep recursion on unbalanced partitions</li>
            <li><strong>Duplicate Elements:</strong> Standard quick sort performs poorly with many duplicates</li>
            <li><strong>Pivot Selection:</strong> Poor pivot choice leads to unbalanced partitions</li>
            <li><strong>Base Case:</strong> Ensure proper termination condition (low < high)</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Average vs Worst Case:</strong> Explain O(n log n) average and O(n²) worst case</li>
            <li><strong>Pivot Selection:</strong> Discuss different strategies (random, median-of-three)</li>
            <li><strong>In-place Sorting:</strong> Highlight space efficiency compared to merge sort</li>
            <li><strong>Partitioning:</strong> Be able to implement both Lomuto and Hoare schemes</li>
            <li><strong>Optimizations:</strong> Mention hybrid approaches and three-way partitioning</li>
            <li><strong>Practical Usage:</strong> Discuss why it's popular despite worst-case complexity</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Quick sort averages O(n log n) but can degrade to O(n²) in worst case</li>
                <li>In-place sorting algorithm with O(log n) average space complexity</li>
                <li>Not stable but can be made stable with modifications</li>
                <li>Randomization helps avoid worst-case scenarios</li>
                <li>Three-way partitioning handles duplicate elements efficiently</li>
                <li>Forms the basis for many hybrid sorting algorithms</li>
                <li>Excellent cache performance due to in-place nature</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch13">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 13</div>
        <h1 class="chapter-title">Heap Sort</h1>
        
        <p class="academic-text">
            Heap sort is a comparison-based sorting algorithm that uses a binary heap data structure. It combines the better attributes of merge sort and insertion sort: like merge sort, it has O(n log n) time complexity, and like insertion sort, it sorts in-place with O(1) auxiliary space. The algorithm works by building a max heap from the input data, then repeatedly extracting the maximum element and placing it at the end of the sorted portion.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given an array of n elements, sort the array in ascending order using the heap sort algorithm. The algorithm should build a heap from the array and repeatedly extract elements to create a sorted sequence.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Array arr[] of size n with comparable elements<br>
            <strong>Output:</strong> Same array sorted in ascending order<br>
            <strong>Stability:</strong> Not stable (can change relative order of equal elements)
        </div>
        
        <h2 class="section-title">Heap Properties</h2>
        
        <p class="academic-text">
            A binary heap is a complete binary tree with the heap property:
        </p>
        
        <ul>
            <li><strong>Max Heap:</strong> Parent ≥ Children (root contains maximum element)</li>
            <li><strong>Min Heap:</strong> Parent ≤ Children (root contains minimum element)</li>
            <li><strong>Complete Tree:</strong> All levels filled except possibly the last, filled left to right</li>
            <li><strong>Array Representation:</strong> For node at index i, left child at 2i+1, right child at 2i+2, parent at (i-1)/2</li>
        </ul>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: HeapSort(arr, n)
1. // Build max heap from array
2. for i = n/2 - 1 down to 0 do
3.     Heapify(arr, n, i)
4. end for
5. 
6. // Extract elements from heap one by one
7. for i = n-1 down to 1 do
8.     swap(arr[0], arr[i])  // Move current root to end
9.     Heapify(arr, i, 0)    // Restore heap property
10. end for

Algorithm: Heapify(arr, n, i)
1. largest = i
2. left = 2*i + 1
3. right = 2*i + 2
4. 
5. if left < n AND arr[left] > arr[largest] then
6.     largest = left
7. end if
8. if right < n AND arr[right] > arr[largest] then
9.     largest = right
10. end if
11. if largest != i then
12.     swap(arr[i], arr[largest])
13.     Heapify(arr, n, largest)
14. end if
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
using namespace std;

/**
 * Heapify function - maintains heap property
 * Assumes subtrees are already heaps, fixes violation at root
 * 
 * @param arr: array representing the heap
 * @param n: size of heap
 * @param i: index of root of subtree to heapify
 */
void heapify(vector<int>& arr, int n, int i) {
    int largest = i;        // Initialize largest as root
    int left = 2 * i + 1;   // Left child
    int right = 2 * i + 2;  // Right child
    
    // If left child is larger than root
    if (left < n && arr[left] > arr[largest]) {
        largest = left;
    }
    
    // If right child is larger than largest so far
    if (right < n && arr[right] > arr[largest]) {
        largest = right;
    }
    
    // If largest is not root
    if (largest != i) {
        swap(arr[i], arr[largest]);
        
        // Recursively heapify the affected subtree
        heapify(arr, n, largest);
    }
}

/**
 * Heap Sort - Main function
 * Builds max heap then repeatedly extracts maximum
 */
void heapSort(vector<int>& arr) {
    int n = arr.size();
    
    // Build max heap (rearrange array)
    // Start from last non-leaf node and heapify each node
    for (int i = n / 2 - 1; i >= 0; i--) {
        heapify(arr, n, i);
    }
    
    // Extract elements from heap one by one
    for (int i = n - 1; i > 0; i--) {
        // Move current root to end
        swap(arr[0], arr[i]);
        
        // Call heapify on the reduced heap
        heapify(arr, i, 0);
    }
}

/**
 * Iterative Heapify
 * Non-recursive version to avoid stack overflow
 */
void iterativeHeapify(vector<int>& arr, int n, int i) {
    while (true) {
        int largest = i;
        int left = 2 * i + 1;
        int right = 2 * i + 2;
        
        if (left < n && arr[left] > arr[largest]) {
            largest = left;
        }
        
        if (right < n && arr[right] > arr[largest]) {
            largest = right;
        }
        
        if (largest == i) {
            break;  // Heap property satisfied
        }
        
        swap(arr[i], arr[largest]);
        i = largest;  // Move down the tree
    }
}

/**
 * Heap Sort with Statistics
 * Tracks comparisons, swaps, and heapify operations
 */
struct HeapSortStats {
    int comparisons;
    int swaps;
    int heapifyOperations;
    vector<vector<int>> stateHistory;
};

void heapifyWithStats(vector<int>& arr, int n, int i, HeapSortStats& stats) {
    stats.heapifyOperations++;
    int largest = i;
    int left = 2 * i + 1;
    int right = 2 * i + 2;
    
    if (left < n) {
        stats.comparisons++;
        if (arr[left] > arr[largest]) {
            largest = left;
        }
    }
    
    if (right < n) {
        stats.comparisons++;
        if (arr[right] > arr[largest]) {
            largest = right;
        }
    }
    
    if (largest != i) {
        swap(arr[i], arr[largest]);
        stats.swaps++;
        heapifyWithStats(arr, n, largest, stats);
    }
}

HeapSortStats heapSortWithStats(vector<int>& arr) {
    HeapSortStats stats = {0, 0, 0, {}};
    int n = arr.size();
    
    // Save initial state
    stats.stateHistory.push_back(arr);
    
    // Build max heap
    for (int i = n / 2 - 1; i >= 0; i--) {
        heapifyWithStats(arr, n, i, stats);
    }
    
    // Save state after heap construction
    stats.stateHistory.push_back(arr);
    
    // Extract elements from heap
    for (int i = n - 1; i > 0; i--) {
        swap(arr[0], arr[i]);
        stats.swaps++;
        
        heapifyWithStats(arr, i, 0, stats);
        
        // Save state after each extraction
        stats.stateHistory.push_back(arr);
    }
    
    return stats;
}

/**
 * Min Heap Sort (for descending order)
 * Uses min heap to sort in descending order
 */
void minHeapify(vector<int>& arr, int n, int i) {
    int smallest = i;
    int left = 2 * i + 1;
    int right = 2 * i + 2;
    
    if (left < n && arr[left] < arr[smallest]) {
        smallest = left;
    }
    
    if (right < n && arr[right] < arr[smallest]) {
        smallest = right;
    }
    
    if (smallest != i) {
        swap(arr[i], arr[smallest]);
        minHeapify(arr, n, smallest);
    }
}

void minHeapSort(vector<int>& arr) {
    int n = arr.size();
    
    // Build min heap
    for (int i = n / 2 - 1; i >= 0; i--) {
        minHeapify(arr, n, i);
    }
    
    // Extract elements (results in descending order)
    for (int i = n - 1; i > 0; i--) {
        swap(arr[0], arr[i]);
        minHeapify(arr, i, 0);
    }
}

/**
 * Generic Heap Sort with Custom Comparator
 */
template<typename T, typename Compare>
void genericHeapify(vector<T>& arr, int n, int i, Compare comp) {
    int target = i;
    int left = 2 * i + 1;
    int right = 2 * i + 2;
    
    if (left < n && comp(arr[target], arr[left])) {
        target = left;
    }
    
    if (right < n && comp(arr[target], arr[right])) {
        target = right;
    }
    
    if (target != i) {
        swap(arr[i], arr[target]);
        genericHeapify(arr, n, target, comp);
    }
}

template<typename T, typename Compare>
void genericHeapSort(vector<T>& arr, Compare comp) {
    int n = arr.size();
    
    // Build heap
    for (int i = n / 2 - 1; i >= 0; i--) {
        genericHeapify(arr, n, i, comp);
    }
    
    // Extract elements
    for (int i = n - 1; i > 0; i--) {
        swap(arr[0], arr[i]);
        genericHeapify(arr, i, 0, comp);
    }
}

/**
 * Heap Sort for K Largest Elements
 * Partially sorts to find k largest elements
 */
vector<int> heapSortKLargest(vector<int>& arr, int k) {
    int n = arr.size();
    k = min(k, n);
    
    // Build max heap
    for (int i = n / 2 - 1; i >= 0; i--) {
        heapify(arr, n, i);
    }
    
    vector<int> result;
    
    // Extract k largest elements
    for (int i = 0; i < k; i++) {
        result.push_back(arr[0]);
        swap(arr[0], arr[n - 1 - i]);
        heapify(arr, n - 1 - i, 0);
    }
    
    return result;
}

/**
 * Bottom-up Heap Construction (Floyd's method)
 * More efficient heap building algorithm
 */
void floydHeapConstruction(vector<int>& arr) {
    int n = arr.size();
    
    // Start from the last non-leaf node
    for (int i = (n - 2) / 2; i >= 0; i--) {
        // Sift down
        int parent = i;
        while (2 * parent + 1 < n) {
            int child = 2 * parent + 1;
            
            // Choose larger child
            if (child + 1 < n && arr[child + 1] > arr[child]) {
                child++;
            }
            
            // If heap property satisfied, stop
            if (arr[parent] >= arr[child]) {
                break;
            }
            
            swap(arr[parent], arr[child]);
            parent = child;
        }
    }
}

// Utility functions
void printArray(const vector<int>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << arr[i];
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

void printHeapStructure(const vector<int>& arr) {
    int n = arr.size();
    cout << "Heap structure:" << endl;
    
    int level = 0;
    int levelSize = 1;
    int index = 0;
    
    while (index < n) {
        cout << "Level " << level << ": ";
        for (int i = 0; i < levelSize && index < n; i++, index++) {
            cout << arr[index] << " ";
        }
        cout << endl;
        level++;
        levelSize *= 2;
    }
}

// Example usage and testing
int main() {
    // Test basic heap sort
    vector<int> arr1 = {12, 11, 13, 5, 6, 7};
    cout << "=== Basic Heap Sort ===" << endl;
    printArray(arr1, "Original");
    
    heapSort(arr1);
    printArray(arr1, "Sorted");
    
    // Test heap sort with statistics
    vector<int> arr2 = {4, 10, 3, 5, 1};
    cout << "\n=== Heap Sort with Statistics ===" << endl;
    printArray(arr2, "Original");
    
    HeapSortStats stats = heapSortWithStats(arr2);
    printArray(arr2, "Sorted");
    
    cout << "Statistics:" << endl;
    cout << "  Comparisons: " << stats.comparisons << endl;
    cout << "  Swaps: " << stats.swaps << endl;
    cout << "  Heapify operations: " << stats.heapifyOperations << endl;
    
    cout << "  State history:" << endl;
    for (int i = 0; i < stats.stateHistory.size(); i++) {
        cout << "    Step " << i << ": ";
        printArray(stats.stateHistory[i], "");
    }
    
    // Test min heap sort (descending order)
    vector<int> arr3 = {64, 34, 25, 12, 22, 11, 90};
    cout << "\n=== Min Heap Sort (Descending) ===" << endl;
    printArray(arr3, "Original");
    
    minHeapSort(arr3);
    printArray(arr3, "Sorted (Descending)");
    
    // Test generic heap sort with strings
    vector<string> words = {"banana", "apple", "cherry", "date"};
    cout << "\n=== Generic Heap Sort (Strings) ===" << endl;
    cout << "Original: [";
    for (int i = 0; i < words.size(); i++) {
        cout << words[i];
        if (i < words.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    genericHeapSort(words, [](const string& a, const string& b) {
        return a < b;  // Max heap for ascending order
    });
    
    cout << "Sorted: [";
    for (int i = 0; i < words.size(); i++) {
        cout << words[i];
        if (i < words.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    // Test k largest elements
    vector<int> arr4 = {7, 10, 4, 3, 20, 15};
    int k = 3;
    cout << "\n=== Finding " << k << " Largest Elements ===" << endl;
    printArray(arr4, "Original");
    
    vector<int> kLargest = heapSortKLargest(arr4, k);
    cout << "3 Largest: [";
    for (int i = 0; i < kLargest.size(); i++) {
        cout << kLargest[i];
        if (i < kLargest.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    // Demonstrate heap structure
    vector<int> arr5 = {90, 15, 10, 7, 12, 2, 7, 3};
    cout << "\n=== Heap Structure Visualization ===" << endl;
    printArray(arr5, "Array");
    
    // Build max heap first
    for (int i = arr5.size() / 2 - 1; i >= 0; i--) {
        heapify(arr5, arr5.size(), i);
    }
    
    printArray(arr5, "Max Heap");
    printHeapStructure(arr5);
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(n log n) - Always builds heap and extracts elements</li>
                <li><strong>Average Case:</strong> O(n log n) - Consistent performance</li>
                <li><strong>Worst Case:</strong> O(n log n) - Guaranteed performance</li>
                <li><strong>Heap Construction:</strong> O(n) using Floyd's method</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(1) - In-place sorting</li>
                <li><strong>Recursion Stack:</strong> O(log n) - Due to heapify recursion</li>
                <li><strong>Iterative Version:</strong> O(1) - No recursion needed</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Stable:</strong> No - Can change relative order of equal elements</li>
                <li><strong>In-place:</strong> Yes - Sorts with constant extra space</li>
                <li><strong>Adaptive:</strong> No - Always performs same operations</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through heap sort on array [4, 10, 3, 5, 1]:
        </p>
        
        <div class="code-block">
Initial: [4, 10, 3, 5, 1]

Step 1: Build Max Heap
Start from last non-leaf node (index 1):
  Heapify(1): Compare 10 with children 5,1 → no change
  Heapify(0): Compare 4 with children 10,3 → swap 4,10
  Result: [10, 5, 3, 4, 1]

Max Heap Structure:
       10
      /  \
     5    3
    / \
   4   1

Step 2: Extract Elements
Extract 10: swap(arr[0], arr[4]) → [1, 5, 3, 4, 10]
Heapify(0) with size 4: [5, 4, 3, 1, 10]

Extract 5: swap(arr[0], arr[3]) → [1, 4, 3, 5, 10]
Heapify(0) with size 3: [4, 1, 3, 5, 10]

Extract 4: swap(arr[0], arr[2]) → [3, 1, 4, 5, 10]
Heapify(0) with size 2: [3, 1, 4, 5, 10]

Extract 3: swap(arr[0], arr[1]) → [1, 3, 4, 5, 10]

Final: [1, 3, 4, 5, 10]
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Heap sort is particularly useful in these scenarios:
        </p>
        
        <ul>
            <li><strong>Memory-Constrained Systems:</strong> O(1) auxiliary space requirement</li>
            <li><strong>Guaranteed Performance:</strong> Always O(n log n), never degrades</li>
            <li><strong>Priority Queues:</strong> Foundation for heap-based priority queues</li>
            <li><strong>Selection Algorithms:</strong> Finding k largest/smallest elements</li>
            <li><strong>Real-time Systems:</strong> Predictable performance characteristics</li>
            <li><strong>External Sorting:</strong> When combined with external merge techniques</li>
        </ul>
        
        <h2 class="section-title">Optimizations and Variations</h2>
        
        <h3>1. Bottom-up Heap Construction</h3>
        <div class="code-block">
// Floyd's method - O(n) heap construction
void efficientHeapBuild(vector<int>& arr) {
    int n = arr.size();
    
    // Start from last internal node
    for (int i = (n - 2) / 2; i >= 0; i--) {
        int parent = i;
        
        // Sift down without recursion
        while (2 * parent + 1 < n) {
            int child = 2 * parent + 1;
            
            if (child + 1 < n && arr[child + 1] > arr[child]) {
                child++;
            }
            
            if (arr[parent] >= arr[child]) break;
            
            swap(arr[parent], arr[child]);
            parent = child;
        }
    }
}
        </div>
        
        <h3>2. Ternary Heap Sort</h3>
        <div class="code-block">
// Uses ternary heap (3 children per node)
void ternaryHeapify(vector<int>& arr, int n, int i) {
    int largest = i;
    
    for (int child = 3 * i + 1; child <= 3 * i + 3 && child < n; child++) {
        if (arr[child] > arr[largest]) {
            largest = child;
        }
    }
    
    if (largest != i) {
        swap(arr[i], arr[largest]);
        ternaryHeapify(arr, n, largest);
    }
}
        </div>
        
        <h2 class="section-title">When to Use Heap Sort</h2>
        
        <div class="definition-box">
            <strong>Use Heap Sort When:</strong><br>
            • Memory usage must be minimal (O(1) auxiliary space)<br>
            • Guaranteed O(n log n) performance is required<br>
            • You need to find k largest/smallest elements<br>
            • Working with priority queue applications<br>
            • Stability is not required<br><br>
            
            <strong>Don't Use Heap Sort When:</strong><br>
            • Stability is required (use merge sort)<br>
            • Cache performance is critical (quick sort often better)<br>
            • Working with small datasets (insertion sort better)<br>
            • Average-case performance is more important than worst-case
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Index Calculations:</strong> Remember parent=(i-1)/2, children=2i+1, 2i+2</li>
            <li><strong>Heap Property:</strong> Ensure max heap for ascending sort, min heap for descending</li>
            <li><strong>Boundary Conditions:</strong> Check array bounds in heapify function</li>
            <li><strong>Recursion Depth:</strong> Use iterative heapify for very large arrays</li>
            <li><strong>Not Stable:</strong> Don't use when stability is required</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Guaranteed Performance:</strong> Always O(n log n), unlike quick sort</li>
            <li><strong>In-place Sorting:</strong> Uses only O(1) extra space</li>
            <li><strong>Heap Property:</strong> Explain parent-child relationship clearly</li>
            <li><strong>Two Phases:</strong> Heap construction (O(n)) + extraction (O(n log n))</li>
            <li><strong>Applications:</strong> Mention priority queues and selection algorithms</li>
            <li><strong>Comparison:</strong> Contrast with merge sort (stable, O(n) space) and quick sort (average faster)</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Heap sort guarantees O(n log n) time complexity in all cases</li>
                <li>In-place sorting algorithm with O(1) auxiliary space</li>
                <li>Not stable but has predictable performance characteristics</li>
                <li>Based on binary heap data structure with parent-child relationships</li>
                <li>Excellent for finding k largest/smallest elements</li>
                <li>Foundation for priority queue implementations</li>
                <li>Two-phase algorithm: heap construction + element extraction</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch14">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 14</div>
        <h1 class="chapter-title">Counting Sort</h1>
        
        <p class="academic-text">
            Counting sort is a non-comparison based sorting algorithm that works by counting the occurrences of each distinct element in the input array. It then uses this count information to place elements directly in their correct positions. When the range of input elements is small compared to the number of elements, counting sort achieves linear time complexity O(n + k), making it extremely efficient for specific use cases.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given an array of n elements where each element is in the range [0, k], sort the array in ascending order using counting sort. The algorithm should count occurrences of each element and use this information to determine positions.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Array arr[] of size n with elements in range [0, k]<br>
            <strong>Output:</strong> Same array sorted in ascending order<br>
            <strong>Stability:</strong> Stable sorting algorithm (maintains relative order of equal elements)
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Counting sort works through these phases:
        </p>
        
        <ol>
            <li><strong>Count:</strong> Count occurrences of each element</li>
            <li><strong>Accumulate:</strong> Transform counts to actual positions</li>
            <li><strong>Place:</strong> Place elements in their correct positions</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: CountingSort(arr, n, k)
1. // Create count array
2. count[0..k] = {0}
3. 
4. // Count occurrences of each element
5. for i = 0 to n-1 do
6.     count[arr[i]]++
7. end for
8. 
9. // Transform count[i] to actual position of element i
10. for i = 1 to k do
11.     count[i] += count[i-1]
12. end for
13. 
14. // Build output array
15. for i = n-1 down to 0 do
16.     output[count[arr[i]] - 1] = arr[i]
17.     count[arr[i]]--
18. end for
19. 
20. // Copy output array to original array
21. for i = 0 to n-1 do
22.     arr[i] = output[i]
23. end for
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
using namespace std;

/**
 * Counting Sort - Basic Implementation
 * Sorts array with elements in range [0, k]
 * 
 * @param arr: input array to be sorted
 * @param k: maximum element value in array
 */
void countingSort(vector<int>& arr, int k) {
    int n = arr.size();
    
    // Create count array and output array
    vector<int> count(k + 1, 0);
    vector<int> output(n);
    
    // Count occurrences of each element
    for (int i = 0; i < n; i++) {
        count[arr[i]]++;
    }
    
    // Transform count[i] to actual position of element i in output array
    for (int i = 1; i <= k; i++) {
        count[i] += count[i - 1];
    }
    
    // Build output array (traverse from right to maintain stability)
    for (int i = n - 1; i >= 0; i--) {
        output[count[arr[i]] - 1] = arr[i];
        count[arr[i]]--;
    }
    
    // Copy output array back to original array
    for (int i = 0; i < n; i++) {
        arr[i] = output[i];
    }
}

/**
 * Counting Sort with Statistics
 * Tracks operations and intermediate states
 */
struct CountingSortStats {
    int countOperations;
    int accumulateOperations;
    int placeOperations;
    vector<vector<int>> countArrayHistory;
    vector<vector<int>> outputHistory;
};

CountingSortStats countingSortWithStats(vector<int>& arr, int k) {
    CountingSortStats stats = {0, 0, 0, {}, {}};
    int n = arr.size();
    
    vector<int> count(k + 1, 0);
    vector<int> output(n);
    
    // Phase 1: Count occurrences
    for (int i = 0; i < n; i++) {
        count[arr[i]]++;
        stats.countOperations++;
    }
    stats.countArrayHistory.push_back(count);
    
    // Phase 2: Accumulate counts
    for (int i = 1; i <= k; i++) {
        count[i] += count[i - 1];
        stats.accumulateOperations++;
    }
    stats.countArrayHistory.push_back(count);
    
    // Phase 3: Place elements
    for (int i = n - 1; i >= 0; i--) {
        output[count[arr[i]] - 1] = arr[i];
        count[arr[i]]--;
        stats.placeOperations++;
        
        // Save intermediate state
        stats.outputHistory.push_back(output);
    }
    
    // Copy back
    for (int i = 0; i < n; i++) {
        arr[i] = output[i];
    }
    
    return stats;
}

/**
 * Counting Sort for Negative Numbers
 * Handles arrays with negative elements
 */
void countingSortNegative(vector<int>& arr) {
    if (arr.empty()) return;
    
    // Find minimum and maximum elements
    int minElement = *min_element(arr.begin(), arr.end());
    int maxElement = *max_element(arr.begin(), arr.end());
    
    int range = maxElement - minElement + 1;
    int n = arr.size();
    
    vector<int> count(range, 0);
    vector<int> output(n);
    
    // Count occurrences (shift by minElement)
    for (int i = 0; i < n; i++) {
        count[arr[i] - minElement]++;
    }
    
    // Accumulate counts
    for (int i = 1; i < range; i++) {
        count[i] += count[i - 1];
    }
    
    // Build output array
    for (int i = n - 1; i >= 0; i--) {
        output[count[arr[i] - minElement] - 1] = arr[i];
        count[arr[i] - minElement]--;
    }
    
    // Copy back
    for (int i = 0; i < n; i++) {
        arr[i] = output[i];
    }
}

/**
 * Counting Sort for Characters
 * Specialized version for sorting characters
 */
void countingSortChars(vector<char>& arr) {
    int n = arr.size();
    vector<int> count(256, 0);  // ASCII range
    vector<char> output(n);
    
    // Count character occurrences
    for (int i = 0; i < n; i++) {
        count[arr[i]]++;
    }
    
    // Accumulate counts
    for (int i = 1; i < 256; i++) {
        count[i] += count[i - 1];
    }
    
    // Build output
    for (int i = n - 1; i >= 0; i--) {
        output[count[arr[i]] - 1] = arr[i];
        count[arr[i]]--;
    }
    
    // Copy back
    for (int i = 0; i < n; i++) {
        arr[i] = output[i];
    }
}

/**
 * Counting Sort for Objects
 * Sorts objects based on a key function
 */
struct Person {
    string name;
    int age;
    
    Person(string n, int a) : name(n), age(a) {}
};

void countingSortObjects(vector<Person>& people, int maxAge) {
    int n = people.size();
    vector<int> count(maxAge + 1, 0);
    vector<Person> output;
    output.reserve(n);
    
    // Count occurrences by age
    for (int i = 0; i < n; i++) {
        count[people[i].age]++;
    }
    
    // Use counting sort principle but with objects
    for (int age = 0; age <= maxAge; age++) {
        for (int i = 0; i < n; i++) {
            if (people[i].age == age && count[age] > 0) {
                output.push_back(people[i]);
                count[age]--;
            }
        }
    }
    
    people = output;
}

/**
 * In-place Counting Sort (when possible)
 * Modifies array in-place when range is small
 */
void inPlaceCountingSort(vector<int>& arr, int k) {
    int n = arr.size();
    
    // Only works when k < n and elements are in [0, k-1]
    if (k >= n) {
        countingSort(arr, k);
        return;
    }
    
    // Use array indices as counters
    for (int i = 0; i < n; i++) {
        arr[arr[i] % k] += k;
    }
    
    // Reconstruct array
    int index = 0;
    for (int i = 0; i < k; i++) {
        int count = arr[i] / k;
        for (int j = 0; j < count; j++) {
            arr[index++] = i;
        }
    }
}

/**
 * Counting Sort with Custom Range
 * Automatically determines range from input
 */
void adaptiveCountingSort(vector<int>& arr) {
    if (arr.empty()) return;
    
    int minVal = *min_element(arr.begin(), arr.end());
    int maxVal = *max_element(arr.begin(), arr.end());
    int range = maxVal - minVal + 1;
    int n = arr.size();
    
    // Check if counting sort is efficient
    if (range > 2 * n) {
        cout << "Warning: Range too large for efficient counting sort" << endl;
        sort(arr.begin(), arr.end());  // Fall back to comparison sort
        return;
    }
    
    vector<int> count(range, 0);
    vector<int> output(n);
    
    // Count with offset
    for (int i = 0; i < n; i++) {
        count[arr[i] - minVal]++;
    }
    
    // Accumulate
    for (int i = 1; i < range; i++) {
        count[i] += count[i - 1];
    }
    
    // Place elements
    for (int i = n - 1; i >= 0; i--) {
        output[count[arr[i] - minVal] - 1] = arr[i];
        count[arr[i] - minVal]--;
    }
    
    // Copy back
    for (int i = 0; i < n; i++) {
        arr[i] = output[i];
    }
}

// Utility functions
void printArray(const vector<int>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << arr[i];
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

void printCountArray(const vector<int>& count, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < count.size(); i++) {
        cout << count[i];
        if (i < count.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

// Example usage and testing
int main() {
    // Test basic counting sort
    vector<int> arr1 = {4, 2, 2, 8, 3, 3, 1};
    cout << "=== Basic Counting Sort ===" << endl;
    printArray(arr1, "Original");
    
    countingSort(arr1, 8);  // k = 8 (max element)
    printArray(arr1, "Sorted");
    
    // Test counting sort with statistics
    vector<int> arr2 = {1, 4, 1, 2, 7, 5, 2};
    cout << "\n=== Counting Sort with Statistics ===" << endl;
    printArray(arr2, "Original");
    
    CountingSortStats stats = countingSortWithStats(arr2, 7);
    printArray(arr2, "Sorted");
    
    cout << "Statistics:" << endl;
    cout << "  Count operations: " << stats.countOperations << endl;
    cout << "  Accumulate operations: " << stats.accumulateOperations << endl;
    cout << "  Place operations: " << stats.placeOperations << endl;
    
    cout << "  Count array history:" << endl;
    for (int i = 0; i < stats.countArrayHistory.size(); i++) {
        cout << "    Phase " << (i + 1) << ": ";
        printCountArray(stats.countArrayHistory[i], "");
    }
    
    // Test counting sort with negative numbers
    vector<int> arr3 = {-5, -10, 0, -3, 8, 5, -1};
    cout << "\n=== Counting Sort with Negative Numbers ===" << endl;
    printArray(arr3, "Original");
    
    countingSortNegative(arr3);
    printArray(arr3, "Sorted");
    
    // Test counting sort for characters
    vector<char> chars = {'g', 'e', 'e', 'k', 's', 'f', 'o', 'r', 'g', 'e', 'e', 'k', 's'};
    cout << "\n=== Counting Sort for Characters ===" << endl;
    cout << "Original: [";
    for (int i = 0; i < chars.size(); i++) {
        cout << chars[i];
        if (i < chars.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    countingSortChars(chars);
    
    cout << "Sorted: [";
    for (int i = 0; i < chars.size(); i++) {
        cout << chars[i];
        if (i < chars.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    // Test counting sort for objects
    vector<Person> people = {
        Person("Alice", 25),
        Person("Bob", 30),
        Person("Charlie", 25),
        Person("David", 35),
        Person("Eve", 30)
    };
    
    cout << "\n=== Counting Sort for Objects (by age) ===" << endl;
    cout << "Original:" << endl;
    for (const auto& p : people) {
        cout << "  " << p.name << " (age " << p.age << ")" << endl;
    }
    
    countingSortObjects(people, 35);
    
    cout << "Sorted by age:" << endl;
    for (const auto& p : people) {
        cout << "  " << p.name << " (age " << p.age << ")" << endl;
    }
    
    // Test adaptive counting sort
    vector<int> arr4 = {100, 50, 75, 25, 90, 60};
    cout << "\n=== Adaptive Counting Sort ===" << endl;
    printArray(arr4, "Original");
    
    adaptiveCountingSort(arr4);
    printArray(arr4, "Sorted");
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(n + k) - Linear in input size and range</li>
                <li><strong>Average Case:</strong> O(n + k) - Consistent performance</li>
                <li><strong>Worst Case:</strong> O(n + k) - Same as best case</li>
                <li><strong>When k = O(n):</strong> O(n) - Linear time sorting!</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(k) - For count array</li>
                <li><strong>Output Array:</strong> O(n) - For stable sorting</li>
                <li><strong>Total Space:</strong> O(n + k)</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Stable:</strong> Yes - Maintains relative order of equal elements</li>
                <li><strong>Non-comparison:</strong> Doesn't compare elements directly</li>
                <li><strong>Integer Sorting:</strong> Works only with integer keys</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through counting sort on array [4, 2, 2, 8, 3, 3, 1] with k = 8:
        </p>
        
        <div class="code-block">
Initial: [4, 2, 2, 8, 3, 3, 1]
Range: 0 to 8 (k = 8)

Step 1: Count occurrences
count = [0, 0, 0, 0, 0, 0, 0, 0, 0]
        0  1  2  3  4  5  6  7  8

Process each element:
- arr[0] = 4: count[4]++ → count = [0, 0, 0, 0, 1, 0, 0, 0, 0]
- arr[1] = 2: count[2]++ → count = [0, 0, 1, 0, 1, 0, 0, 0, 0]
- arr[2] = 2: count[2]++ → count = [0, 0, 2, 0, 1, 0, 0, 0, 0]
- arr[3] = 8: count[8]++ → count = [0, 0, 2, 0, 1, 0, 0, 0, 1]
- arr[4] = 3: count[3]++ → count = [0, 0, 2, 1, 1, 0, 0, 0, 1]
- arr[5] = 3: count[3]++ → count = [0, 0, 2, 2, 1, 0, 0, 0, 1]
- arr[6] = 1: count[1]++ → count = [0, 1, 2, 2, 1, 0, 0, 0, 1]

Step 2: Accumulate counts (positions)
count[1] = count[1] + count[0] = 1 + 0 = 1
count[2] = count[2] + count[1] = 2 + 1 = 3
count[3] = count[3] + count[2] = 2 + 3 = 5
count[4] = count[4] + count[3] = 1 + 5 = 6
count[8] = count[8] + count[7] = 1 + 6 = 7

Final count = [0, 1, 3, 5, 6, 6, 6, 6, 7]

Step 3: Place elements (right to left for stability)
output = [_, _, _, _, _, _, _]

- arr[6] = 1: place at position count[1]-1 = 0, count[1]-- → output = [1, _, _, _, _, _, _]
- arr[5] = 3: place at position count[3]-1 = 4, count[3]-- → output = [1, _, _, _, 3, _, _]
- arr[4] = 3: place at position count[3]-1 = 3, count[3]-- → output = [1, _, _, 3, 3, _, _]
- arr[3] = 8: place at position count[8]-1 = 6, count[8]-- → output = [1, _, _, 3, 3, _, 8]
- arr[2] = 2: place at position count[2]-1 = 2, count[2]-- → output = [1, _, 2, 3, 3, _, 8]
- arr[1] = 2: place at position count[2]-1 = 1, count[2]-- → output = [1, 2, 2, 3, 3, _, 8]
- arr[0] = 4: place at position count[4]-1 = 5, count[4]-- → output = [1, 2, 2, 3, 3, 4, 8]

Final: [1, 2, 2, 3, 3, 4, 8]
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Counting sort is particularly useful in these scenarios:
        </p>
        
        <ul>
            <li><strong>Small Range Data:</strong> When k (range) is much smaller than n²</li>
            <li><strong>Integer Sorting:</strong> Ages, grades, small ID numbers</li>
            <li><strong>Stable Sorting:</strong> When relative order of equal elements matters</li>
            <li><strong>Radix Sort Component:</strong> Used as subroutine in radix sort</li>
            <li><strong>Histogram Generation:</strong> Counting frequencies of elements</li>
            <li><strong>Character Sorting:</strong> Sorting strings by individual characters</li>
        </ul>
        
        <h2 class="section-title">When to Use Counting Sort</h2>
        
        <div class="definition-box">
            <strong>Use Counting Sort When:</strong><br>
            • Range of elements (k) is small compared to number of elements (n)<br>
            • Elements are non-negative integers or can be mapped to them<br>
            • Stability is required<br>
            • Linear time sorting is needed<br>
            • Working with frequency counting problems<br><br>
            
            <strong>Don't Use Counting Sort When:</strong><br>
            • Range k is very large (k >> n)<br>
            • Elements are floating-point numbers or complex objects<br>
            • Memory usage is a critical constraint<br>
            • Elements cannot be easily mapped to integers
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Large Range:</strong> Don't use when k >> n (wastes memory and time)</li>
            <li><strong>Negative Numbers:</strong> Handle by shifting range or using offset</li>
            <li><strong>Stability:</strong> Process elements from right to left to maintain stability</li>
            <li><strong>Memory Allocation:</strong> Ensure count array is properly sized</li>
            <li><strong>Integer Assumption:</strong> Only works with integer keys or mappable data</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Linear Time:</strong> Emphasize O(n + k) complexity for small k</li>
            <li><strong>Non-comparison:</strong> Explain that it doesn't compare elements</li>
            <li><strong>Stability:</strong> Highlight stable sorting property</li>
            <li><strong>Range Dependency:</strong> Discuss when it's efficient vs inefficient</li>
            <li><strong>Applications:</strong> Mention use in radix sort and histogram problems</li>
            <li><strong>Space Trade-off:</strong> More space for better time complexity</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Counting sort achieves O(n + k) time complexity for integer sorting</li>
                <li>Non-comparison based algorithm that counts element frequencies</li>
                <li>Stable sorting algorithm that preserves relative order</li>
                <li>Efficient when range k is small compared to input size n</li>
                <li>Uses O(n + k) extra space for count and output arrays</li>
                <li>Foundation for radix sort and other non-comparison algorithms</li>
                <li>Limited to integer keys or data mappable to integers</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch15">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 15</div>
        <h1 class="chapter-title">Radix Sort</h1>
        
        <p class="academic-text">
            Radix sort is a non-comparison based sorting algorithm that sorts integers by processing individual digits. It works by sorting the elements digit by digit, starting from the least significant digit (LSD) to the most significant digit (MSD), or vice versa. By using a stable sorting algorithm (like counting sort) as a subroutine for each digit, radix sort achieves linear time complexity when the number of digits is constant.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given an array of n non-negative integers, sort the array in ascending order using radix sort. The algorithm should process digits from least significant to most significant, using a stable sorting method for each digit position.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Array arr[] of size n with non-negative integers<br>
            <strong>Output:</strong> Same array sorted in ascending order<br>
            <strong>Stability:</strong> Stable sorting algorithm (maintains relative order of equal elements)
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Radix sort works through these phases:
        </p>
        
        <ol>
            <li><strong>Find Maximum:</strong> Determine the number with maximum digits</li>
            <li><strong>Digit Processing:</strong> Sort by each digit position (LSD to MSD)</li>
            <li><strong>Stable Subroutine:</strong> Use counting sort for each digit</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: RadixSort(arr, n)
1. // Find maximum number to know number of digits
2. max = findMax(arr, n)
3. 
4. // Do counting sort for every digit
5. // exp is 10^i where i is current digit number
6. for exp = 1; max/exp > 0; exp *= 10 do
7.     CountingSortByDigit(arr, n, exp)
8. end for

Algorithm: CountingSortByDigit(arr, n, exp)
1. count[0..9] = {0}
2. 
3. // Count occurrences of each digit
4. for i = 0 to n-1 do
5.     digit = (arr[i] / exp) % 10
6.     count[digit]++
7. end for
8. 
9. // Transform count to positions
10. for i = 1 to 9 do
11.     count[i] += count[i-1]
12. end for
13. 
14. // Build output array
15. for i = n-1 down to 0 do
16.     digit = (arr[i] / exp) % 10
17.     output[count[digit] - 1] = arr[i]
18.     count[digit]--
19. end for
20. 
21. // Copy output to original array
22. for i = 0 to n-1 do
23.     arr[i] = output[i]
24. end for
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
#include <string>
using namespace std;

/**
 * Counting Sort for a specific digit position
 * Used as subroutine in radix sort
 * 
 * @param arr: array to be sorted
 * @param n: size of array
 * @param exp: exponent representing current digit position (1, 10, 100, ...)
 */
void countingSortByDigit(vector<int>& arr, int n, int exp) {
    vector<int> output(n);
    vector<int> count(10, 0);  // Count array for digits 0-9
    
    // Count occurrences of each digit at current position
    for (int i = 0; i < n; i++) {
        int digit = (arr[i] / exp) % 10;
        count[digit]++;
    }
    
    // Transform count[i] to actual position of digit i in output array
    for (int i = 1; i < 10; i++) {
        count[i] += count[i - 1];
    }
    
    // Build output array (process from right to maintain stability)
    for (int i = n - 1; i >= 0; i--) {
        int digit = (arr[i] / exp) % 10;
        output[count[digit] - 1] = arr[i];
        count[digit]--;
    }
    
    // Copy output array back to original array
    for (int i = 0; i < n; i++) {
        arr[i] = output[i];
    }
}

/**
 * Radix Sort - Main function (LSD approach)
 * Sorts from least significant digit to most significant digit
 */
void radixSort(vector<int>& arr) {
    int n = arr.size();
    if (n <= 1) return;
    
    // Find maximum number to determine number of digits
    int maxNum = *max_element(arr.begin(), arr.end());
    
    // Do counting sort for every digit
    // exp is 10^i where i is current digit number
    for (int exp = 1; maxNum / exp > 0; exp *= 10) {
        countingSortByDigit(arr, n, exp);
    }
}

/**
 * Radix Sort with Statistics
 * Tracks operations and intermediate states
 */
struct RadixSortStats {
    int digitPasses;
    int totalComparisons;
    int totalSwaps;
    vector<vector<int>> stateHistory;
    vector<int> digitProcessed;
};

RadixSortStats radixSortWithStats(vector<int>& arr) {
    RadixSortStats stats = {0, 0, 0, {}, {}};
    int n = arr.size();
    
    if (n <= 1) return stats;
    
    // Save initial state
    stats.stateHistory.push_back(arr);
    
    int maxNum = *max_element(arr.begin(), arr.end());
    
    for (int exp = 1; maxNum / exp > 0; exp *= 10) {
        stats.digitPasses++;
        stats.digitProcessed.push_back(exp);
        
        // Modified counting sort with statistics
        vector<int> output(n);
        vector<int> count(10, 0);
        
        // Count phase
        for (int i = 0; i < n; i++) {
            int digit = (arr[i] / exp) % 10;
            count[digit]++;
            stats.totalComparisons++;
        }
        
        // Accumulate phase
        for (int i = 1; i < 10; i++) {
            count[i] += count[i - 1];
        }
        
        // Place phase
        for (int i = n - 1; i >= 0; i--) {
            int digit = (arr[i] / exp) % 10;
            output[count[digit] - 1] = arr[i];
            count[digit]--;
            stats.totalSwaps++;
        }
        
        // Copy back
        for (int i = 0; i < n; i++) {
            arr[i] = output[i];
        }
        
        // Save state after each digit pass
        stats.stateHistory.push_back(arr);
    }
    
    return stats;
}

/**
 * MSD Radix Sort (Most Significant Digit first)
 * Recursive approach starting from most significant digit
 */
void msdRadixSort(vector<int>& arr, int low, int high, int exp) {
    if (low >= high || exp <= 0) return;
    
    // Count array for digits 0-9
    vector<int> count(11, 0);  // Extra space for easier indexing
    
    // Count occurrences of each digit
    for (int i = low; i <= high; i++) {
        int digit = (arr[i] / exp) % 10;
        count[digit + 1]++;
    }
    
    // Transform counts to indices
    for (int i = 0; i < 10; i++) {
        count[i + 1] += count[i];
    }
    
    // Distribute elements
    vector<int> temp(high - low + 1);
    for (int i = low; i <= high; i++) {
        int digit = (arr[i] / exp) % 10;
        temp[count[digit]++] = arr[i];
    }
    
    // Copy back
    for (int i = 0; i < temp.size(); i++) {
        arr[low + i] = temp[i];
    }
    
    // Recursively sort each bucket
    for (int digit = 0; digit < 10; digit++) {
        int bucketStart = low + count[digit];
        int bucketEnd = low + count[digit + 1] - 1;
        if (bucketStart < bucketEnd) {
            msdRadixSort(arr, bucketStart, bucketEnd, exp / 10);
        }
    }
}

void msdRadixSortWrapper(vector<int>& arr) {
    if (arr.empty()) return;
    
    int maxNum = *max_element(arr.begin(), arr.end());
    
    // Find the most significant digit position
    int exp = 1;
    while (maxNum / exp >= 10) {
        exp *= 10;
    }
    
    msdRadixSort(arr, 0, arr.size() - 1, exp);
}

/**
 * Radix Sort for Negative Numbers
 * Handles arrays containing negative integers
 */
void radixSortWithNegatives(vector<int>& arr) {
    if (arr.empty()) return;
    
    vector<int> positive, negative;
    
    // Separate positive and negative numbers
    for (int num : arr) {
        if (num >= 0) {
            positive.push_back(num);
        } else {
            negative.push_back(-num);  // Store absolute value
        }
    }
    
    // Sort positive numbers normally
    if (!positive.empty()) {
        radixSort(positive);
    }
    
    // Sort negative numbers (as positive) then reverse
    if (!negative.empty()) {
        radixSort(negative);
        reverse(negative.begin(), negative.end());
        
        // Convert back to negative
        for (int& num : negative) {
            num = -num;
        }
    }
    
    // Combine results: negatives first, then positives
    arr.clear();
    arr.insert(arr.end(), negative.begin(), negative.end());
    arr.insert(arr.end(), positive.begin(), positive.end());
}

/**
 * Radix Sort for Strings
 * Sorts strings using radix sort principle
 */
void radixSortStrings(vector<string>& arr) {
    if (arr.empty()) return;
    
    // Find maximum length
    int maxLen = 0;
    for (const string& str : arr) {
        maxLen = max(maxLen, (int)str.length());
    }
    
    // Sort by each character position from right to left
    for (int pos = maxLen - 1; pos >= 0; pos--) {
        vector<vector<string>> buckets(256);  // ASCII buckets
        
        // Distribute strings into buckets based on character at position pos
        for (const string& str : arr) {
            char ch = (pos < str.length()) ? str[pos] : 0;  // Use null for shorter strings
            buckets[ch].push_back(str);
        }
        
        // Collect strings from buckets
        arr.clear();
        for (int i = 0; i < 256; i++) {
            for (const string& str : buckets[i]) {
                arr.push_back(str);
            }
        }
    }
}

/**
 * Binary Radix Sort
 * Sorts using binary representation (base 2)
 */
void binaryRadixSort(vector<int>& arr) {
    if (arr.empty()) return;
    
    int maxNum = *max_element(arr.begin(), arr.end());
    int maxBits = 0;
    
    // Find number of bits needed
    while ((1 << maxBits) <= maxNum) {
        maxBits++;
    }
    
    // Sort by each bit position
    for (int bit = 0; bit < maxBits; bit++) {
        vector<int> zeros, ones;
        
        // Partition based on current bit
        for (int num : arr) {
            if ((num >> bit) & 1) {
                ones.push_back(num);
            } else {
                zeros.push_back(num);
            }
        }
        
        // Combine: zeros first, then ones
        arr.clear();
        arr.insert(arr.end(), zeros.begin(), zeros.end());
        arr.insert(arr.end(), ones.begin(), ones.end());
    }
}

/**
 * Radix Sort with Custom Base
 * Allows sorting with different radix bases
 */
void radixSortCustomBase(vector<int>& arr, int base) {
    if (arr.empty() || base < 2) return;
    
    int maxNum = *max_element(arr.begin(), arr.end());
    int n = arr.size();
    
    for (int exp = 1; maxNum / exp > 0; exp *= base) {
        vector<int> output(n);
        vector<int> count(base, 0);
        
        // Count occurrences
        for (int i = 0; i < n; i++) {
            int digit = (arr[i] / exp) % base;
            count[digit]++;
        }
        
        // Accumulate counts
        for (int i = 1; i < base; i++) {
            count[i] += count[i - 1];
        }
        
        // Build output
        for (int i = n - 1; i >= 0; i--) {
            int digit = (arr[i] / exp) % base;
            output[count[digit] - 1] = arr[i];
            count[digit]--;
        }
        
        // Copy back
        for (int i = 0; i < n; i++) {
            arr[i] = output[i];
        }
    }
}

// Utility functions
void printArray(const vector<int>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << arr[i];
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

void printStringArray(const vector<string>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << "\"" << arr[i] << "\"";
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

// Example usage and testing
int main() {
    // Test basic radix sort
    vector<int> arr1 = {170, 45, 75, 90, 2, 802, 24, 66};
    cout << "=== Basic Radix Sort ===" << endl;
    printArray(arr1, "Original");
    
    radixSort(arr1);
    printArray(arr1, "Sorted");
    
    // Test radix sort with statistics
    vector<int> arr2 = {329, 457, 657, 839, 436, 720, 355};
    cout << "\n=== Radix Sort with Statistics ===" << endl;
    printArray(arr2, "Original");
    
    RadixSortStats stats = radixSortWithStats(arr2);
    printArray(arr2, "Sorted");
    
    cout << "Statistics:" << endl;
    cout << "  Digit passes: " << stats.digitPasses << endl;
    cout << "  Total comparisons: " << stats.totalComparisons << endl;
    cout << "  Total operations: " << stats.totalSwaps << endl;
    
    cout << "  Digit processing order: ";
    for (int digit : stats.digitProcessed) {
        cout << digit << " ";
    }
    cout << endl;
    
    cout << "  State history:" << endl;
    for (int i = 0; i < stats.stateHistory.size(); i++) {
        cout << "    Step " << i << ": ";
        printArray(stats.stateHistory[i], "");
    }
    
    // Test MSD radix sort
    vector<int> arr3 = {54, 26, 93, 17, 77, 31, 44, 55, 20};
    cout << "\n=== MSD Radix Sort ===" << endl;
    printArray(arr3, "Original");
    
    msdRadixSortWrapper(arr3);
    printArray(arr3, "Sorted");
    
    // Test radix sort with negative numbers
    vector<int> arr4 = {-170, 45, -75, 90, -2, 802, -24, 66};
    cout << "\n=== Radix Sort with Negative Numbers ===" << endl;
    printArray(arr4, "Original");
    
    radixSortWithNegatives(arr4);
    printArray(arr4, "Sorted");
    
    // Test radix sort for strings
    vector<string> words = {"banana", "apple", "cherry", "date", "elderberry"};
    cout << "\n=== Radix Sort for Strings ===" << endl;
    printStringArray(words, "Original");
    
    radixSortStrings(words);
    printStringArray(words, "Sorted");
    
    // Test binary radix sort
    vector<int> arr5 = {64, 34, 25, 12, 22, 11, 90};
    cout << "\n=== Binary Radix Sort ===" << endl;
    printArray(arr5, "Original");
    
    binaryRadixSort(arr5);
    printArray(arr5, "Sorted");
    
    // Test custom base radix sort
    vector<int> arr6 = {125, 383, 274, 96, 458, 712, 639};
    cout << "\n=== Radix Sort with Base 8 ===" << endl;
    printArray(arr6, "Original");
    
    radixSortCustomBase(arr6, 8);
    printArray(arr6, "Sorted");
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(d × (n + k)) where d = digits, k = base</li>
                <li><strong>Average Case:</strong> O(d × (n + k)) - Consistent performance</li>
                <li><strong>Worst Case:</strong> O(d × (n + k)) - Same as best case</li>
                <li><strong>When d is constant:</strong> O(n) - Linear time sorting!</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(n + k) - For output and count arrays</li>
                <li><strong>LSD Approach:</strong> O(n) - Uses iterative approach</li>
                <li><strong>MSD Approach:</strong> O(d × n) - Due to recursion stack</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Stable:</strong> Yes - Maintains relative order of equal elements</li>
                <li><strong>Non-comparison:</strong> Doesn't compare elements directly</li>
                <li><strong>Integer Sorting:</strong> Works with integers and strings</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through radix sort on array [170, 45, 75, 90, 2, 802, 24, 66]:
        </p>
        
        <div class="code-block">
Initial: [170, 45, 75, 90, 2, 802, 24, 66]
Maximum: 802 (3 digits)

Pass 1: Sort by units digit (exp = 1)
Digits: [0, 5, 5, 0, 2, 2, 4, 6]
After sorting by units: [170, 90, 2, 802, 24, 45, 75, 66]

Pass 2: Sort by tens digit (exp = 10)  
Digits: [7, 9, 0, 0, 2, 4, 7, 6]
After sorting by tens: [2, 802, 24, 45, 66, 170, 75, 90]

Pass 3: Sort by hundreds digit (exp = 100)
Digits: [1, 8, 0, 0, 0, 1, 0, 0]
After sorting by hundreds: [2, 24, 45, 66, 75, 90, 170, 802]

Final: [2, 24, 45, 66, 75, 90, 170, 802]

Detailed Pass 1 (units digit):
Count array after counting: [2, 0, 2, 0, 1, 2, 1, 0, 0, 0]
                           0  1  2  3  4  5  6  7  8  9

Cumulative count: [2, 2, 4, 4, 5, 7, 8, 8, 8, 8]

Placing elements (right to left):
- 66 (digit 6): position 7, place at index 7
- 24 (digit 4): position 4, place at index 4  
- 802 (digit 2): position 3, place at index 3
- 2 (digit 2): position 2, place at index 2
- 90 (digit 0): position 1, place at index 1
- 75 (digit 5): position 6, place at index 6
- 45 (digit 5): position 5, place at index 5
- 170 (digit 0): position 0, place at index 0

Result: [170, 90, 2, 802, 24, 45, 75, 66]
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Radix sort is particularly useful in these scenarios:
        </p>
        
        <ul>
            <li><strong>Integer Sorting:</strong> When integers have limited number of digits</li>
            <li><strong>String Sorting:</strong> Lexicographic sorting of fixed-length strings</li>
            <li><strong>Database Systems:</strong> Sorting records by numeric keys</li>
            <li><strong>Parallel Processing:</strong> Can be easily parallelized by digits</li>
            <li><strong>External Sorting:</strong> Efficient for large datasets on disk</li>
            <li><strong>Suffix Arrays:</strong> Used in string processing algorithms</li>
        </ul>
        
        <h2 class="section-title">LSD vs MSD Radix Sort</h2>
        
        <div class="definition-box">
            <strong>LSD (Least Significant Digit):</strong><br>
            • Processes digits from right to left (units → tens → hundreds)<br>
            • Simpler implementation, iterative approach<br>
            • Stable sorting, maintains original order<br>
            • Better for fixed-length keys<br><br>
            
            <strong>MSD (Most Significant Digit):</strong><br>
            • Processes digits from left to right (hundreds → tens → units)<br>
            • Recursive implementation, more complex<br>
            • Can terminate early for some buckets<br>
            • Better for variable-length keys
        </div>
        
        <h2 class="section-title">When to Use Radix Sort</h2>
        
        <div class="definition-box">
            <strong>Use Radix Sort When:</strong><br>
            • Sorting integers with limited number of digits<br>
            • Number of digits (d) is small compared to input size (n)<br>
            • Stability is required<br>
            • Working with fixed-length strings<br>
            • Linear time sorting is needed<br><br>
            
            <strong>Don't Use Radix Sort When:</strong><br>
            • Number of digits is very large (d >> log n)<br>
            • Sorting floating-point numbers or complex objects<br>
            • Memory usage is critical (uses O(n) extra space)<br>
            • Working with comparison-based requirements
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Digit Count:</strong> Ensure correct calculation of maximum digits</li>
            <li><strong>Negative Numbers:</strong> Handle separately or use offset technique</li>
            <li><strong>Stability:</strong> Process elements from right to left in counting sort</li>
            <li><strong>Base Selection:</strong> Choose appropriate base for efficiency</li>
            <li><strong>Memory Usage:</strong> Consider space complexity for large inputs</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Linear Time:</strong> Emphasize O(d × n) complexity when d is constant</li>
            <li><strong>Non-comparison:</strong> Explain digit-by-digit processing approach</li>
            <li><strong>Stability:</strong> Highlight stable sorting property</li>
            <li><strong>Applications:</strong> Mention string sorting and database applications</li>
            <li><strong>Limitations:</strong> Discuss when it's not suitable (large d, floating-point)</li>
            <li><strong>Variants:</strong> Know both LSD and MSD approaches</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Radix sort achieves O(d × n) time complexity for d-digit numbers</li>
                <li>Non-comparison based algorithm that processes digits individually</li>
                <li>Stable sorting algorithm using counting sort as subroutine</li>
                <li>Efficient when number of digits is small compared to input size</li>
                <li>Works for integers, strings, and other digit-based representations</li>
                <li>Can be implemented as LSD (iterative) or MSD (recursive)</li>
                <li>Linear time sorting when digit count is constant</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch16">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 16</div>
        <h1 class="chapter-title">Bucket Sort</h1>
        
        <p class="academic-text">
            Bucket sort is a distribution-based sorting algorithm that works by distributing elements into a number of buckets, sorting individual buckets, and then concatenating the sorted buckets. It's particularly effective when the input is uniformly distributed over a range. By using an appropriate number of buckets and a good distribution function, bucket sort can achieve linear average-case time complexity.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given an array of n elements that are uniformly distributed over a range [0, 1) or can be normalized to this range, sort the array in ascending order using bucket sort. The algorithm should distribute elements into buckets, sort each bucket individually, and combine the results.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Array arr[] of size n with elements in range [0, 1) or normalizable<br>
            <strong>Output:</strong> Same array sorted in ascending order<br>
            <strong>Stability:</strong> Can be stable depending on the sorting method used for buckets
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Bucket sort works through these phases:
        </p>
        
        <ol>
            <li><strong>Create Buckets:</strong> Initialize empty buckets (usually n buckets)</li>
            <li><strong>Distribute:</strong> Place each element in appropriate bucket</li>
            <li><strong>Sort Buckets:</strong> Sort individual buckets using any sorting algorithm</li>
            <li><strong>Concatenate:</strong> Combine sorted buckets to get final result</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: BucketSort(arr, n)
1. // Create n empty buckets
2. buckets[0..n-1] = empty lists
3. 
4. // Distribute elements into buckets
5. for i = 0 to n-1 do
6.     bucketIndex = floor(n * arr[i])
7.     buckets[bucketIndex].add(arr[i])
8. end for
9. 
10. // Sort individual buckets
11. for i = 0 to n-1 do
12.     sort(buckets[i])  // Use any sorting algorithm
13. end for
14. 
15. // Concatenate sorted buckets
16. index = 0
17. for i = 0 to n-1 do
18.     for each element in buckets[i] do
19.         arr[index++] = element
20.     end for
21. end for
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
using namespace std;

/**
 * Bucket Sort for floating-point numbers in range [0, 1)
 * Classic implementation for uniformly distributed data
 */
void bucketSort(vector<float>& arr) {
    int n = arr.size();
    if (n <= 1) return;
    
    // Create n empty buckets
    vector<vector<float>> buckets(n);
    
    // Distribute elements into buckets
    for (int i = 0; i < n; i++) {
        int bucketIndex = (int)(n * arr[i]);
        
        // Handle edge case where arr[i] = 1.0
        if (bucketIndex == n) bucketIndex = n - 1;
        
        buckets[bucketIndex].push_back(arr[i]);
    }
    
    // Sort individual buckets using insertion sort
    for (int i = 0; i < n; i++) {
        sort(buckets[i].begin(), buckets[i].end());
    }
    
    // Concatenate sorted buckets
    int index = 0;
    for (int i = 0; i < n; i++) {
        for (float element : buckets[i]) {
            arr[index++] = element;
        }
    }
}

/**
 * Bucket Sort for integers in a given range
 * Normalizes integers to [0, 1) range internally
 */
void bucketSortIntegers(vector<int>& arr, int minVal, int maxVal) {
    int n = arr.size();
    if (n <= 1 || minVal >= maxVal) return;
    
    int range = maxVal - minVal + 1;
    vector<vector<int>> buckets(n);
    
    // Distribute elements into buckets
    for (int i = 0; i < n; i++) {
        // Normalize to [0, n) range
        int bucketIndex = ((arr[i] - minVal) * n) / range;
        
        // Handle edge case
        if (bucketIndex == n) bucketIndex = n - 1;
        
        buckets[bucketIndex].push_back(arr[i]);
    }
    
    // Sort individual buckets
    for (int i = 0; i < n; i++) {
        sort(buckets[i].begin(), buckets[i].end());
    }
    
    // Concatenate results
    int index = 0;
    for (int i = 0; i < n; i++) {
        for (int element : buckets[i]) {
            arr[index++] = element;
        }
    }
}

/**
 * Bucket Sort with Statistics
 * Tracks bucket distribution and operations
 */
struct BucketSortStats {
    int numBuckets;
    vector<int> bucketSizes;
    vector<vector<float>> bucketContents;
    int totalComparisons;
    int distributionOperations;
};

BucketSortStats bucketSortWithStats(vector<float>& arr) {
    BucketSortStats stats;
    int n = arr.size();
    stats.numBuckets = n;
    stats.totalComparisons = 0;
    stats.distributionOperations = 0;
    
    if (n <= 1) return stats;
    
    vector<vector<float>> buckets(n);
    
    // Distribution phase
    for (int i = 0; i < n; i++) {
        int bucketIndex = (int)(n * arr[i]);
        if (bucketIndex == n) bucketIndex = n - 1;
        
        buckets[bucketIndex].push_back(arr[i]);
        stats.distributionOperations++;
    }
    
    // Record bucket sizes and contents
    for (int i = 0; i < n; i++) {
        stats.bucketSizes.push_back(buckets[i].size());
        stats.bucketContents.push_back(buckets[i]);
    }
    
    // Sort individual buckets and count comparisons
    for (int i = 0; i < n; i++) {
        if (buckets[i].size() > 1) {
            // Estimate comparisons for sorting (using insertion sort complexity)
            stats.totalComparisons += buckets[i].size() * buckets[i].size();
        }
        sort(buckets[i].begin(), buckets[i].end());
    }
    
    // Concatenate
    int index = 0;
    for (int i = 0; i < n; i++) {
        for (float element : buckets[i]) {
            arr[index++] = element;
        }
    }
    
    return stats;
}

/**
 * Adaptive Bucket Sort
 * Automatically determines optimal number of buckets
 */
void adaptiveBucketSort(vector<float>& arr) {
    int n = arr.size();
    if (n <= 1) return;
    
    // Find min and max for better distribution
    float minVal = *min_element(arr.begin(), arr.end());
    float maxVal = *max_element(arr.begin(), arr.end());
    
    if (minVal == maxVal) return;  // All elements are equal
    
    // Use sqrt(n) buckets for better performance
    int numBuckets = max(1, (int)sqrt(n));
    vector<vector<float>> buckets(numBuckets);
    
    float range = maxVal - minVal;
    
    // Distribute elements
    for (int i = 0; i < n; i++) {
        int bucketIndex = (int)((arr[i] - minVal) / range * numBuckets);
        
        // Handle edge case
        if (bucketIndex == numBuckets) bucketIndex = numBuckets - 1;
        
        buckets[bucketIndex].push_back(arr[i]);
    }
    
    // Sort buckets
    for (int i = 0; i < numBuckets; i++) {
        sort(buckets[i].begin(), buckets[i].end());
    }
    
    // Concatenate
    int index = 0;
    for (int i = 0; i < numBuckets; i++) {
        for (float element : buckets[i]) {
            arr[index++] = element;
        }
    }
}

/**
 * Bucket Sort with Custom Bucket Function
 * Allows custom distribution strategy
 */
template<typename T, typename BucketFunc>
void customBucketSort(vector<T>& arr, int numBuckets, BucketFunc getBucket) {
    if (arr.empty() || numBuckets <= 0) return;
    
    vector<vector<T>> buckets(numBuckets);
    
    // Distribute using custom function
    for (const T& element : arr) {
        int bucketIndex = getBucket(element, numBuckets);
        bucketIndex = max(0, min(numBuckets - 1, bucketIndex));  // Clamp to valid range
        buckets[bucketIndex].push_back(element);
    }
    
    // Sort buckets
    for (int i = 0; i < numBuckets; i++) {
        sort(buckets[i].begin(), buckets[i].end());
    }
    
    // Concatenate
    arr.clear();
    for (int i = 0; i < numBuckets; i++) {
        for (const T& element : buckets[i]) {
            arr.push_back(element);
        }
    }
}

/**
 * Bucket Sort for Strings by Length
 * Sorts strings first by length, then lexicographically
 */
void bucketSortStringsByLength(vector<string>& arr) {
    if (arr.empty()) return;
    
    // Find maximum string length
    int maxLen = 0;
    for (const string& str : arr) {
        maxLen = max(maxLen, (int)str.length());
    }
    
    // Create buckets for each possible length
    vector<vector<string>> buckets(maxLen + 1);
    
    // Distribute by length
    for (const string& str : arr) {
        buckets[str.length()].push_back(str);
    }
    
    // Sort each bucket lexicographically
    for (int i = 0; i <= maxLen; i++) {
        sort(buckets[i].begin(), buckets[i].end());
    }
    
    // Concatenate
    arr.clear();
    for (int i = 0; i <= maxLen; i++) {
        for (const string& str : buckets[i]) {
            arr.push_back(str);
        }
    }
}

/**
 * Parallel Bucket Sort (Conceptual)
 * Shows how bucket sort can be parallelized
 */
void parallelBucketSort(vector<float>& arr) {
    int n = arr.size();
    if (n <= 1) return;
    
    vector<vector<float>> buckets(n);
    
    // Distribution phase (can be parallelized)
    for (int i = 0; i < n; i++) {
        int bucketIndex = (int)(n * arr[i]);
        if (bucketIndex == n) bucketIndex = n - 1;
        buckets[bucketIndex].push_back(arr[i]);
    }
    
    // Sorting phase (each bucket can be sorted in parallel)
    // In actual parallel implementation, use threads/OpenMP here
    for (int i = 0; i < n; i++) {
        sort(buckets[i].begin(), buckets[i].end());
    }
    
    // Concatenation phase
    int index = 0;
    for (int i = 0; i < n; i++) {
        for (float element : buckets[i]) {
            arr[index++] = element;
        }
    }
}

/**
 * In-place Bucket Sort (Limited cases)
 * Attempts to minimize extra space usage
 */
void inPlaceBucketSort(vector<int>& arr, int maxVal) {
    int n = arr.size();
    if (n <= 1) return;
    
    // This works only when maxVal is small
    // Use array positions as implicit buckets
    
    // Count occurrences (similar to counting sort)
    vector<int> count(maxVal + 1, 0);
    for (int num : arr) {
        count[num]++;
    }
    
    // Reconstruct array
    int index = 0;
    for (int i = 0; i <= maxVal; i++) {
        while (count[i]-- > 0) {
            arr[index++] = i;
        }
    }
}

// Utility functions
void printFloatArray(const vector<float>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << fixed << setprecision(3) << arr[i];
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

void printIntArray(const vector<int>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << arr[i];
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

void printStringArray(const vector<string>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << "\"" << arr[i] << "\"";
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

// Example usage and testing
int main() {
    // Test basic bucket sort with floats
    vector<float> arr1 = {0.897, 0.565, 0.656, 0.1234, 0.665, 0.3434};
    cout << "=== Basic Bucket Sort (Floats) ===" << endl;
    printFloatArray(arr1, "Original");
    
    bucketSort(arr1);
    printFloatArray(arr1, "Sorted");
    
    // Test bucket sort with integers
    vector<int> arr2 = {29, 25, 3, 49, 9, 37, 21, 43};
    cout << "\n=== Bucket Sort for Integers ===" << endl;
    printIntArray(arr2, "Original");
    
    bucketSortIntegers(arr2, 0, 50);  // Range 0-50
    printIntArray(arr2, "Sorted");
    
    // Test bucket sort with statistics
    vector<float> arr3 = {0.78, 0.17, 0.39, 0.26, 0.72, 0.94, 0.21, 0.12, 0.23, 0.68};
    cout << "\n=== Bucket Sort with Statistics ===" << endl;
    printFloatArray(arr3, "Original");
    
    BucketSortStats stats = bucketSortWithStats(arr3);
    printFloatArray(arr3, "Sorted");
    
    cout << "Statistics:" << endl;
    cout << "  Number of buckets: " << stats.numBuckets << endl;
    cout << "  Distribution operations: " << stats.distributionOperations << endl;
    cout << "  Estimated comparisons: " << stats.totalComparisons << endl;
    
    cout << "  Bucket sizes: [";
    for (int i = 0; i < stats.bucketSizes.size(); i++) {
        cout << stats.bucketSizes[i];
        if (i < stats.bucketSizes.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    cout << "  Non-empty buckets:" << endl;
    for (int i = 0; i < stats.bucketContents.size(); i++) {
        if (!stats.bucketContents[i].empty()) {
            cout << "    Bucket " << i << ": ";
            printFloatArray(stats.bucketContents[i], "");
        }
    }
    
    // Test adaptive bucket sort
    vector<float> arr4 = {2.5, 1.2, 4.8, 3.1, 0.9, 5.7, 2.3, 4.1, 1.8, 3.9};
    cout << "\n=== Adaptive Bucket Sort ===" << endl;
    printFloatArray(arr4, "Original");
    
    adaptiveBucketSort(arr4);
    printFloatArray(arr4, "Sorted");
    
    // Test custom bucket sort with strings by first character
    vector<string> words = {"apple", "banana", "cherry", "date", "elderberry", "fig", "grape"};
    cout << "\n=== Custom Bucket Sort (Strings by First Character) ===" << endl;
    printStringArray(words, "Original");
    
    customBucketSort(words, 26, [](const string& str, int numBuckets) {
        return str.empty() ? 0 : (str[0] - 'a');
    });
    printStringArray(words, "Sorted");
    
    // Test bucket sort for strings by length
    vector<string> words2 = {"cat", "elephant", "dog", "butterfly", "ant", "hippopotamus", "bee"};
    cout << "\n=== Bucket Sort by String Length ===" << endl;
    printStringArray(words2, "Original");
    
    bucketSortStringsByLength(words2);
    printStringArray(words2, "Sorted by length then lexicographically");
    
    // Test with uniformly distributed random data
    vector<float> arr5;
    srand(42);  // For reproducible results
    for (int i = 0; i < 15; i++) {
        arr5.push_back((float)rand() / RAND_MAX);
    }
    
    cout << "\n=== Bucket Sort with Random Uniform Data ===" << endl;
    printFloatArray(arr5, "Original (random uniform)");
    
    bucketSort(arr5);
    printFloatArray(arr5, "Sorted");
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Best Case:</strong> O(n + k) - When elements are uniformly distributed</li>
                <li><strong>Average Case:</strong> O(n + k) - With uniform distribution assumption</li>
                <li><strong>Worst Case:</strong> O(n²) - When all elements fall into one bucket</li>
                <li><strong>Bucket Sorting:</strong> O(k × (n/k)²) = O(n²/k + k) on average</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(n + k) - For buckets and temporary storage</li>
                <li><strong>Bucket Storage:</strong> O(n) - All elements stored in buckets</li>
                <li><strong>Additional Arrays:</strong> O(k) - For bucket headers/pointers</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Stable:</strong> Yes - If bucket sorting algorithm is stable</li>
                <li><strong>Distribution-based:</strong> Performance depends on input distribution</li>
                <li><strong>Parallelizable:</strong> Buckets can be sorted independently</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through bucket sort on array [0.78, 0.17, 0.39, 0.26, 0.72, 0.94]:
        </p>
        
        <div class="code-block">
Initial: [0.78, 0.17, 0.39, 0.26, 0.72, 0.94]
Number of buckets: n = 6

Step 1: Create 6 empty buckets
Buckets: [[], [], [], [], [], []]

Step 2: Distribute elements into buckets
For each element, bucket_index = floor(n * element)

- 0.78: bucket_index = floor(6 * 0.78) = floor(4.68) = 4
  Buckets: [[], [], [], [], [0.78], []]

- 0.17: bucket_index = floor(6 * 0.17) = floor(1.02) = 1  
  Buckets: [[], [0.17], [], [], [0.78], []]

- 0.39: bucket_index = floor(6 * 0.39) = floor(2.34) = 2
  Buckets: [[], [0.17], [0.39], [], [0.78], []]

- 0.26: bucket_index = floor(6 * 0.26) = floor(1.56) = 1
  Buckets: [[], [0.17, 0.26], [0.39], [], [0.78], []]

- 0.72: bucket_index = floor(6 * 0.72) = floor(4.32) = 4
  Buckets: [[], [0.17, 0.26], [0.39], [], [0.78, 0.72], []]

- 0.94: bucket_index = floor(6 * 0.94) = floor(5.64) = 5
  Buckets: [[], [0.17, 0.26], [0.39], [], [0.78, 0.72], [0.94]]

Step 3: Sort individual buckets
- Bucket 0: [] (empty)
- Bucket 1: [0.17, 0.26] → [0.17, 0.26] (already sorted)
- Bucket 2: [0.39] → [0.39] (single element)
- Bucket 3: [] (empty)
- Bucket 4: [0.78, 0.72] → [0.72, 0.78] (sorted)
- Bucket 5: [0.94] → [0.94] (single element)

Step 4: Concatenate sorted buckets
Result: [0.17, 0.26, 0.39, 0.72, 0.78, 0.94]
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Bucket sort is particularly useful in these scenarios:
        </p>
        
        <ul>
            <li><strong>Uniform Distribution:</strong> When input data is uniformly distributed</li>
            <li><strong>Floating-Point Numbers:</strong> Sorting decimal numbers in known ranges</li>
            <li><strong>External Sorting:</strong> Large datasets that don't fit in memory</li>
            <li><strong>Parallel Processing:</strong> Can distribute buckets across processors</li>
            <li><strong>Database Systems:</strong> Sorting records by numeric ranges</li>
            <li><strong>Graphics Processing:</strong> Sorting pixels by color intensity</li>
        </ul>
        
        <h2 class="section-title">Distribution Strategies</h2>
        
        <div class="definition-box">
            <strong>Uniform Distribution:</strong><br>
            • bucket_index = floor(n × (element - min) / (max - min))<br>
            • Works best when elements are uniformly distributed<br><br>
            
            <strong>Square Root Buckets:</strong><br>
            • Use √n buckets instead of n buckets<br>
            • Better space-time trade-off<br><br>
            
            <strong>Logarithmic Distribution:</strong><br>
            • bucket_index = floor(log(element) × scale_factor)<br>
            • Useful for exponentially distributed data<br><br>
            
            <strong>Custom Hash Function:</strong><br>
            • Use domain-specific distribution function<br>
            • Tailored to specific data characteristics
        </div>
        
        <h2 class="section-title">When to Use Bucket Sort</h2>
        
        <div class="definition-box">
            <strong>Use Bucket Sort When:</strong><br>
            • Input is uniformly distributed over a known range<br>
            • Working with floating-point numbers<br>
            • Parallel processing is available<br>
            • Stable sorting is required<br>
            • External sorting is needed<br><br>
            
            <strong>Don't Use Bucket Sort When:</strong><br>
            • Input distribution is highly skewed<br>
            • Range of input values is unknown<br>
            • Memory usage is critical<br>
            • Input size is very small (overhead not worth it)
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Skewed Distribution:</strong> Poor performance when elements cluster in few buckets</li>
            <li><strong>Bucket Count:</strong> Too few buckets reduce efficiency, too many waste space</li>
            <li><strong>Range Estimation:</strong> Incorrect min/max estimation affects distribution</li>
            <li><strong>Edge Cases:</strong> Handle elements at boundary values (min, max) carefully</li>
            <li><strong>Empty Buckets:</strong> Many empty buckets indicate poor distribution function</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Distribution Assumption:</strong> Emphasize uniform distribution requirement</li>
            <li><strong>Linear Average Case:</strong> Explain O(n) average-case complexity</li>
            <li><strong>Parallelization:</strong> Highlight parallel processing advantages</li>
            <li><strong>Bucket Strategy:</strong> Discuss different bucket distribution methods</li>
            <li><strong>Applications:</strong> Mention external sorting and floating-point sorting</li>
            <li><strong>Comparison:</strong> Contrast with radix sort and counting sort</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Bucket sort achieves O(n) average-case complexity with uniform distribution</li>
                <li>Distribution-based algorithm that divides elements into buckets</li>
                <li>Stable sorting algorithm when using stable bucket sorting method</li>
                <li>Excellent for parallel processing due to independent bucket sorting</li>
                <li>Performance heavily depends on input distribution quality</li>
                <li>Effective for floating-point numbers and external sorting</li>
                <li>Can degrade to O(n²) with poor distribution (all elements in one bucket)</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch17">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 17</div>
        <h1 class="chapter-title">Shell Sort</h1>
        
        <p class="academic-text">
            Shell sort is an in-place comparison-based sorting algorithm that generalizes insertion sort by allowing the exchange of items that are far apart. It works by sorting elements at specific intervals (gaps) and gradually reducing the gap until it becomes 1. The choice of gap sequence significantly affects the algorithm's performance, with some sequences providing better time complexity than others.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given an array of n elements, sort the array in ascending order using shell sort. The algorithm should use a gap sequence to perform multiple passes of insertion sort with decreasing gaps, ending with a final pass where gap = 1.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Array arr[] of size n with comparable elements<br>
            <strong>Output:</strong> Same array sorted in ascending order<br>
            <strong>Stability:</strong> Not stable (can change relative order of equal elements)
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Shell sort works through these phases:
        </p>
        
        <ol>
            <li><strong>Gap Selection:</strong> Choose initial gap and gap sequence</li>
            <li><strong>Gap-based Insertion Sort:</strong> Sort elements gap positions apart</li>
            <li><strong>Gap Reduction:</strong> Reduce gap according to sequence</li>
            <li><strong>Final Pass:</strong> Perform insertion sort with gap = 1</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: ShellSort(arr, n)
1. // Start with a large gap and reduce it
2. gap = n / 2
3. 
4. while gap > 0 do
5.     // Perform insertion sort for elements gap apart
6.     for i = gap to n-1 do
7.         temp = arr[i]
8.         j = i
9.         
10.        // Shift elements until correct position found
11.        while j >= gap AND arr[j - gap] > temp do
12.            arr[j] = arr[j - gap]
13.            j = j - gap
14.        end while
15.        
16.        arr[j] = temp
17.    end for
18.    
19.    gap = gap / 2  // Reduce gap
20. end while
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <algorithm>
using namespace std;

/**
 * Shell Sort - Basic implementation with simple gap sequence
 * Uses gap sequence: n/2, n/4, n/8, ..., 1
 */
void shellSort(vector<int>& arr) {
    int n = arr.size();
    
    // Start with a large gap and reduce it
    for (int gap = n / 2; gap > 0; gap /= 2) {
        // Perform insertion sort for elements gap apart
        for (int i = gap; i < n; i++) {
            int temp = arr[i];
            int j = i;
            
            // Shift elements until correct position is found
            while (j >= gap && arr[j - gap] > temp) {
                arr[j] = arr[j - gap];
                j -= gap;
            }
            
            arr[j] = temp;
        }
    }
}

/**
 * Shell Sort with Knuth's Gap Sequence
 * Uses gap sequence: 1, 4, 13, 40, 121, ... (3^k - 1)/2
 */
void shellSortKnuth(vector<int>& arr) {
    int n = arr.size();
    
    // Generate Knuth's gap sequence
    int gap = 1;
    while (gap < n / 3) {
        gap = 3 * gap + 1;  // 1, 4, 13, 40, 121, ...
    }
    
    // Sort with decreasing gaps
    while (gap >= 1) {
        for (int i = gap; i < n; i++) {
            int temp = arr[i];
            int j = i;
            
            while (j >= gap && arr[j - gap] > temp) {
                arr[j] = arr[j - gap];
                j -= gap;
            }
            
            arr[j] = temp;
        }
        
        gap /= 3;  // Reduce gap according to Knuth's sequence
    }
}

/**
 * Shell Sort with Sedgewick's Gap Sequence
 * Uses gap sequence: 1, 5, 19, 41, 109, ... (4^i + 3*2^(i-1) + 1)
 */
void shellSortSedgewick(vector<int>& arr) {
    int n = arr.size();
    vector<int> gaps;
    
    // Generate Sedgewick's gap sequence
    for (int i = 0; ; i++) {
        int gap;
        if (i % 2 == 0) {
            gap = 9 * (1 << i) - 9 * (1 << (i / 2)) + 1;
        } else {
            gap = 8 * (1 << i) - 6 * (1 << ((i + 1) / 2)) + 1;
        }
        
        if (gap >= n) break;
        gaps.push_back(gap);
    }
    
    // Sort with gaps in reverse order
    for (int k = gaps.size() - 1; k >= 0; k--) {
        int gap = gaps[k];
        
        for (int i = gap; i < n; i++) {
            int temp = arr[i];
            int j = i;
            
            while (j >= gap && arr[j - gap] > temp) {
                arr[j] = arr[j - gap];
                j -= gap;
            }
            
            arr[j] = temp;
        }
    }
    
    // Final pass with gap = 1 (insertion sort)
    for (int i = 1; i < n; i++) {
        int temp = arr[i];
        int j = i - 1;
        
        while (j >= 0 && arr[j] > temp) {
            arr[j + 1] = arr[j];
            j--;
        }
        
        arr[j + 1] = temp;
    }
}

/**
 * Shell Sort with Statistics
 * Tracks gaps used, comparisons, and swaps
 */
struct ShellSortStats {
    vector<int> gapsUsed;
    int totalComparisons;
    int totalSwaps;
    vector<vector<int>> stateHistory;
};

ShellSortStats shellSortWithStats(vector<int>& arr) {
    ShellSortStats stats = {{}, 0, 0, {}};
    int n = arr.size();
    
    // Save initial state
    stats.stateHistory.push_back(arr);
    
    for (int gap = n / 2; gap > 0; gap /= 2) {
        stats.gapsUsed.push_back(gap);
        
        for (int i = gap; i < n; i++) {
            int temp = arr[i];
            int j = i;
            
            while (j >= gap) {
                stats.totalComparisons++;
                if (arr[j - gap] > temp) {
                    arr[j] = arr[j - gap];
                    stats.totalSwaps++;
                    j -= gap;
                } else {
                    break;
                }
            }
            
            if (j != i) {
                arr[j] = temp;
                stats.totalSwaps++;
            }
        }
        
        // Save state after each gap
        stats.stateHistory.push_back(arr);
    }
    
    return stats;
}

/**
 * Shell Sort with Custom Gap Sequence
 * Allows user to specify their own gap sequence
 */
void shellSortCustomGaps(vector<int>& arr, const vector<int>& gaps) {
    int n = arr.size();
    
    for (int gap : gaps) {
        if (gap >= n) continue;  // Skip gaps larger than array size
        
        for (int i = gap; i < n; i++) {
            int temp = arr[i];
            int j = i;
            
            while (j >= gap && arr[j - gap] > temp) {
                arr[j] = arr[j - gap];
                j -= gap;
            }
            
            arr[j] = temp;
        }
    }
}

/**
 * Shell Sort with Hibbard's Gap Sequence
 * Uses gap sequence: 1, 3, 7, 15, 31, ... (2^k - 1)
 */
void shellSortHibbard(vector<int>& arr) {
    int n = arr.size();
    vector<int> gaps;
    
    // Generate Hibbard's gap sequence
    for (int k = 1; (1 << k) - 1 < n; k++) {
        gaps.push_back((1 << k) - 1);
    }
    
    // Sort with gaps in reverse order
    for (int i = gaps.size() - 1; i >= 0; i--) {
        int gap = gaps[i];
        
        for (int j = gap; j < n; j++) {
            int temp = arr[j];
            int k = j;
            
            while (k >= gap && arr[k - gap] > temp) {
                arr[k] = arr[k - gap];
                k -= gap;
            }
            
            arr[k] = temp;
        }
    }
}

/**
 * Shell Sort with Pratt's Gap Sequence
 * Uses gaps of form 2^i * 3^j
 */
void shellSortPratt(vector<int>& arr) {
    int n = arr.size();
    vector<int> gaps;
    
    // Generate Pratt's sequence (2^i * 3^j)
    for (int i = 0; (1 << i) < n; i++) {
        for (int j = 0; (1 << i) * pow(3, j) < n; j++) {
            gaps.push_back((1 << i) * pow(3, j));
        }
    }
    
    // Sort gaps in descending order
    sort(gaps.rbegin(), gaps.rend());
    
    // Apply shell sort with Pratt's gaps
    for (int gap : gaps) {
        for (int i = gap; i < n; i++) {
            int temp = arr[i];
            int j = i;
            
            while (j >= gap && arr[j - gap] > temp) {
                arr[j] = arr[j - gap];
                j -= gap;
            }
            
            arr[j] = temp;
        }
    }
}

/**
 * Generic Shell Sort Template
 * Works with any comparable type
 */
template<typename T>
void genericShellSort(vector<T>& arr) {
    int n = arr.size();
    
    for (int gap = n / 2; gap > 0; gap /= 2) {
        for (int i = gap; i < n; i++) {
            T temp = arr[i];
            int j = i;
            
            while (j >= gap && arr[j - gap] > temp) {
                arr[j] = arr[j - gap];
                j -= gap;
            }
            
            arr[j] = temp;
        }
    }
}

/**
 * Shell Sort Performance Comparison
 * Tests different gap sequences on the same data
 */
void compareGapSequences(vector<int> originalArr) {
    cout << "\n=== Gap Sequence Performance Comparison ===" << endl;
    
    // Test Shell's original sequence
    vector<int> arr1 = originalArr;
    auto start = chrono::high_resolution_clock::now();
    shellSort(arr1);
    auto end = chrono::high_resolution_clock::now();
    auto duration1 = chrono::duration_cast<chrono::microseconds>(end - start);
    
    // Test Knuth's sequence
    vector<int> arr2 = originalArr;
    start = chrono::high_resolution_clock::now();
    shellSortKnuth(arr2);
    end = chrono::high_resolution_clock::now();
    auto duration2 = chrono::duration_cast<chrono::microseconds>(end - start);
    
    // Test Hibbard's sequence
    vector<int> arr3 = originalArr;
    start = chrono::high_resolution_clock::now();
    shellSortHibbard(arr3);
    end = chrono::high_resolution_clock::now();
    auto duration3 = chrono::duration_cast<chrono::microseconds>(end - start);
    
    cout << "Shell's sequence (n/2, n/4, ...): " << duration1.count() << " μs" << endl;
    cout << "Knuth's sequence (3k+1): " << duration2.count() << " μs" << endl;
    cout << "Hibbard's sequence (2^k-1): " << duration3.count() << " μs" << endl;
}

// Utility functions
void printArray(const vector<int>& arr, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < arr.size(); i++) {
        cout << arr[i];
        if (i < arr.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

void printGaps(const vector<int>& gaps, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    cout << "[";
    for (int i = 0; i < gaps.size(); i++) {
        cout << gaps[i];
        if (i < gaps.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
}

// Example usage and testing
int main() {
    // Test basic shell sort
    vector<int> arr1 = {64, 34, 25, 12, 22, 11, 90};
    cout << "=== Basic Shell Sort ===" << endl;
    printArray(arr1, "Original");
    
    shellSort(arr1);
    printArray(arr1, "Sorted");
    
    // Test shell sort with statistics
    vector<int> arr2 = {5, 2, 4, 6, 1, 3};
    cout << "\n=== Shell Sort with Statistics ===" << endl;
    printArray(arr2, "Original");
    
    ShellSortStats stats = shellSortWithStats(arr2);
    printArray(arr2, "Sorted");
    
    cout << "Statistics:" << endl;
    cout << "  Total comparisons: " << stats.totalComparisons << endl;
    cout << "  Total swaps: " << stats.totalSwaps << endl;
    printGaps(stats.gapsUsed, "  Gaps used");
    
    cout << "  State history:" << endl;
    for (int i = 0; i < stats.stateHistory.size(); i++) {
        if (i == 0) {
            cout << "    Initial: ";
        } else {
            cout << "    Gap " << stats.gapsUsed[i-1] << ": ";
        }
        printArray(stats.stateHistory[i], "");
    }
    
    // Test Knuth's gap sequence
    vector<int> arr3 = {23, 45, 16, 37, 3, 99, 22};
    cout << "\n=== Shell Sort with Knuth's Sequence ===" << endl;
    printArray(arr3, "Original");
    
    shellSortKnuth(arr3);
    printArray(arr3, "Sorted");
    
    // Test Hibbard's gap sequence
    vector<int> arr4 = {88, 12, 45, 67, 23, 91, 34};
    cout << "\n=== Shell Sort with Hibbard's Sequence ===" << endl;
    printArray(arr4, "Original");
    
    shellSortHibbard(arr4);
    printArray(arr4, "Sorted");
    
    // Test custom gap sequence
    vector<int> arr5 = {9, 8, 7, 6, 5, 4, 3, 2, 1};
    vector<int> customGaps = {5, 3, 1};  // Custom gap sequence
    cout << "\n=== Shell Sort with Custom Gaps ===" << endl;
    printArray(arr5, "Original");
    printGaps(customGaps, "Custom gaps");
    
    shellSortCustomGaps(arr5, customGaps);
    printArray(arr5, "Sorted");
    
    // Test generic shell sort with strings
    vector<string> words = {"banana", "apple", "cherry", "date"};
    cout << "\n=== Generic Shell Sort (Strings) ===" << endl;
    cout << "Original: [";
    for (int i = 0; i < words.size(); i++) {
        cout << "\"" << words[i] << "\"";
        if (i < words.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    genericShellSort(words);
    
    cout << "Sorted: [";
    for (int i = 0; i < words.size(); i++) {
        cout << "\"" << words[i] << "\"";
        if (i < words.size() - 1) cout << ", ";
    }
    cout << "]" << endl;
    
    // Performance comparison of gap sequences
    vector<int> largeArray;
    for (int i = 100; i > 0; i--) {
        largeArray.push_back(i);
    }
    
    compareGapSequences(largeArray);
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity (depends on gap sequence)</h3>
            <ul>
                <li><strong>Shell's Original (n/2^k):</strong> O(n²) - Same as insertion sort worst case</li>
                <li><strong>Knuth's Sequence (3k+1):</strong> O(n^(3/2)) - Better performance</li>
                <li><strong>Hibbard's Sequence (2^k-1):</strong> O(n^(3/2)) - Proven upper bound</li>
                <li><strong>Sedgewick's Sequence:</strong> O(n^(4/3)) - Even better performance</li>
                <li><strong>Best Known:</strong> O(n log² n) - With optimal gap sequences</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Auxiliary Space:</strong> O(1) - In-place sorting algorithm</li>
                <li><strong>Gap Storage:</strong> O(log n) - For storing gap sequence</li>
                <li><strong>Recursion:</strong> None - Iterative algorithm</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Stable:</strong> No - Can change relative order of equal elements</li>
                <li><strong>In-place:</strong> Yes - Sorts with constant extra space</li>
                <li><strong>Adaptive:</strong> Partially - Better on nearly sorted data</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through shell sort on array [64, 34, 25, 12, 22, 11, 90] using Shell's original sequence:
        </p>
        
        <div class="code-block">
Initial: [64, 34, 25, 12, 22, 11, 90]
Array size: n = 7

Gap Sequence: 7/2=3, 3/2=1

Pass 1: Gap = 3
Compare elements 3 positions apart:
- Compare arr[0]=64 with arr[3]=12: 64 > 12, swap
  [12, 34, 25, 64, 22, 11, 90]
- Compare arr[1]=34 with arr[4]=22: 34 > 22, swap
  [12, 22, 25, 64, 34, 11, 90]
- Compare arr[2]=25 with arr[5]=11: 25 > 11, swap
  [12, 22, 11, 64, 34, 25, 90]
- Continue insertion sort with gap=3:
  [12, 22, 11, 64, 34, 25, 90]

Pass 2: Gap = 1 (regular insertion sort)
- Insert 22: [12, 22, 11, 64, 34, 25, 90]
- Insert 11: [11, 12, 22, 64, 34, 25, 90]
- Insert 64: [11, 12, 22, 64, 34, 25, 90]
- Insert 34: [11, 12, 22, 34, 64, 25, 90]
- Insert 25: [11, 12, 22, 25, 34, 64, 90]
- Insert 90: [11, 12, 22, 25, 34, 64, 90]

Final: [11, 12, 22, 25, 34, 64, 90]

Key insight: The gap=3 pass pre-sorted the array, making the final 
insertion sort pass much more efficient.
        </div>
        
        <h2 class="section-title">Gap Sequences</h2>
        
        <p class="academic-text">
            The choice of gap sequence is crucial for shell sort's performance:
        </p>
        
        <div class="definition-box">
            <strong>Shell's Original:</strong> n/2, n/4, n/8, ..., 1<br>
            • Simple but not optimal<br>
            • O(n²) worst-case complexity<br><br>
            
            <strong>Knuth's Sequence:</strong> 1, 4, 13, 40, 121, ... (3^k-1)/2<br>
            • Better performance than Shell's<br>
            • O(n^(3/2)) complexity<br><br>
            
            <strong>Hibbard's Sequence:</strong> 1, 3, 7, 15, 31, ... (2^k-1)<br>
            • Proven O(n^(3/2)) upper bound<br>
            • Good theoretical properties<br><br>
            
            <strong>Sedgewick's Sequence:</strong> 1, 5, 19, 41, 109, ...<br>
            • Best practical performance<br>
            • O(n^(4/3)) average case
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Shell sort is particularly useful in these scenarios:
        </p>
        
        <ul>
            <li><strong>Medium-sized Arrays:</strong> Better than insertion sort, simpler than quicksort</li>
            <li><strong>Embedded Systems:</strong> Simple implementation with good performance</li>
            <li><strong>Nearly Sorted Data:</strong> Performs well on partially sorted arrays</li>
            <li><strong>Memory-Constrained Systems:</strong> In-place sorting with O(1) space</li>
            <li><strong>Educational Purposes:</strong> Good introduction to advanced sorting concepts</li>
            <li><strong>Hybrid Algorithms:</strong> Used as subroutine in other sorting methods</li>
        </ul>
        
        <h2 class="section-title">When to Use Shell Sort</h2>
        
        <div class="definition-box">
            <strong>Use Shell Sort When:</strong><br>
            • Array size is medium (hundreds to thousands of elements)<br>
            • Memory usage must be minimal (O(1) space)<br>
            • Implementation simplicity is important<br>
            • Data is partially sorted<br>
            • Consistent performance is needed<br><br>
            
            <strong>Don't Use Shell Sort When:</strong><br>
            • Array is very large (quicksort/mergesort better)<br>
            • Stability is required<br>
            • Optimal worst-case performance is critical<br>
            • Working with very small arrays (insertion sort better)
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Gap Sequence Choice:</strong> Poor gap sequence leads to O(n²) performance</li>
            <li><strong>Gap Calculation:</strong> Ensure gaps are calculated correctly</li>
            <li><strong>Final Gap:</strong> Always end with gap = 1 to ensure complete sorting</li>
            <li><strong>Index Bounds:</strong> Check array bounds when accessing gap-separated elements</li>
            <li><strong>Not Stable:</strong> Don't use when stability is required</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Gap Concept:</strong> Explain how gaps allow distant element exchanges</li>
            <li><strong>Insertion Sort Extension:</strong> Show how it generalizes insertion sort</li>
            <li><strong>Gap Sequences:</strong> Know different sequences and their complexities</li>
            <li><strong>Performance:</strong> Discuss O(n^(3/2)) with good gap sequences</li>
            <li><strong>Practical Use:</strong> Mention use in embedded systems and medium arrays</li>
            <li><strong>Comparison:</strong> Contrast with other O(n log n) algorithms</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Shell sort generalizes insertion sort by using gap sequences</li>
                <li>Performance heavily depends on the choice of gap sequence</li>
                <li>Achieves O(n^(3/2)) complexity with good gap sequences</li>
                <li>In-place sorting algorithm with O(1) auxiliary space</li>
                <li>Not stable but performs well on partially sorted data</li>
                <li>Good balance between simplicity and performance for medium arrays</li>
                <li>Historical importance as first algorithm to break O(n²) barrier</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch18">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 18</div>
        <h1 class="chapter-title">Breadth-First Search (BFS)</h1>
        
        <p class="academic-text">
            Breadth-First Search (BFS) is a fundamental graph traversal algorithm that explores vertices in layers, visiting all vertices at distance k before visiting any vertex at distance k+1 from the source. BFS uses a queue data structure and guarantees finding the shortest path in unweighted graphs. It's essential for many graph problems including shortest path, connected components, and level-order traversals.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given a graph G = (V, E) and a source vertex s, traverse all reachable vertices from s in breadth-first order. The algorithm should visit vertices level by level, exploring all neighbors of the current level before moving to the next level.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Graph G and source vertex s<br>
            <strong>Output:</strong> BFS traversal order and distances from source<br>
            <strong>Graph Type:</strong> Works on both directed and undirected graphs
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            BFS works through these phases:
        </p>
        
        <ol>
            <li><strong>Initialize:</strong> Mark source as visited, add to queue</li>
            <li><strong>Process Queue:</strong> While queue is not empty, dequeue vertex</li>
            <li><strong>Explore Neighbors:</strong> For each unvisited neighbor, mark visited and enqueue</li>
            <li><strong>Repeat:</strong> Continue until queue is empty</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: BFS(graph, source)
1. visited[all vertices] = false
2. distance[all vertices] = infinity
3. parent[all vertices] = null
4. 
5. queue = empty queue
6. visited[source] = true
7. distance[source] = 0
8. queue.enqueue(source)
9. 
10. while queue is not empty do
11.     current = queue.dequeue()
12.     print current  // Process current vertex
13.     
14.     for each neighbor of current do
15.         if not visited[neighbor] then
16.             visited[neighbor] = true
17.             distance[neighbor] = distance[current] + 1
18.             parent[neighbor] = current
19.             queue.enqueue(neighbor)
20.         end if
21.     end for
22. end while
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <queue>
#include <unordered_map>
#include <unordered_set>
using namespace std;

/**
 * Graph representation using adjacency list
 */
class Graph {
private:
    unordered_map<int, vector<int>> adjList;
    bool isDirected;
    
public:
    Graph(bool directed = false) : isDirected(directed) {}
    
    void addEdge(int u, int v) {
        adjList[u].push_back(v);
        if (!isDirected) {
            adjList[v].push_back(u);
        }
    }
    
    vector<int> getNeighbors(int vertex) {
        return adjList[vertex];
    }
    
    vector<int> getAllVertices() {
        vector<int> vertices;
        for (auto& pair : adjList) {
            vertices.push_back(pair.first);
        }
        return vertices;
    }
    
    void printGraph() {
        for (auto& pair : adjList) {
            cout << pair.first << " -> ";
            for (int neighbor : pair.second) {
                cout << neighbor << " ";
            }
            cout << endl;
        }
    }
};

/**
 * Basic BFS Implementation
 * Returns BFS traversal order
 */
vector<int> bfs(Graph& graph, int source) {
    vector<int> traversal;
    unordered_set<int> visited;
    queue<int> q;
    
    // Initialize
    visited.insert(source);
    q.push(source);
    
    while (!q.empty()) {
        int current = q.front();
        q.pop();
        
        traversal.push_back(current);
        
        // Explore neighbors
        for (int neighbor : graph.getNeighbors(current)) {
            if (visited.find(neighbor) == visited.end()) {
                visited.insert(neighbor);
                q.push(neighbor);
            }
        }
    }
    
    return traversal;
}

/**
 * BFS with Distance and Parent Tracking
 * Returns distances and parent pointers for path reconstruction
 */
struct BFSResult {
    unordered_map<int, int> distances;
    unordered_map<int, int> parents;
    vector<int> traversal;
};

BFSResult bfsWithDetails(Graph& graph, int source) {
    BFSResult result;
    unordered_set<int> visited;
    queue<int> q;
    
    // Initialize source
    visited.insert(source);
    result.distances[source] = 0;
    result.parents[source] = -1;  // Source has no parent
    q.push(source);
    
    while (!q.empty()) {
        int current = q.front();
        q.pop();
        
        result.traversal.push_back(current);
        
        // Explore neighbors
        for (int neighbor : graph.getNeighbors(current)) {
            if (visited.find(neighbor) == visited.end()) {
                visited.insert(neighbor);
                result.distances[neighbor] = result.distances[current] + 1;
                result.parents[neighbor] = current;
                q.push(neighbor);
            }
        }
    }
    
    return result;
}

/**
 * BFS for Shortest Path
 * Returns shortest path between source and target
 */
vector<int> bfsShortestPath(Graph& graph, int source, int target) {
    if (source == target) return {source};
    
    unordered_set<int> visited;
    unordered_map<int, int> parent;
    queue<int> q;
    
    visited.insert(source);
    parent[source] = -1;
    q.push(source);
    
    while (!q.empty()) {
        int current = q.front();
        q.pop();
        
        if (current == target) {
            // Reconstruct path
            vector<int> path;
            int node = target;
            while (node != -1) {
                path.push_back(node);
                node = parent[node];
            }
            reverse(path.begin(), path.end());
            return path;
        }
        
        for (int neighbor : graph.getNeighbors(current)) {
            if (visited.find(neighbor) == visited.end()) {
                visited.insert(neighbor);
                parent[neighbor] = current;
                q.push(neighbor);
            }
        }
    }
    
    return {};  // No path found
}

/**
 * BFS for Connected Components
 * Returns all connected components in undirected graph
 */
vector<vector<int>> bfsConnectedComponents(Graph& graph) {
    vector<vector<int>> components;
    unordered_set<int> globalVisited;
    
    for (int vertex : graph.getAllVertices()) {
        if (globalVisited.find(vertex) == globalVisited.end()) {
            // Start new component
            vector<int> component;
            queue<int> q;
            
            globalVisited.insert(vertex);
            q.push(vertex);
            
            while (!q.empty()) {
                int current = q.front();
                q.pop();
                component.push_back(current);
                
                for (int neighbor : graph.getNeighbors(current)) {
                    if (globalVisited.find(neighbor) == globalVisited.end()) {
                        globalVisited.insert(neighbor);
                        q.push(neighbor);
                    }
                }
            }
            
            components.push_back(component);
        }
    }
    
    return components;
}

/**
 * BFS Level Order Traversal
 * Returns vertices grouped by their distance from source
 */
vector<vector<int>> bfsLevelOrder(Graph& graph, int source) {
    vector<vector<int>> levels;
    unordered_set<int> visited;
    queue<int> q;
    
    visited.insert(source);
    q.push(source);
    
    while (!q.empty()) {
        int levelSize = q.size();
        vector<int> currentLevel;
        
        // Process all vertices at current level
        for (int i = 0; i < levelSize; i++) {
            int current = q.front();
            q.pop();
            currentLevel.push_back(current);
            
            // Add neighbors for next level
            for (int neighbor : graph.getNeighbors(current)) {
                if (visited.find(neighbor) == visited.end()) {
                    visited.insert(neighbor);
                    q.push(neighbor);
                }
            }
        }
        
        levels.push_back(currentLevel);
    }
    
    return levels;
}

/**
 * BFS for Bipartite Graph Check
 * Returns true if graph is bipartite, false otherwise
 */
bool isBipartiteBFS(Graph& graph, int source) {
    unordered_map<int, int> color;  // 0 or 1
    queue<int> q;
    
    color[source] = 0;
    q.push(source);
    
    while (!q.empty()) {
        int current = q.front();
        q.pop();
        
        for (int neighbor : graph.getNeighbors(current)) {
            if (color.find(neighbor) == color.end()) {
                // Color with opposite color
                color[neighbor] = 1 - color[current];
                q.push(neighbor);
            } else if (color[neighbor] == color[current]) {
                // Same color as current - not bipartite
                return false;
            }
        }
    }
    
    return true;
}

/**
 * Multi-source BFS
 * BFS from multiple sources simultaneously
 */
vector<int> multiSourceBFS(Graph& graph, vector<int> sources) {
    vector<int> traversal;
    unordered_set<int> visited;
    unordered_map<int, int> distance;
    queue<int> q;
    
    // Initialize all sources
    for (int source : sources) {
        visited.insert(source);
        distance[source] = 0;
        q.push(source);
    }
    
    while (!q.empty()) {
        int current = q.front();
        q.pop();
        traversal.push_back(current);
        
        for (int neighbor : graph.getNeighbors(current)) {
            if (visited.find(neighbor) == visited.end()) {
                visited.insert(neighbor);
                distance[neighbor] = distance[current] + 1;
                q.push(neighbor);
            }
        }
    }
    
    return traversal;
}

/**
 * BFS with Statistics
 * Tracks various metrics during traversal
 */
struct BFSStats {
    int verticesVisited;
    int edgesExplored;
    int maxQueueSize;
    vector<int> queueSizeHistory;
    unordered_map<int, int> visitOrder;
};

BFSStats bfsWithStats(Graph& graph, int source) {
    BFSStats stats = {0, 0, 0, {}, {}};
    unordered_set<int> visited;
    queue<int> q;
    
    visited.insert(source);
    q.push(source);
    stats.verticesVisited = 1;
    stats.visitOrder[source] = 0;
    
    while (!q.empty()) {
        // Track queue size
        stats.maxQueueSize = max(stats.maxQueueSize, (int)q.size());
        stats.queueSizeHistory.push_back(q.size());
        
        int current = q.front();
        q.pop();
        
        for (int neighbor : graph.getNeighbors(current)) {
            stats.edgesExplored++;
            
            if (visited.find(neighbor) == visited.end()) {
                visited.insert(neighbor);
                stats.visitOrder[neighbor] = stats.verticesVisited;
                stats.verticesVisited++;
                q.push(neighbor);
            }
        }
    }
    
    return stats;
}

// Utility functions
void printPath(const vector<int>& path) {
    if (path.empty()) {
        cout << "No path found" << endl;
        return;
    }
    
    for (int i = 0; i < path.size(); i++) {
        cout << path[i];
        if (i < path.size() - 1) cout << " -> ";
    }
    cout << endl;
}

void printTraversal(const vector<int>& traversal, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    for (int i = 0; i < traversal.size(); i++) {
        cout << traversal[i];
        if (i < traversal.size() - 1) cout << " ";
    }
    cout << endl;
}

// Example usage and testing
int main() {
    // Create sample graph
    Graph graph(false);  // Undirected graph
    
    // Add edges to create a connected graph
    graph.addEdge(0, 1);
    graph.addEdge(0, 2);
    graph.addEdge(1, 3);
    graph.addEdge(1, 4);
    graph.addEdge(2, 5);
    graph.addEdge(2, 6);
    graph.addEdge(3, 7);
    graph.addEdge(4, 7);
    
    cout << "=== Graph Structure ===" << endl;
    graph.printGraph();
    
    // Test basic BFS
    cout << "\n=== Basic BFS from vertex 0 ===" << endl;
    vector<int> traversal = bfs(graph, 0);
    printTraversal(traversal, "BFS Traversal");
    
    // Test BFS with details
    cout << "\n=== BFS with Distance and Parent Tracking ===" << endl;
    BFSResult result = bfsWithDetails(graph, 0);
    printTraversal(result.traversal, "Traversal");
    
    cout << "Distances from source 0:" << endl;
    for (auto& pair : result.distances) {
        cout << "  Vertex " << pair.first << ": distance " << pair.second << endl;
    }
    
    // Test shortest path
    cout << "\n=== Shortest Path from 0 to 7 ===" << endl;
    vector<int> path = bfsShortestPath(graph, 0, 7);
    cout << "Path: ";
    printPath(path);
    cout << "Path length: " << (path.empty() ? 0 : path.size() - 1) << endl;
    
    // Test level order traversal
    cout << "\n=== Level Order Traversal from vertex 0 ===" << endl;
    vector<vector<int>> levels = bfsLevelOrder(graph, 0);
    for (int i = 0; i < levels.size(); i++) {
        cout << "Level " << i << ": ";
        for (int vertex : levels[i]) {
            cout << vertex << " ";
        }
        cout << endl;
    }
    
    // Test connected components
    cout << "\n=== Connected Components ===" << endl;
    vector<vector<int>> components = bfsConnectedComponents(graph);
    for (int i = 0; i < components.size(); i++) {
        cout << "Component " << i + 1 << ": ";
        for (int vertex : components[i]) {
            cout << vertex << " ";
        }
        cout << endl;
    }
    
    // Test bipartite check
    cout << "\n=== Bipartite Check ===" << endl;
    bool bipartite = isBipartiteBFS(graph, 0);
    cout << "Graph is " << (bipartite ? "bipartite" : "not bipartite") << endl;
    
    // Test multi-source BFS
    cout << "\n=== Multi-source BFS from vertices {0, 7} ===" << endl;
    vector<int> multiTraversal = multiSourceBFS(graph, {0, 7});
    printTraversal(multiTraversal, "Multi-source BFS");
    
    // Test BFS with statistics
    cout << "\n=== BFS Statistics ===" << endl;
    BFSStats stats = bfsWithStats(graph, 0);
    cout << "Vertices visited: " << stats.verticesVisited << endl;
    cout << "Edges explored: " << stats.edgesExplored << endl;
    cout << "Max queue size: " << stats.maxQueueSize << endl;
    cout << "Queue size history: ";
    for (int size : stats.queueSizeHistory) {
        cout << size << " ";
    }
    cout << endl;
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Adjacency List:</strong> O(V + E) - Each vertex and edge visited once</li>
                <li><strong>Adjacency Matrix:</strong> O(V²) - Must check all possible edges</li>
                <li><strong>Dense Graphs:</strong> O(V²) when E ≈ V²</li>
                <li><strong>Sparse Graphs:</strong> O(V) when E ≈ V</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Queue Storage:</strong> O(V) - Maximum vertices in queue</li>
                <li><strong>Visited Array:</strong> O(V) - Track visited vertices</li>
                <li><strong>Distance/Parent Arrays:</strong> O(V) - Additional information</li>
                <li><strong>Total Space:</strong> O(V) auxiliary space</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Completeness:</strong> Always finds solution if one exists</li>
                <li><strong>Optimality:</strong> Finds shortest path in unweighted graphs</li>
                <li><strong>Memory Usage:</strong> Can use significant memory for wide graphs</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through BFS on a simple graph starting from vertex 0:
        </p>
        
        <div class="code-block">
Graph: 0 -- 1 -- 3
       |    |    |
       2 -- 4 -- 5

BFS from vertex 0:

Initial: Queue = [0], Visited = {0}, Distance[0] = 0

Step 1: Dequeue 0
- Neighbors of 0: [1, 2]
- Add 1: Queue = [1], Visited = {0, 1}, Distance[1] = 1
- Add 2: Queue = [1, 2], Visited = {0, 1, 2}, Distance[2] = 1
- Traversal: [0]

Step 2: Dequeue 1
- Neighbors of 1: [0, 3, 4] (0 already visited)
- Add 3: Queue = [2, 3], Visited = {0, 1, 2, 3}, Distance[3] = 2
- Add 4: Queue = [2, 3, 4], Visited = {0, 1, 2, 3, 4}, Distance[4] = 2
- Traversal: [0, 1]

Step 3: Dequeue 2
- Neighbors of 2: [0, 4] (0 already visited, 4 already visited)
- No new vertices added
- Traversal: [0, 1, 2]

Step 4: Dequeue 3
- Neighbors of 3: [1, 5] (1 already visited)
- Add 5: Queue = [4, 5], Visited = {0, 1, 2, 3, 4, 5}, Distance[5] = 3
- Traversal: [0, 1, 2, 3]

Step 5: Dequeue 4
- Neighbors of 4: [1, 2, 5] (all already visited)
- No new vertices added
- Traversal: [0, 1, 2, 3, 4]

Step 6: Dequeue 5
- Neighbors of 5: [3, 4] (all already visited)
- Queue becomes empty
- Traversal: [0, 1, 2, 3, 4, 5]

Final BFS order: 0 → 1 → 2 → 3 → 4 → 5
Distances: 0(0), 1(1), 2(1), 3(2), 4(2), 5(3)
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            BFS has numerous important applications:
        </p>
        
        <ul>
            <li><strong>Shortest Path:</strong> Finding shortest path in unweighted graphs</li>
            <li><strong>Connected Components:</strong> Finding all connected components</li>
            <li><strong>Bipartite Testing:</strong> Checking if graph is bipartite</li>
            <li><strong>Level Order Traversal:</strong> Tree and graph level-wise processing</li>
            <li><strong>Web Crawling:</strong> Crawling web pages level by level</li>
            <li><strong>Social Networks:</strong> Finding friends at distance k</li>
            <li><strong>GPS Navigation:</strong> Finding shortest routes</li>
            <li><strong>Puzzle Solving:</strong> State space search problems</li>
        </ul>
        
        <h2 class="section-title">BFS vs DFS Comparison</h2>
        
        <div class="definition-box">
            <strong>BFS Advantages:</strong><br>
            • Finds shortest path in unweighted graphs<br>
            • Good for finding nodes close to source<br>
            • Level-wise exploration<br>
            • Optimal for minimum spanning tree problems<br><br>
            
            <strong>BFS Disadvantages:</strong><br>
            • Higher memory usage (stores all nodes at current level)<br>
            • Not suitable for decision tree problems<br>
            • May be slower for deep, narrow graphs<br><br>
            
            <strong>When to Use BFS:</strong><br>
            • Finding shortest path<br>
            • Level order traversal<br>
            • Finding all nodes within k distance<br>
            • Bipartite graph testing
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Forgetting to Mark Visited:</strong> Can cause infinite loops</li>
            <li><strong>Wrong Queue Operations:</strong> Using stack instead of queue gives DFS</li>
            <li><strong>Not Handling Disconnected Graphs:</strong> May miss some vertices</li>
            <li><strong>Memory Issues:</strong> BFS can use lots of memory for wide graphs</li>
            <li><strong>Path Reconstruction:</strong> Forgetting to store parent pointers</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Queue Usage:</strong> Emphasize FIFO nature for level-wise exploration</li>
            <li><strong>Shortest Path:</strong> Highlight optimality for unweighted graphs</li>
            <li><strong>Time Complexity:</strong> Explain O(V + E) for adjacency list</li>
            <li><strong>Applications:</strong> Mention real-world uses like GPS and social networks</li>
            <li><strong>Variations:</strong> Know multi-source BFS and bidirectional BFS</li>
            <li><strong>Implementation:</strong> Be able to code both basic and advanced versions</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>BFS explores vertices level by level using a queue data structure</li>
                <li>Guarantees shortest path in unweighted graphs</li>
                <li>Time complexity O(V + E) with adjacency list representation</li>
                <li>Space complexity O(V) for queue and auxiliary arrays</li>
                <li>Essential for connectivity, shortest path, and level-order problems</li>
                <li>Foundation for many advanced graph algorithms</li>
                <li>Can be extended for multi-source and bidirectional search</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch19">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 19</div>
        <h1 class="chapter-title">Depth-First Search (DFS)</h1>
        
        <p class="academic-text">
            Depth-First Search (DFS) is a fundamental graph traversal algorithm that explores as far as possible along each branch before backtracking. DFS uses a stack data structure (either explicit or through recursion) and is essential for many graph problems including cycle detection, topological sorting, and finding strongly connected components. Unlike BFS, DFS goes deep into the graph before exploring breadth.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given a graph G = (V, E) and a source vertex s, traverse all reachable vertices from s in depth-first order. The algorithm should explore each branch as deeply as possible before backtracking to explore other branches.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Graph G and source vertex s<br>
            <strong>Output:</strong> DFS traversal order and discovery/finish times<br>
            <strong>Graph Type:</strong> Works on both directed and undirected graphs
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            DFS works through these phases:
        </p>
        
        <ol>
            <li><strong>Initialize:</strong> Mark all vertices as unvisited</li>
            <li><strong>Visit Vertex:</strong> Mark current vertex as visited</li>
            <li><strong>Explore Recursively:</strong> For each unvisited neighbor, recursively apply DFS</li>
            <li><strong>Backtrack:</strong> Return when all neighbors are visited</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: DFS(graph, source)
1. visited[all vertices] = false
2. time = 0
3. DFS-Visit(source)

Algorithm: DFS-Visit(vertex)
1. visited[vertex] = true
2. discovery[vertex] = ++time
3. print vertex  // Process vertex
4. 
5. for each neighbor of vertex do
6.     if not visited[neighbor] then
7.         parent[neighbor] = vertex
8.         DFS-Visit(neighbor)
9.     end if
10. end for
11. 
12. finish[vertex] = ++time
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <stack>
#include <unordered_map>
#include <unordered_set>
using namespace std;

/**
 * Graph representation using adjacency list
 */
class Graph {
private:
    unordered_map<int, vector<int>> adjList;
    bool isDirected;
    
public:
    Graph(bool directed = false) : isDirected(directed) {}
    
    void addEdge(int u, int v) {
        adjList[u].push_back(v);
        if (!isDirected) {
            adjList[v].push_back(u);
        }
    }
    
    vector<int> getNeighbors(int vertex) {
        return adjList[vertex];
    }
    
    vector<int> getAllVertices() {
        vector<int> vertices;
        for (auto& pair : adjList) {
            vertices.push_back(pair.first);
        }
        return vertices;
    }
    
    void printGraph() {
        for (auto& pair : adjList) {
            cout << pair.first << " -> ";
            for (int neighbor : pair.second) {
                cout << neighbor << " ";
            }
            cout << endl;
        }
    }
};

/**
 * Basic Recursive DFS Implementation
 */
class DFSRecursive {
private:
    unordered_set<int> visited;
    vector<int> traversal;
    
    void dfsVisit(Graph& graph, int vertex) {
        visited.insert(vertex);
        traversal.push_back(vertex);
        
        for (int neighbor : graph.getNeighbors(vertex)) {
            if (visited.find(neighbor) == visited.end()) {
                dfsVisit(graph, neighbor);
            }
        }
    }
    
public:
    vector<int> dfs(Graph& graph, int source) {
        visited.clear();
        traversal.clear();
        dfsVisit(graph, source);
        return traversal;
    }
};

/**
 * Iterative DFS Implementation using Stack
 */
vector<int> dfsIterative(Graph& graph, int source) {
    vector<int> traversal;
    unordered_set<int> visited;
    stack<int> stk;
    
    stk.push(source);
    
    while (!stk.empty()) {
        int current = stk.top();
        stk.pop();
        
        if (visited.find(current) == visited.end()) {
            visited.insert(current);
            traversal.push_back(current);
            
            // Add neighbors in reverse order to maintain left-to-right traversal
            vector<int> neighbors = graph.getNeighbors(current);
            for (int i = neighbors.size() - 1; i >= 0; i--) {
                if (visited.find(neighbors[i]) == visited.end()) {
                    stk.push(neighbors[i]);
                }
            }
        }
    }
    
    return traversal;
}

/**
 * DFS with Discovery and Finish Times
 */
struct DFSTimestamps {
    unordered_map<int, int> discovery;
    unordered_map<int, int> finish;
    unordered_map<int, int> parent;
    vector<int> traversal;
    int time;
};

class DFSWithTimes {
private:
    unordered_set<int> visited;
    DFSTimestamps result;
    
    void dfsVisit(Graph& graph, int vertex) {
        visited.insert(vertex);
        result.discovery[vertex] = ++result.time;
        result.traversal.push_back(vertex);
        
        for (int neighbor : graph.getNeighbors(vertex)) {
            if (visited.find(neighbor) == visited.end()) {
                result.parent[neighbor] = vertex;
                dfsVisit(graph, neighbor);
            }
        }
        
        result.finish[vertex] = ++result.time;
    }
    
public:
    DFSTimestamps dfs(Graph& graph, int source) {
        visited.clear();
        result = {{}, {}, {}, {}, 0};
        result.parent[source] = -1;
        dfsVisit(graph, source);
        return result;
    }
};

/**
 * DFS for Cycle Detection in Undirected Graph
 */
bool hasCycleUndirected(Graph& graph, int source) {
    unordered_set<int> visited;
    unordered_map<int, int> parent;
    
    function<bool(int)> dfsVisit = [&](int vertex) -> bool {
        visited.insert(vertex);
        
        for (int neighbor : graph.getNeighbors(vertex)) {
            if (visited.find(neighbor) == visited.end()) {
                parent[neighbor] = vertex;
                if (dfsVisit(neighbor)) return true;
            } else if (parent[vertex] != neighbor) {
                // Back edge found (not to parent)
                return true;
            }
        }
        return false;
    };
    
    parent[source] = -1;
    return dfsVisit(source);
}

/**
 * DFS for Cycle Detection in Directed Graph
 */
bool hasCycleDirected(Graph& graph) {
    unordered_set<int> visited;
    unordered_set<int> recStack;  // Recursion stack
    
    function<bool(int)> dfsVisit = [&](int vertex) -> bool {
        visited.insert(vertex);
        recStack.insert(vertex);
        
        for (int neighbor : graph.getNeighbors(vertex)) {
            if (recStack.find(neighbor) != recStack.end()) {
                // Back edge to vertex in current path
                return true;
            }
            if (visited.find(neighbor) == visited.end() && dfsVisit(neighbor)) {
                return true;
            }
        }
        
        recStack.erase(vertex);
        return false;
    };
    
    for (int vertex : graph.getAllVertices()) {
        if (visited.find(vertex) == visited.end()) {
            if (dfsVisit(vertex)) return true;
        }
    }
    
    return false;
}

/**
 * DFS for Topological Sorting
 */
vector<int> topologicalSort(Graph& graph) {
    unordered_set<int> visited;
    stack<int> finishStack;
    
    function<void(int)> dfsVisit = [&](int vertex) {
        visited.insert(vertex);
        
        for (int neighbor : graph.getNeighbors(vertex)) {
            if (visited.find(neighbor) == visited.end()) {
                dfsVisit(neighbor);
            }
        }
        
        finishStack.push(vertex);  // Add to stack when finished
    };
    
    // Visit all vertices
    for (int vertex : graph.getAllVertices()) {
        if (visited.find(vertex) == visited.end()) {
            dfsVisit(vertex);
        }
    }
    
    // Pop from stack to get topological order
    vector<int> topoOrder;
    while (!finishStack.empty()) {
        topoOrder.push_back(finishStack.top());
        finishStack.pop();
    }
    
    return topoOrder;
}

/**
 * DFS for Connected Components
 */
vector<vector<int>> dfsConnectedComponents(Graph& graph) {
    vector<vector<int>> components;
    unordered_set<int> globalVisited;
    
    function<void(int, vector<int>&)> dfsVisit = [&](int vertex, vector<int>& component) {
        globalVisited.insert(vertex);
        component.push_back(vertex);
        
        for (int neighbor : graph.getNeighbors(vertex)) {
            if (globalVisited.find(neighbor) == globalVisited.end()) {
                dfsVisit(neighbor, component);
            }
        }
    };
    
    for (int vertex : graph.getAllVertices()) {
        if (globalVisited.find(vertex) == globalVisited.end()) {
            vector<int> component;
            dfsVisit(vertex, component);
            components.push_back(component);
        }
    }
    
    return components;
}

/**
 * DFS for Path Finding
 */
vector<int> dfsPath(Graph& graph, int source, int target) {
    unordered_set<int> visited;
    vector<int> path;
    bool found = false;
    
    function<void(int)> dfsVisit = [&](int vertex) {
        if (found) return;
        
        visited.insert(vertex);
        path.push_back(vertex);
        
        if (vertex == target) {
            found = true;
            return;
        }
        
        for (int neighbor : graph.getNeighbors(vertex)) {
            if (visited.find(neighbor) == visited.end()) {
                dfsVisit(neighbor);
                if (found) return;
            }
        }
        
        if (!found) {
            path.pop_back();  // Backtrack
        }
    };
    
    dfsVisit(source);
    return found ? path : vector<int>();
}

/**
 * DFS for Bridge Detection
 */
vector<pair<int, int>> findBridges(Graph& graph) {
    unordered_set<int> visited;
    unordered_map<int, int> discovery;
    unordered_map<int, int> low;
    unordered_map<int, int> parent;
    vector<pair<int, int>> bridges;
    int time = 0;
    
    function<void(int)> dfsVisit = [&](int u) {
        visited.insert(u);
        discovery[u] = low[u] = ++time;
        
        for (int v : graph.getNeighbors(u)) {
            if (visited.find(v) == visited.end()) {
                parent[v] = u;
                dfsVisit(v);
                
                low[u] = min(low[u], low[v]);
                
                // Bridge condition
                if (low[v] > discovery[u]) {
                    bridges.push_back({u, v});
                }
            } else if (v != parent[u]) {
                low[u] = min(low[u], discovery[v]);
            }
        }
    };
    
    for (int vertex : graph.getAllVertices()) {
        if (visited.find(vertex) == visited.end()) {
            parent[vertex] = -1;
            dfsVisit(vertex);
        }
    }
    
    return bridges;
}

/**
 * DFS with Statistics
 */
struct DFSStats {
    int verticesVisited;
    int edgesExplored;
    int maxDepth;
    int currentDepth;
    vector<int> depthHistory;
    unordered_map<int, int> visitOrder;
};

DFSStats dfsWithStats(Graph& graph, int source) {
    DFSStats stats = {0, 0, 0, 0, {}, {}};
    unordered_set<int> visited;
    
    function<void(int)> dfsVisit = [&](int vertex) {
        visited.insert(vertex);
        stats.visitOrder[vertex] = stats.verticesVisited++;
        stats.currentDepth++;
        stats.maxDepth = max(stats.maxDepth, stats.currentDepth);
        stats.depthHistory.push_back(stats.currentDepth);
        
        for (int neighbor : graph.getNeighbors(vertex)) {
            stats.edgesExplored++;
            if (visited.find(neighbor) == visited.end()) {
                dfsVisit(neighbor);
            }
        }
        
        stats.currentDepth--;
    };
    
    dfsVisit(source);
    return stats;
}

// Utility functions
void printPath(const vector<int>& path) {
    if (path.empty()) {
        cout << "No path found" << endl;
        return;
    }
    
    for (int i = 0; i < path.size(); i++) {
        cout << path[i];
        if (i < path.size() - 1) cout << " -> ";
    }
    cout << endl;
}

void printTraversal(const vector<int>& traversal, const string& label = "") {
    if (!label.empty()) cout << label << ": ";
    for (int i = 0; i < traversal.size(); i++) {
        cout << traversal[i];
        if (i < traversal.size() - 1) cout << " ";
    }
    cout << endl;
}

// Example usage and testing
int main() {
    // Create sample graph
    Graph graph(false);  // Undirected graph
    
    // Add edges
    graph.addEdge(0, 1);
    graph.addEdge(0, 2);
    graph.addEdge(1, 3);
    graph.addEdge(1, 4);
    graph.addEdge(2, 5);
    graph.addEdge(2, 6);
    graph.addEdge(3, 7);
    graph.addEdge(4, 7);
    
    cout << "=== Graph Structure ===" << endl;
    graph.printGraph();
    
    // Test recursive DFS
    cout << "\n=== Recursive DFS from vertex 0 ===" << endl;
    DFSRecursive dfsRec;
    vector<int> traversal = dfsRec.dfs(graph, 0);
    printTraversal(traversal, "DFS Traversal");
    
    // Test iterative DFS
    cout << "\n=== Iterative DFS from vertex 0 ===" << endl;
    vector<int> iterTraversal = dfsIterative(graph, 0);
    printTraversal(iterTraversal, "Iterative DFS");
    
    // Test DFS with timestamps
    cout << "\n=== DFS with Discovery and Finish Times ===" << endl;
    DFSWithTimes dfsTime;
    DFSTimestamps timestamps = dfsTime.dfs(graph, 0);
    printTraversal(timestamps.traversal, "Traversal");
    
    cout << "Discovery and Finish Times:" << endl;
    for (int vertex : timestamps.traversal) {
        cout << "  Vertex " << vertex << ": discovery=" << timestamps.discovery[vertex] 
             << ", finish=" << timestamps.finish[vertex] << endl;
    }
    
    // Test cycle detection
    cout << "\n=== Cycle Detection ===" << endl;
    bool hasCycle = hasCycleUndirected(graph, 0);
    cout << "Graph has cycle: " << (hasCycle ? "Yes" : "No") << endl;
    
    // Test path finding
    cout << "\n=== Path Finding from 0 to 7 ===" << endl;
    vector<int> path = dfsPath(graph, 0, 7);
    cout << "Path: ";
    printPath(path);
    
    // Test connected components
    cout << "\n=== Connected Components ===" << endl;
    vector<vector<int>> components = dfsConnectedComponents(graph);
    for (int i = 0; i < components.size(); i++) {
        cout << "Component " << i + 1 << ": ";
        for (int vertex : components[i]) {
            cout << vertex << " ";
        }
        cout << endl;
    }
    
    // Test topological sort on directed graph
    cout << "\n=== Topological Sort (Directed Graph) ===" << endl;
    Graph directedGraph(true);
    directedGraph.addEdge(5, 2);
    directedGraph.addEdge(5, 0);
    directedGraph.addEdge(4, 0);
    directedGraph.addEdge(4, 1);
    directedGraph.addEdge(2, 3);
    directedGraph.addEdge(3, 1);
    
    vector<int> topoOrder = topologicalSort(directedGraph);
    printTraversal(topoOrder, "Topological Order");
    
    // Test bridge detection
    cout << "\n=== Bridge Detection ===" << endl;
    vector<pair<int, int>> bridges = findBridges(graph);
    cout << "Bridges found: " << bridges.size() << endl;
    for (auto& bridge : bridges) {
        cout << "  " << bridge.first << " - " << bridge.second << endl;
    }
    
    // Test DFS with statistics
    cout << "\n=== DFS Statistics ===" << endl;
    DFSStats stats = dfsWithStats(graph, 0);
    cout << "Vertices visited: " << stats.verticesVisited << endl;
    cout << "Edges explored: " << stats.edgesExplored << endl;
    cout << "Maximum depth: " << stats.maxDepth << endl;
    cout << "Depth history: ";
    for (int depth : stats.depthHistory) {
        cout << depth << " ";
    }
    cout << endl;
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Adjacency List:</strong> O(V + E) - Each vertex and edge visited once</li>
                <li><strong>Adjacency Matrix:</strong> O(V²) - Must check all possible edges</li>
                <li><strong>Dense Graphs:</strong> O(V²) when E ≈ V²</li>
                <li><strong>Sparse Graphs:</strong> O(V) when E ≈ V</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Recursive:</strong> O(V) - Recursion stack depth</li>
                <li><strong>Iterative:</strong> O(V) - Explicit stack storage</li>
                <li><strong>Visited Array:</strong> O(V) - Track visited vertices</li>
                <li><strong>Worst Case:</strong> O(V) for linear graphs</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Completeness:</strong> Always finds solution if one exists</li>
                <li><strong>Optimality:</strong> Does not guarantee shortest path</li>
                <li><strong>Memory Usage:</strong> Generally uses less memory than BFS</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through DFS on a simple graph starting from vertex 0:
        </p>
        
        <div class="code-block">
Graph: 0 -- 1 -- 3
       |    |    |
       2 -- 4 -- 5

DFS from vertex 0 (assuming neighbors processed in order):

Initial: Stack = [0], Visited = {}

Step 1: Visit 0
- Mark 0 as visited
- Neighbors of 0: [1, 2]
- Recursively visit 1
- Traversal: [0]

Step 2: Visit 1 (from 0)
- Mark 1 as visited  
- Neighbors of 1: [0, 3, 4] (0 already visited)
- Recursively visit 3
- Traversal: [0, 1]

Step 3: Visit 3 (from 1)
- Mark 3 as visited
- Neighbors of 3: [1, 5] (1 already visited)
- Recursively visit 5
- Traversal: [0, 1, 3]

Step 4: Visit 5 (from 3)
- Mark 5 as visited
- Neighbors of 5: [3, 4] (3 already visited)
- Recursively visit 4
- Traversal: [0, 1, 3, 5]

Step 5: Visit 4 (from 5)
- Mark 4 as visited
- Neighbors of 4: [1, 2, 5] (1 and 5 already visited)
- Recursively visit 2
- Traversal: [0, 1, 3, 5, 4]

Step 6: Visit 2 (from 4)
- Mark 2 as visited
- Neighbors of 2: [0, 4] (both already visited)
- Backtrack to 4, then 5, then 3, then 1, then 0
- Traversal: [0, 1, 3, 5, 4, 2]

Final DFS order: 0 → 1 → 3 → 5 → 4 → 2
Note: Order may vary based on neighbor processing order
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            DFS has numerous important applications:
        </p>
        
        <ul>
            <li><strong>Cycle Detection:</strong> Finding cycles in directed and undirected graphs</li>
            <li><strong>Topological Sorting:</strong> Ordering vertices in DAGs</li>
            <li><strong>Connected Components:</strong> Finding strongly connected components</li>
            <li><strong>Bridge and Articulation Points:</strong> Finding critical edges and vertices</li>
            <li><strong>Maze Solving:</strong> Finding paths through mazes</li>
            <li><strong>Puzzle Solving:</strong> Backtracking algorithms</li>
            <li><strong>Compiler Design:</strong> Syntax analysis and optimization</li>
            <li><strong>AI and Game Trees:</strong> Decision tree exploration</li>
        </ul>
        
        <h2 class="section-title">DFS Variants</h2>
        
        <div class="definition-box">
            <strong>Recursive DFS:</strong><br>
            • Natural implementation using function calls<br>
            • Cleaner code but limited by stack size<br>
            • Risk of stack overflow for deep graphs<br><br>
            
            <strong>Iterative DFS:</strong><br>
            • Uses explicit stack data structure<br>
            • No recursion depth limitations<br>
            • Slightly different traversal order<br><br>
            
            <strong>DFS with Timestamps:</strong><br>
            • Records discovery and finish times<br>
            • Useful for advanced algorithms<br>
            • Enables classification of edges
        </div>
        
        <h2 class="section-title">Edge Classification in DFS</h2>
        
        <p class="academic-text">
            DFS can classify edges based on discovery and finish times:
        </p>
        
        <ul>
            <li><strong>Tree Edges:</strong> Edges in DFS tree (parent to child)</li>
            <li><strong>Back Edges:</strong> Edges to ancestors (indicate cycles)</li>
            <li><strong>Forward Edges:</strong> Edges to descendants (not in tree)</li>
            <li><strong>Cross Edges:</strong> Edges between different subtrees</li>
        </ul>
        
        <h2 class="section-title">When to Use DFS</h2>
        
        <div class="definition-box">
            <strong>Use DFS When:</strong><br>
            • Detecting cycles in graphs<br>
            • Topological sorting of DAGs<br>
            • Finding connected components<br>
            • Solving maze and puzzle problems<br>
            • Implementing backtracking algorithms<br>
            • Memory usage should be minimized<br><br>
            
            <strong>Don't Use DFS When:</strong><br>
            • Finding shortest paths (use BFS)<br>
            • Level-order traversal needed<br>
            • Graph is very deep (stack overflow risk)<br>
            • Breadth-first exploration is required
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Stack Overflow:</strong> Deep recursion can cause stack overflow</li>
            <li><strong>Infinite Loops:</strong> Forgetting to mark vertices as visited</li>
            <li><strong>Wrong Data Structure:</strong> Using queue instead of stack gives BFS</li>
            <li><strong>Cycle Detection Logic:</strong> Different logic for directed vs undirected graphs</li>
            <li><strong>Backtracking Issues:</strong> Not properly undoing changes when backtracking</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Stack Usage:</strong> Emphasize LIFO nature for depth-first exploration</li>
            <li><strong>Recursion vs Iteration:</strong> Know both implementations</li>
            <li><strong>Applications:</strong> Mention cycle detection and topological sorting</li>
            <li><strong>Edge Classification:</strong> Understand tree, back, forward, and cross edges</li>
            <li><strong>Time Complexity:</strong> Explain O(V + E) analysis</li>
            <li><strong>Comparison with BFS:</strong> Know when to use each algorithm</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>DFS explores as deeply as possible before backtracking</li>
                <li>Uses stack data structure (recursive or iterative)</li>
                <li>Time complexity O(V + E) with adjacency list representation</li>
                <li>Space complexity O(V) for recursion stack or explicit stack</li>
                <li>Essential for cycle detection, topological sorting, and connectivity</li>
                <li>Can classify edges and detect various graph properties</li>
                <li>Foundation for many advanced graph algorithms and backtracking</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch20">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 20</div>
        <h1 class="chapter-title">Dijkstra's Algorithm</h1>
        
        <p class="academic-text">
            Dijkstra's algorithm is a graph search algorithm that finds the shortest path from a source vertex to all other vertices in a weighted graph with non-negative edge weights. It uses a greedy approach, always selecting the vertex with the minimum distance that hasn't been processed yet. The algorithm is fundamental in network routing, GPS navigation, and many optimization problems.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given a weighted graph G = (V, E) with non-negative edge weights and a source vertex s, find the shortest path from s to all other vertices. The algorithm should compute the minimum distance and provide a way to reconstruct the actual shortest paths.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Weighted graph G with non-negative weights and source vertex s<br>
            <strong>Output:</strong> Shortest distances and paths from source to all vertices<br>
            <strong>Constraint:</strong> All edge weights must be non-negative
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Dijkstra's algorithm works through these phases:
        </p>
        
        <ol>
            <li><strong>Initialize:</strong> Set distance to source as 0, all others as infinity</li>
            <li><strong>Select Minimum:</strong> Choose unvisited vertex with minimum distance</li>
            <li><strong>Relax Edges:</strong> Update distances to neighbors if shorter path found</li>
            <li><strong>Mark Visited:</strong> Mark current vertex as visited</li>
            <li><strong>Repeat:</strong> Continue until all vertices are visited</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: Dijkstra(graph, source)
1. distance[all vertices] = infinity
2. distance[source] = 0
3. parent[all vertices] = null
4. visited[all vertices] = false
5. priority_queue = all vertices ordered by distance
6. 
7. while priority_queue is not empty do
8.     u = extract vertex with minimum distance
9.     visited[u] = true
10.    
11.    for each neighbor v of u do
12.        if not visited[v] then
13.            alt = distance[u] + weight(u, v)
14.            if alt < distance[v] then
15.                distance[v] = alt
16.                parent[v] = u
17.                decrease_key(priority_queue, v, alt)
18.            end if
19.        end if
20.    end for
21. end while
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <queue>
#include <unordered_map>
#include <climits>
using namespace std;

/**
 * Edge representation for weighted graph
 */
struct Edge {
    int to;
    int weight;
    
    Edge(int t, int w) : to(t), weight(w) {}
};

/**
 * Weighted Graph using adjacency list
 */
class WeightedGraph {
private:
    unordered_map<int, vector<Edge>> adjList;
    bool isDirected;
    
public:
    WeightedGraph(bool directed = false) : isDirected(directed) {}
    
    void addEdge(int from, int to, int weight) {
        adjList[from].push_back(Edge(to, weight));
        if (!isDirected) {
            adjList[to].push_back(Edge(from, weight));
        }
    }
    
    vector<Edge> getNeighbors(int vertex) {
        return adjList[vertex];
    }
    
    vector<int> getAllVertices() {
        vector<int> vertices;
        for (auto& pair : adjList) {
            vertices.push_back(pair.first);
        }
        return vertices;
    }
    
    void printGraph() {
        for (auto& pair : adjList) {
            cout << pair.first << " -> ";
            for (Edge& edge : pair.second) {
                cout << "(" << edge.to << "," << edge.weight << ") ";
            }
            cout << endl;
        }
    }
};

/**
 * Priority queue element for Dijkstra's algorithm
 */
struct PQElement {
    int vertex;
    int distance;
    
    PQElement(int v, int d) : vertex(v), distance(d) {}
    
    // For min-heap (priority queue)
    bool operator>(const PQElement& other) const {
        return distance > other.distance;
    }
};

/**
 * Dijkstra's Algorithm Result
 */
struct DijkstraResult {
    unordered_map<int, int> distances;
    unordered_map<int, int> parents;
    vector<int> visitOrder;
};

/**
 * Basic Dijkstra's Algorithm Implementation
 */
DijkstraResult dijkstra(WeightedGraph& graph, int source) {
    DijkstraResult result;
    unordered_map<int, bool> visited;
    priority_queue<PQElement, vector<PQElement>, greater<PQElement>> pq;
    
    // Initialize distances
    for (int vertex : graph.getAllVertices()) {
        result.distances[vertex] = INT_MAX;
        result.parents[vertex] = -1;
        visited[vertex] = false;
    }
    
    result.distances[source] = 0;
    pq.push(PQElement(source, 0));
    
    while (!pq.empty()) {
        PQElement current = pq.top();
        pq.pop();
        
        int u = current.vertex;
        
        if (visited[u]) continue;
        
        visited[u] = true;
        result.visitOrder.push_back(u);
        
        // Relax all neighbors
        for (Edge& edge : graph.getNeighbors(u)) {
            int v = edge.to;
            int weight = edge.weight;
            
            if (!visited[v]) {
                int alt = result.distances[u] + weight;
                if (alt < result.distances[v]) {
                    result.distances[v] = alt;
                    result.parents[v] = u;
                    pq.push(PQElement(v, alt));
                }
            }
        }
    }
    
    return result;
}

/**
 * Dijkstra's Algorithm with Path Reconstruction
 */
vector<int> dijkstraPath(WeightedGraph& graph, int source, int target) {
    DijkstraResult result = dijkstra(graph, source);
    
    if (result.distances[target] == INT_MAX) {
        return {};  // No path exists
    }
    
    // Reconstruct path
    vector<int> path;
    int current = target;
    
    while (current != -1) {
        path.push_back(current);
        current = result.parents[current];
    }
    
    reverse(path.begin(), path.end());
    return path;
}

/**
 * Dijkstra's Algorithm with Statistics
 */
struct DijkstraStats {
    int verticesProcessed;
    int edgesRelaxed;
    int distanceUpdates;
    vector<pair<int, int>> relaxationHistory;  // (vertex, new_distance)
    unordered_map<int, int> finalDistances;
};

DijkstraStats dijkstraWithStats(WeightedGraph& graph, int source) {
    DijkstraStats stats = {0, 0, 0, {}, {}};
    unordered_map<int, int> distances;
    unordered_map<int, bool> visited;
    priority_queue<PQElement, vector<PQElement>, greater<PQElement>> pq;
    
    // Initialize
    for (int vertex : graph.getAllVertices()) {
        distances[vertex] = INT_MAX;
        visited[vertex] = false;
    }
    
    distances[source] = 0;
    pq.push(PQElement(source, 0));
    
    while (!pq.empty()) {
        PQElement current = pq.top();
        pq.pop();
        
        int u = current.vertex;
        
        if (visited[u]) continue;
        
        visited[u] = true;
        stats.verticesProcessed++;
        
        for (Edge& edge : graph.getNeighbors(u)) {
            int v = edge.to;
            int weight = edge.weight;
            stats.edgesRelaxed++;
            
            if (!visited[v]) {
                int alt = distances[u] + weight;
                if (alt < distances[v]) {
                    distances[v] = alt;
                    stats.distanceUpdates++;
                    stats.relaxationHistory.push_back({v, alt});
                    pq.push(PQElement(v, alt));
                }
            }
        }
    }
    
    stats.finalDistances = distances;
    return stats;
}

/**
 * Modified Dijkstra for All Pairs Shortest Path
 * Runs Dijkstra from each vertex
 */
unordered_map<int, unordered_map<int, int>> allPairsShortestPath(WeightedGraph& graph) {
    unordered_map<int, unordered_map<int, int>> allDistances;
    
    for (int source : graph.getAllVertices()) {
        DijkstraResult result = dijkstra(graph, source);
        allDistances[source] = result.distances;
    }
    
    return allDistances;
}

/**
 * Dijkstra with Early Termination
 * Stops when target is reached
 */
pair<int, vector<int>> dijkstraToTarget(WeightedGraph& graph, int source, int target) {
    unordered_map<int, int> distances;
    unordered_map<int, int> parents;
    unordered_map<int, bool> visited;
    priority_queue<PQElement, vector<PQElement>, greater<PQElement>> pq;
    
    // Initialize
    for (int vertex : graph.getAllVertices()) {
        distances[vertex] = INT_MAX;
        parents[vertex] = -1;
        visited[vertex] = false;
    }
    
    distances[source] = 0;
    pq.push(PQElement(source, 0));
    
    while (!pq.empty()) {
        PQElement current = pq.top();
        pq.pop();
        
        int u = current.vertex;
        
        if (visited[u]) continue;
        if (u == target) break;  // Early termination
        
        visited[u] = true;
        
        for (Edge& edge : graph.getNeighbors(u)) {
            int v = edge.to;
            int weight = edge.weight;
            
            if (!visited[v]) {
                int alt = distances[u] + weight;
                if (alt < distances[v]) {
                    distances[v] = alt;
                    parents[v] = u;
                    pq.push(PQElement(v, alt));
                }
            }
        }
    }
    
    // Reconstruct path
    vector<int> path;
    if (distances[target] != INT_MAX) {
        int current = target;
        while (current != -1) {
            path.push_back(current);
            current = parents[current];
        }
        reverse(path.begin(), path.end());
    }
    
    return {distances[target], path};
}

/**
 * Dijkstra with K Shortest Paths
 * Finds k shortest paths to target
 */
vector<pair<int, vector<int>>> kShortestPaths(WeightedGraph& graph, int source, int target, int k) {
    vector<pair<int, vector<int>>> paths;
    priority_queue<pair<int, vector<int>>, vector<pair<int, vector<int>>>, 
                   greater<pair<int, vector<int>>>> pq;
    
    // Start with shortest path
    auto shortestPath = dijkstraToTarget(graph, source, target);
    if (shortestPath.second.empty()) return paths;
    
    pq.push(shortestPath);
    
    while (!pq.empty() && paths.size() < k) {
        auto current = pq.top();
        pq.pop();
        
        paths.push_back(current);
        
        // Generate variations by removing edges (simplified version)
        // In practice, this would use Yen's algorithm or similar
    }
    
    return paths;
}

/**
 * Bidirectional Dijkstra
 * Searches from both source and target simultaneously
 */
pair<int, vector<int>> bidirectionalDijkstra(WeightedGraph& graph, int source, int target) {
    // Forward search from source
    unordered_map<int, int> distForward;
    unordered_map<int, int> parentForward;
    unordered_map<int, bool> visitedForward;
    priority_queue<PQElement, vector<PQElement>, greater<PQElement>> pqForward;
    
    // Backward search from target
    unordered_map<int, int> distBackward;
    unordered_map<int, int> parentBackward;
    unordered_map<int, bool> visitedBackward;
    priority_queue<PQElement, vector<PQElement>, greater<PQElement>> pqBackward;
    
    // Initialize forward search
    for (int vertex : graph.getAllVertices()) {
        distForward[vertex] = INT_MAX;
        parentForward[vertex] = -1;
        visitedForward[vertex] = false;
    }
    distForward[source] = 0;
    pqForward.push(PQElement(source, 0));
    
    // Initialize backward search
    for (int vertex : graph.getAllVertices()) {
        distBackward[vertex] = INT_MAX;
        parentBackward[vertex] = -1;
        visitedBackward[vertex] = false;
    }
    distBackward[target] = 0;
    pqBackward.push(PQElement(target, 0));
    
    int meetingPoint = -1;
    int shortestDistance = INT_MAX;
    
    while (!pqForward.empty() || !pqBackward.empty()) {
        // Forward step
        if (!pqForward.empty()) {
            PQElement current = pqForward.top();
            pqForward.pop();
            
            int u = current.vertex;
            
            if (!visitedForward[u]) {
                visitedForward[u] = true;
                
                // Check if we've met the backward search
                if (visitedBackward[u]) {
                    int totalDist = distForward[u] + distBackward[u];
                    if (totalDist < shortestDistance) {
                        shortestDistance = totalDist;
                        meetingPoint = u;
                    }
                }
                
                // Relax edges
                for (Edge& edge : graph.getNeighbors(u)) {
                    int v = edge.to;
                    int weight = edge.weight;
                    
                    if (!visitedForward[v]) {
                        int alt = distForward[u] + weight;
                        if (alt < distForward[v]) {
                            distForward[v] = alt;
                            parentForward[v] = u;
                            pqForward.push(PQElement(v, alt));
                        }
                    }
                }
            }
        }
        
        // Backward step (similar logic with reversed edges)
        // Implementation would require reverse graph or undirected graph
    }
    
    // Reconstruct path through meeting point
    vector<int> path;
    if (meetingPoint != -1) {
        // Build path from source to meeting point
        vector<int> forwardPath;
        int current = meetingPoint;
        while (current != -1) {
            forwardPath.push_back(current);
            current = parentForward[current];
        }
        reverse(forwardPath.begin(), forwardPath.end());
        
        // Build path from meeting point to target
        vector<int> backwardPath;
        current = meetingPoint;
        while (current != -1) {
            backwardPath.push_back(current);
            current = parentBackward[current];
        }
        
        // Combine paths
        path = forwardPath;
        for (int i = 1; i < backwardPath.size(); i++) {
            path.push_back(backwardPath[i]);
        }
    }
    
    return {shortestDistance, path};
}

// Utility functions
void printDistances(const unordered_map<int, int>& distances, int source) {
    cout << "Shortest distances from vertex " << source << ":" << endl;
    for (auto& pair : distances) {
        if (pair.second == INT_MAX) {
            cout << "  To " << pair.first << ": INF" << endl;
        } else {
            cout << "  To " << pair.first << ": " << pair.second << endl;
        }
    }
}

void printPath(const vector<int>& path, int distance) {
    if (path.empty()) {
        cout << "No path found" << endl;
        return;
    }
    
    cout << "Path (distance " << distance << "): ";
    for (int i = 0; i < path.size(); i++) {
        cout << path[i];
        if (i < path.size() - 1) cout << " -> ";
    }
    cout << endl;
}

// Example usage and testing
int main() {
    // Create sample weighted graph
    WeightedGraph graph(false);  // Undirected graph
    
    // Add weighted edges
    graph.addEdge(0, 1, 4);
    graph.addEdge(0, 2, 2);
    graph.addEdge(1, 2, 1);
    graph.addEdge(1, 3, 5);
    graph.addEdge(2, 3, 8);
    graph.addEdge(2, 4, 10);
    graph.addEdge(3, 4, 2);
    graph.addEdge(3, 5, 6);
    graph.addEdge(4, 5, 3);
    
    cout << "=== Weighted Graph Structure ===" << endl;
    graph.printGraph();
    
    // Test basic Dijkstra's algorithm
    cout << "\n=== Dijkstra's Algorithm from vertex 0 ===" << endl;
    DijkstraResult result = dijkstra(graph, 0);
    printDistances(result.distances, 0);
    
    cout << "Visit order: ";
    for (int vertex : result.visitOrder) {
        cout << vertex << " ";
    }
    cout << endl;
    
    // Test shortest path to specific target
    cout << "\n=== Shortest Path from 0 to 5 ===" << endl;
    vector<int> path = dijkstraPath(graph, 0, 5);
    printPath(path, result.distances[5]);
    
    // Test Dijkstra with statistics
    cout << "\n=== Dijkstra Statistics ===" << endl;
    DijkstraStats stats = dijkstraWithStats(graph, 0);
    cout << "Vertices processed: " << stats.verticesProcessed << endl;
    cout << "Edges relaxed: " << stats.edgesRelaxed << endl;
    cout << "Distance updates: " << stats.distanceUpdates << endl;
    
    cout << "Relaxation history:" << endl;
    for (auto& update : stats.relaxationHistory) {
        cout << "  Vertex " << update.first << " -> distance " << update.second << endl;
    }
    
    // Test early termination
    cout << "\n=== Dijkstra with Early Termination (0 to 5) ===" << endl;
    auto targetResult = dijkstraToTarget(graph, 0, 5);
    cout << "Distance to target: " << targetResult.first << endl;
    cout << "Path: ";
    for (int i = 0; i < targetResult.second.size(); i++) {
        cout << targetResult.second[i];
        if (i < targetResult.second.size() - 1) cout << " -> ";
    }
    cout << endl;
    
    // Test all pairs shortest path
    cout << "\n=== All Pairs Shortest Paths ===" << endl;
    auto allPairs = allPairsShortestPath(graph);
    for (auto& sourcePair : allPairs) {
        int source = sourcePair.first;
        cout << "From vertex " << source << ":" << endl;
        for (auto& targetPair : sourcePair.second) {
            int target = targetPair.first;
            int distance = targetPair.second;
            if (source != target) {
                cout << "  To " << target << ": " << 
                        (distance == INT_MAX ? "INF" : to_string(distance)) << endl;
            }
        }
    }
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Binary Heap:</strong> O((V + E) log V) - Standard implementation</li>
                <li><strong>Fibonacci Heap:</strong> O(E + V log V) - Theoretical optimum</li>
                <li><strong>Array Implementation:</strong> O(V²) - For dense graphs</li>
                <li><strong>Dense Graphs:</strong> O(V²) when E ≈ V²</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Distance Array:</strong> O(V) - Store distances to all vertices</li>
                <li><strong>Parent Array:</strong> O(V) - For path reconstruction</li>
                <li><strong>Priority Queue:</strong> O(V) - Maximum vertices in queue</li>
                <li><strong>Total Space:</strong> O(V) auxiliary space</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Optimality:</strong> Finds shortest paths with non-negative weights</li>
                <li><strong>Greedy Algorithm:</strong> Makes locally optimal choices</li>
                <li><strong>Single Source:</strong> Computes shortest paths from one source</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through Dijkstra's algorithm on a weighted graph:
        </p>
        
        <div class="code-block">
Graph:     0 ----4---- 1
           |           /|
           2          1 5
           |         /  |
           2 ----8---- 3
           |           |
          10          2
           |           |
           4 ----3---- 5

Dijkstra from vertex 0:

Initial: dist[0]=0, dist[others]=∞, PQ=[(0,0)]

Step 1: Process vertex 0 (distance 0)
- Relax edge 0->1: dist[1] = min(∞, 0+4) = 4
- Relax edge 0->2: dist[2] = min(∞, 0+2) = 2
- PQ = [(2,2), (1,4)]

Step 2: Process vertex 2 (distance 2)
- Relax edge 2->1: dist[1] = min(4, 2+1) = 3
- Relax edge 2->3: dist[3] = min(∞, 2+8) = 10
- Relax edge 2->4: dist[4] = min(∞, 2+10) = 12
- PQ = [(1,3), (1,4), (3,10), (4,12)]

Step 3: Process vertex 1 (distance 3)
- Relax edge 1->3: dist[3] = min(10, 3+5) = 8
- PQ = [(1,4), (3,8), (3,10), (4,12)]

Step 4: Process vertex 1 again (distance 4) - skip (already processed)

Step 5: Process vertex 3 (distance 8)
- Relax edge 3->5: dist[5] = min(∞, 8+2) = 10
- PQ = [(3,10), (5,10), (4,12)]

Step 6: Process vertex 3 again (distance 10) - skip

Step 7: Process vertex 5 (distance 10)
- Relax edge 5->4: dist[4] = min(12, 10+3) = 11
- PQ = [(4,11), (4,12)]

Step 8: Process vertex 4 (distance 11)
- All neighbors already processed

Final distances: 0->0:0, 0->1:3, 0->2:2, 0->3:8, 0->4:11, 0->5:10
Shortest path 0->5: 0 -> 2 -> 1 -> 3 -> 5 (distance 10)
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Dijkstra's algorithm has numerous real-world applications:
        </p>
        
        <ul>
            <li><strong>GPS Navigation:</strong> Finding shortest routes in road networks</li>
            <li><strong>Network Routing:</strong> Optimal packet routing in computer networks</li>
            <li><strong>Social Networks:</strong> Finding shortest connection paths</li>
            <li><strong>Game AI:</strong> Pathfinding for NPCs and game characters</li>
            <li><strong>Flight Planning:</strong> Optimal flight routes considering fuel costs</li>
            <li><strong>Robotics:</strong> Path planning for autonomous robots</li>
            <li><strong>Telecommunications:</strong> Optimal signal routing</li>
            <li><strong>Supply Chain:</strong> Minimizing transportation costs</li>
        </ul>
        
        <h2 class="section-title">Algorithm Variants</h2>
        
        <div class="definition-box">
            <strong>Standard Dijkstra:</strong><br>
            • Single-source shortest paths<br>
            • Works with non-negative weights only<br>
            • Uses priority queue for efficiency<br><br>
            
            <strong>Bidirectional Dijkstra:</strong><br>
            • Searches from both source and target<br>
            • Often faster for single target queries<br>
            • Meets in the middle approach<br><br>
            
            <strong>A* Algorithm:</strong><br>
            • Dijkstra with heuristic function<br>
            • Guides search toward target<br>
            • Optimal with admissible heuristic
        </div>
        
        <h2 class="section-title">When to Use Dijkstra's Algorithm</h2>
        
        <div class="definition-box">
            <strong>Use Dijkstra When:</strong><br>
            • Finding shortest paths in weighted graphs<br>
            • All edge weights are non-negative<br>
            • Need optimal solution guaranteed<br>
            • Single-source multiple-target scenarios<br>
            • Graph is not too dense<br><br>
            
            <strong>Don't Use Dijkstra When:</strong><br>
            • Graph has negative edge weights (use Bellman-Ford)<br>
            • Only need to check path existence (use BFS/DFS)<br>
            • All edges have equal weight (use BFS)<br>
            • Need all-pairs shortest paths (use Floyd-Warshall)
        </div>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Negative Weights:</strong> Algorithm fails with negative edge weights</li>
            <li><strong>Priority Queue Issues:</strong> Not updating priorities correctly</li>
            <li><strong>Visited Check:</strong> Processing same vertex multiple times</li>
            <li><strong>Initialization:</strong> Forgetting to initialize distances to infinity</li>
            <li><strong>Path Reconstruction:</strong> Not storing parent pointers correctly</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Greedy Nature:</strong> Explain why greedy approach works</li>
            <li><strong>Priority Queue:</strong> Emphasize importance of min-heap</li>
            <li><strong>Non-negative Weights:</strong> Highlight this crucial constraint</li>
            <li><strong>Relaxation:</strong> Explain edge relaxation process clearly</li>
            <li><strong>Applications:</strong> Mention GPS and network routing</li>
            <li><strong>Complexity:</strong> Know different implementations and their complexities</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Dijkstra's algorithm finds shortest paths from single source to all vertices</li>
                <li>Requires non-negative edge weights for correctness</li>
                <li>Uses greedy approach with priority queue for efficiency</li>
                <li>Time complexity O((V + E) log V) with binary heap</li>
                <li>Space complexity O(V) for distance and parent arrays</li>
                <li>Foundation for many pathfinding and routing algorithms</li>
                <li>Can be optimized with better data structures or heuristics</li>
            </ul>
        </div>
    </div>

    </div>
            
    <div class="min-h-screen academic-content page-break" id="ch21">
        
    <div class="academic-content">
        <div class="chapter-number">CHAPTER 21</div>
        <h1 class="chapter-title">Bellman-Ford Algorithm</h1>
        
        <p class="academic-text">
            The Bellman-Ford algorithm finds the shortest paths from a single source vertex to all other vertices in a weighted graph, even when the graph contains negative edge weights. Unlike Dijkstra's algorithm, Bellman-Ford can handle negative weights and can detect negative cycles. It uses dynamic programming principles and is essential for applications involving negative costs or detecting arbitrage opportunities.
        </p>
        
        <h2 class="section-title">Problem Statement</h2>
        
        <p class="academic-text">
            Given a weighted directed graph G = (V, E) with possibly negative edge weights and a source vertex s, find the shortest path from s to all other vertices. If a negative cycle is reachable from the source, detect and report it.
        </p>
        
        <div class="definition-box">
            <strong>Input:</strong> Weighted graph G (can have negative weights) and source vertex s<br>
            <strong>Output:</strong> Shortest distances and paths, or negative cycle detection<br>
            <strong>Advantage:</strong> Handles negative edge weights unlike Dijkstra's algorithm
        </div>
        
        <h2 class="section-title">Approach</h2>
        
        <p class="academic-text">
            Bellman-Ford algorithm works through these phases:
        </p>
        
        <ol>
            <li><strong>Initialize:</strong> Set distance to source as 0, all others as infinity</li>
            <li><strong>Relax Edges:</strong> For V-1 iterations, relax all edges</li>
            <li><strong>Check Negative Cycles:</strong> Run one more iteration to detect negative cycles</li>
            <li><strong>Report Results:</strong> Return distances or negative cycle detection</li>
        </ol>
        
        <h2 class="section-title">Algorithm Steps</h2>
        
        <div class="code-block">
Algorithm: BellmanFord(graph, source)
1. distance[all vertices] = infinity
2. distance[source] = 0
3. parent[all vertices] = null
4. 
5. // Relax all edges V-1 times
6. for i = 1 to |V| - 1 do
7.     for each edge (u, v) with weight w do
8.         if distance[u] != infinity AND distance[u] + w < distance[v] then
9.             distance[v] = distance[u] + w
10.            parent[v] = u
11.        end if
12.    end for
13. end for
14. 
15. // Check for negative cycles
16. for each edge (u, v) with weight w do
17.     if distance[u] != infinity AND distance[u] + w < distance[v] then
18.         return "Negative cycle detected"
19.     end if
20. end for
21. 
22. return distance, parent
        </div>
        
        <h2 class="section-title">Implementation</h2>
        
        <div class="code-block">
#include <iostream>
#include <vector>
#include <unordered_map>
#include <climits>
using namespace std;

/**
 * Edge representation for weighted graph
 */
struct Edge {
    int from, to, weight;
    
    Edge(int f, int t, int w) : from(f), to(t), weight(w) {}
};

/**
 * Weighted Graph using edge list representation
 */
class WeightedGraph {
private:
    vector<Edge> edges;
    unordered_map<int, vector<int>> adjList;  // For neighbor access
    
public:
    void addEdge(int from, int to, int weight) {
        edges.push_back(Edge(from, to, weight));
        adjList[from].push_back(edges.size() - 1);  // Store edge index
    }
    
    vector<Edge>& getEdges() {
        return edges;
    }
    
    vector<int> getAllVertices() {
        unordered_map<int, bool> vertices;
        for (const Edge& edge : edges) {
            vertices[edge.from] = true;
            vertices[edge.to] = true;
        }
        
        vector<int> result;
        for (auto& pair : vertices) {
            result.push_back(pair.first);
        }
        return result;
    }
    
    void printGraph() {
        cout << "Edges:" << endl;
        for (const Edge& edge : edges) {
            cout << edge.from << " -> " << edge.to << " (weight: " << edge.weight << ")" << endl;
        }
    }
};

/**
 * Bellman-Ford Algorithm Result
 */
struct BellmanFordResult {
    unordered_map<int, long long> distances;
    unordered_map<int, int> parents;
    bool hasNegativeCycle;
    vector<int> negativeCycle;
};

/**
 * Basic Bellman-Ford Algorithm Implementation
 */
BellmanFordResult bellmanFord(WeightedGraph& graph, int source) {
    BellmanFordResult result;
    vector<int> vertices = graph.getAllVertices();
    vector<Edge>& edges = graph.getEdges();
    
    // Initialize distances
    for (int vertex : vertices) {
        result.distances[vertex] = LLONG_MAX;
        result.parents[vertex] = -1;
    }
    result.distances[source] = 0;
    result.hasNegativeCycle = false;
    
    int V = vertices.size();
    
    // Relax all edges V-1 times
    for (int i = 0; i < V - 1; i++) {
        bool updated = false;
        
        for (const Edge& edge : edges) {
            if (result.distances[edge.from] != LLONG_MAX) {
                long long newDist = result.distances[edge.from] + edge.weight;
                if (newDist < result.distances[edge.to]) {
                    result.distances[edge.to] = newDist;
                    result.parents[edge.to] = edge.from;
                    updated = true;
                }
            }
        }
        
        // Early termination if no updates
        if (!updated) break;
    }
    
    // Check for negative cycles
    for (const Edge& edge : edges) {
        if (result.distances[edge.from] != LLONG_MAX) {
            long long newDist = result.distances[edge.from] + edge.weight;
            if (newDist < result.distances[edge.to]) {
                result.hasNegativeCycle = true;
                
                // Find negative cycle
                unordered_map<int, bool> inCycle;
                int current = edge.to;
                
                // Move V steps to ensure we're in the cycle
                for (int i = 0; i < V; i++) {
                    current = result.parents[current];
                }
                
                // Collect cycle vertices
                int start = current;
                do {
                    result.negativeCycle.push_back(current);
                    current = result.parents[current];
                } while (current != start);
                
                reverse(result.negativeCycle.begin(), result.negativeCycle.end());
                break;
            }
        }
    }
    
    return result;
}

/**
 * Bellman-Ford with Statistics
 */
struct BellmanFordStats {
    int iterations;
    int edgeRelaxations;
    int distanceUpdates;
    vector<vector<long long>> distanceHistory;
    bool earlyTermination;
};

BellmanFordStats bellmanFordWithStats(WeightedGraph& graph, int source) {
    BellmanFordStats stats = {0, 0, 0, {}, false};
    unordered_map<int, long long> distances;
    vector<int> vertices = graph.getAllVertices();
    vector<Edge>& edges = graph.getEdges();
    
    // Initialize
    for (int vertex : vertices) {
        distances[vertex] = LLONG_MAX;
    }
    distances[source] = 0;
    
    // Save initial state
    vector<long long> initialState;
    for (int vertex : vertices) {
        initialState.push_back(distances[vertex]);
    }
    stats.distanceHistory.push_back(initialState);
    
    int V = vertices.size();
    
    // Main algorithm
    for (int i = 0; i < V - 1; i++) {
        stats.iterations++;
        bool updated = false;
        
        for (const Edge& edge : edges) {
            stats.edgeRelaxations++;
            
            if (distances[edge.from] != LLONG_MAX) {
                long long newDist = distances[edge.from] + edge.weight;
                if (newDist < distances[edge.to]) {
                    distances[edge.to] = newDist;
                    stats.distanceUpdates++;
                    updated = true;
                }
            }
        }
        
        // Save state after each iteration
        vector<long long> currentState;
        for (int vertex : vertices) {
            currentState.push_back(distances[vertex]);
        }
        stats.distanceHistory.push_back(currentState);
        
        if (!updated) {
            stats.earlyTermination = true;
            break;
        }
    }
    
    return stats;
}

/**
 * Bellman-Ford for Shortest Path to Specific Target
 */
pair<long long, vector<int>> bellmanFordPath(WeightedGraph& graph, int source, int target) {
    BellmanFordResult result = bellmanFord(graph, source);
    
    if (result.hasNegativeCycle) {
        return {LLONG_MIN, {}};  // Indicate negative cycle
    }
    
    if (result.distances[target] == LLONG_MAX) {
        return {LLONG_MAX, {}};  // No path
    }
    
    // Reconstruct path
    vector<int> path;
    int current = target;
    
    while (current != -1) {
        path.push_back(current);
        current = result.parents[current];
    }
    
    reverse(path.begin(), path.end());
    return {result.distances[target], path};
}

/**
 * Modified Bellman-Ford for Detecting All Negative Cycles
 */
vector<vector<int>> findAllNegativeCycles(WeightedGraph& graph) {
    vector<vector<int>> cycles;
    vector<int> vertices = graph.getAllVertices();
    vector<Edge>& edges = graph.getEdges();
    
    for (int source : vertices) {
        unordered_map<int, long long> distances;
        unordered_map<int, int> parents;
        
        // Initialize
        for (int vertex : vertices) {
            distances[vertex] = LLONG_MAX;
            parents[vertex] = -1;
        }
        distances[source] = 0;
        
        int V = vertices.size();
        
        // Relax edges V-1 times
        for (int i = 0; i < V - 1; i++) {
            for (const Edge& edge : edges) {
                if (distances[edge.from] != LLONG_MAX) {
                    long long newDist = distances[edge.from] + edge.weight;
                    if (newDist < distances[edge.to]) {
                        distances[edge.to] = newDist;
                        parents[edge.to] = edge.from;
                    }
                }
            }
        }
        
        // Check for negative cycles
        for (const Edge& edge : edges) {
            if (distances[edge.from] != LLONG_MAX) {
                long long newDist = distances[edge.from] + edge.weight;
                if (newDist < distances[edge.to]) {
                    // Found negative cycle, extract it
                    vector<int> cycle;
                    unordered_map<int, bool> visited;
                    int current = edge.to;
                    
                    // Move to ensure we're in the cycle
                    for (int i = 0; i < V; i++) {
                        current = parents[current];
                    }
                    
                    // Extract cycle
                    int start = current;
                    do {
                        cycle.push_back(current);
                        current = parents[current];
                    } while (current != start);
                    
                    reverse(cycle.begin(), cycle.end());
                    cycles.push_back(cycle);
                    break;
                }
            }
        }
    }
    
    return cycles;
}

/**
 * SPFA (Shortest Path Faster Algorithm) - Optimized Bellman-Ford
 */
BellmanFordResult spfa(WeightedGraph& graph, int source) {
    BellmanFordResult result;
    vector<int> vertices = graph.getAllVertices();
    vector<Edge>& edges = graph.getEdges();
    
    // Build adjacency list for SPFA
    unordered_map<int, vector<pair<int, int>>> adj;
    for (const Edge& edge : edges) {
        adj[edge.from].push_back({edge.to, edge.weight});
    }
    
    // Initialize
    for (int vertex : vertices) {
        result.distances[vertex] = LLONG_MAX;
        result.parents[vertex] = -1;
    }
    result.distances[source] = 0;
    result.hasNegativeCycle = false;
    
    // SPFA using queue
    queue<int> q;
    unordered_map<int, bool> inQueue;
    unordered_map<int, int> relaxCount;
    
    q.push(source);
    inQueue[source] = true;
    
    while (!q.empty()) {
        int u = q.front();
        q.pop();
        inQueue[u] = false;
        
        for (auto& edge : adj[u]) {
            int v = edge.first;
            int weight = edge.second;
            
            if (result.distances[u] != LLONG_MAX) {
                long long newDist = result.distances[u] + weight;
                if (newDist < result.distances[v]) {
                    result.distances[v] = newDist;
                    result.parents[v] = u;
                    
                    if (!inQueue[v]) {
                        q.push(v);
                        inQueue[v] = true;
                        relaxCount[v]++;
                        
                        // Negative cycle detection
                        if (relaxCount[v] >= vertices.size()) {
                            result.hasNegativeCycle = true;
                            return result;
                        }
                    }
                }
            }
        }
    }
    
    return result;
}

/**
 * Bellman-Ford for Currency Arbitrage Detection
 */
bool detectArbitrage(vector<vector<double>>& exchangeRates) {
    int n = exchangeRates.size();
    
    // Convert to negative log to use Bellman-Ford
    WeightedGraph graph;
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            if (i != j && exchangeRates[i][j] > 0) {
                int weight = (int)(-log(exchangeRates[i][j]) * 1000);  // Scale for integer
                graph.addEdge(i, j, weight);
            }
        }
    }
    
    // Run Bellman-Ford from each vertex
    for (int source = 0; source < n; source++) {
        BellmanFordResult result = bellmanFord(graph, source);
        if (result.hasNegativeCycle) {
            return true;  // Arbitrage opportunity found
        }
    }
    
    return false;
}

// Utility functions
void printDistances(const unordered_map<int, long long>& distances, int source) {
    cout << "Shortest distances from vertex " << source << ":" << endl;
    for (auto& pair : distances) {
        if (pair.second == LLONG_MAX) {
            cout << "  To " << pair.first << ": INF" << endl;
        } else {
            cout << "  To " << pair.first << ": " << pair.second << endl;
        }
    }
}

void printPath(const vector<int>& path, long long distance) {
    if (path.empty()) {
        cout << "No path found" << endl;
        return;
    }
    
    cout << "Path (distance " << distance << "): ";
    for (int i = 0; i < path.size(); i++) {
        cout << path[i];
        if (i < path.size() - 1) cout << " -> ";
    }
    cout << endl;
}

void printNegativeCycle(const vector<int>& cycle) {
    if (cycle.empty()) {
        cout << "No negative cycle" << endl;
        return;
    }
    
    cout << "Negative cycle: ";
    for (int i = 0; i < cycle.size(); i++) {
        cout << cycle[i];
        if (i < cycle.size() - 1) cout << " -> ";
    }
    cout << " -> " << cycle[0] << endl;
}

// Example usage and testing
int main() {
    // Create sample weighted graph with negative edges
    WeightedGraph graph;
    
    // Add edges (some with negative weights)
    graph.addEdge(0, 1, 4);
    graph.addEdge(0, 2, 2);
    graph.addEdge(1, 2, -3);
    graph.addEdge(1, 3, 2);
    graph.addEdge(1, 4, 3);
    graph.addEdge(2, 3, 4);
    graph.addEdge(2, 4, 5);
    graph.addEdge(3, 4, -5);
    
    cout << "=== Weighted Graph with Negative Edges ===" << endl;
    graph.printGraph();
    
    // Test basic Bellman-Ford algorithm
    cout << "\n=== Bellman-Ford Algorithm from vertex 0 ===" << endl;
    BellmanFordResult result = bellmanFord(graph, 0);
    
    if (result.hasNegativeCycle) {
        cout << "Negative cycle detected!" << endl;
        printNegativeCycle(result.negativeCycle);
    } else {
        printDistances(result.distances, 0);
    }
    
    // Test shortest path to specific target
    cout << "\n=== Shortest Path from 0 to 4 ===" << endl;
    auto pathResult = bellmanFordPath(graph, 0, 4);
    
    if (pathResult.first == LLONG_MIN) {
        cout << "Cannot find shortest path due to negative cycle" << endl;
    } else if (pathResult.first == LLONG_MAX) {
        cout << "No path exists" << endl;
    } else {
        printPath(pathResult.second, pathResult.first);
    }
    
    // Test Bellman-Ford with statistics
    cout << "\n=== Bellman-Ford Statistics ===" << endl;
    BellmanFordStats stats = bellmanFordWithStats(graph, 0);
    cout << "Iterations completed: " << stats.iterations << endl;
    cout << "Edge relaxations: " << stats.edgeRelaxations << endl;
    cout << "Distance updates: " << stats.distanceUpdates << endl;
    cout << "Early termination: " << (stats.earlyTermination ? "Yes" : "No") << endl;
    
    cout << "Distance evolution:" << endl;
    vector<int> vertices = graph.getAllVertices();
    sort(vertices.begin(), vertices.end());
    
    for (int iter = 0; iter < stats.distanceHistory.size(); iter++) {
        cout << "  Iteration " << iter << ": ";
        for (int i = 0; i < vertices.size(); i++) {
            long long dist = stats.distanceHistory[iter][i];
            if (dist == LLONG_MAX) {
                cout << "INF ";
            } else {
                cout << dist << " ";
            }
        }
        cout << endl;
    }
    
    // Test SPFA algorithm
    cout << "\n=== SPFA Algorithm from vertex 0 ===" << endl;
    BellmanFordResult spfaResult = spfa(graph, 0);
    
    if (spfaResult.hasNegativeCycle) {
        cout << "SPFA detected negative cycle!" << endl;
    } else {
        printDistances(spfaResult.distances, 0);
    }
    
    // Test with graph containing negative cycle
    cout << "\n=== Graph with Negative Cycle ===" << endl;
    WeightedGraph negCycleGraph;
    negCycleGraph.addEdge(0, 1, 1);
    negCycleGraph.addEdge(1, 2, -3);
    negCycleGraph.addEdge(2, 3, 2);
    negCycleGraph.addEdge(3, 1, -1);  // Creates negative cycle: 1->2->3->1
    
    BellmanFordResult negResult = bellmanFord(negCycleGraph, 0);
    if (negResult.hasNegativeCycle) {
        cout << "Negative cycle found!" << endl;
        printNegativeCycle(negResult.negativeCycle);
    }
    
    // Test currency arbitrage detection
    cout << "\n=== Currency Arbitrage Detection ===" << endl;
    vector<vector<double>> exchangeRates = {
        {1.0, 0.741, 0.657, 1.061},
        {1.349, 1.0, 0.888, 1.433},
        {1.521, 1.126, 1.0, 1.614},
        {0.942, 0.698, 0.619, 1.0}
    };
    
    bool hasArbitrage = detectArbitrage(exchangeRates);
    cout << "Arbitrage opportunity: " << (hasArbitrage ? "Yes" : "No") << endl;
    
    return 0;
}
        </div>
        
        <h2 class="section-title">Complexity Analysis</h2>
        
        <div class="performance-summary">
            <h3>Time Complexity</h3>
            <ul>
                <li><strong>Standard Bellman-Ford:</strong> O(VE) - V-1 iterations over E edges</li>
                <li><strong>SPFA (Average):</strong> O(E) - Queue-based optimization</li>
                <li><strong>SPFA (Worst):</strong> O(VE) - Same as standard in worst case</li>
                <li><strong>Dense Graphs:</strong> O(V³) when E ≈ V²</li>
            </ul>
            
            <h3>Space Complexity</h3>
            <ul>
                <li><strong>Distance Array:</strong> O(V) - Store distances to all vertices</li>
                <li><strong>Parent Array:</strong> O(V) - For path reconstruction</li>
                <li><strong>Edge List:</strong> O(E) - Store all edges</li>
                <li><strong>Total Space:</strong> O(V + E) auxiliary space</li>
            </ul>
            
            <h3>Other Properties</h3>
            <ul>
                <li><strong>Handles Negative Weights:</strong> Unlike Dijkstra's algorithm</li>
                <li><strong>Detects Negative Cycles:</strong> Can identify and report cycles</li>
                <li><strong>Dynamic Programming:</strong> Uses optimal substructure principle</li>
            </ul>
        </div>
        
        <h2 class="section-title">Example Walkthrough</h2>
        
        <p class="academic-text">
            Let's trace through Bellman-Ford algorithm on a graph with negative edges:
        </p>
        
        <div class="code-block">
Graph: 0 --4--> 1 --2--> 3
       |        |       ^
       2        -3      |
       v        v       4
       2 --------> 4 ---

Bellman-Ford from vertex 0:

Initial: dist[0]=0, dist[others]=∞

Iteration 1: Relax all edges
- Edge 0->1: dist[1] = min(∞, 0+4) = 4
- Edge 0->2: dist[2] = min(∞, 0+2) = 2
- Edge 1->2: dist[2] = min(2, 4+(-3)) = 1
- Edge 1->3: dist[3] = min(∞, 4+2) = 6
- Edge 2->4: dist[4] = min(∞, 1+5) = 6
- Edge 4->3: dist[3] = min(6, 6+4) = 6

After iteration 1: [0, 4, 1, 6, 6]

Iteration 2: Relax all edges
- Edge 0->1: dist[1] = min(4, 0+4) = 4 (no change)
- Edge 0->2: dist[2] = min(1, 0+2) = 1 (no change)
- Edge 1->2: dist[2] = min(1, 4+(-3)) = 1 (no change)
- Edge 1->3: dist[3] = min(6, 4+2) = 6 (no change)
- Edge 2->4: dist[4] = min(6, 1+5) = 6 (no change)
- Edge 4->3: dist[3] = min(6, 6+4) = 6 (no change)

After iteration 2: [0, 4, 1, 6, 6] (no changes)

Iteration 3: No changes, algorithm can terminate early

Negative Cycle Check: Run one more iteration
- All edges produce no improvements
- No negative cycle detected

Final distances: 0->0:0, 0->1:4, 0->2:1, 0->3:6, 0->4:6
Shortest path 0->3: 0 -> 1 -> 3 (distance 6)
        </div>
        
        <h2 class="section-title">Applications</h2>
        
        <p class="academic-text">
            Bellman-Ford algorithm has important applications:
        </p>
        
        <ul>
            <li><strong>Currency Arbitrage:</strong> Detecting profitable currency exchange cycles</li>
            <li><strong>Network Routing:</strong> Protocols like RIP use distance-vector algorithms</li>
            <li><strong>Game Theory:</strong> Finding optimal strategies with negative payoffs</li>
            <li><strong>Economics:</strong> Modeling markets with transaction costs</li>
            <li><strong>Social Networks:</strong> Analyzing influence propagation with negative effects</li>
            <li><strong>Constraint Systems:</strong> Solving difference constraint systems</li>
            <li><strong>VLSI Design:</strong> Timing analysis with negative delays</li>
            <li><strong>Transportation:</strong> Routes with tolls, fees, or penalties</li>
        </ul>
        
        <h2 class="section-title">Bellman-Ford vs Dijkstra</h2>
        
        <div class="definition-box">
            <strong>Bellman-Ford Advantages:</strong><br>
            • Handles negative edge weights<br>
            • Detects negative cycles<br>
            • Simpler implementation<br>
            • Works with any edge weight distribution<br><br>
            
            <strong>Bellman-Ford Disadvantages:</strong><br>
            • Slower time complexity O(VE)<br>
            • Not suitable for large dense graphs<br>
            • Cannot handle negative cycles in paths<br><br>
            
            <strong>When to Use Bellman-Ford:</strong><br>
            • Graph has negative edge weights<br>
            • Need to detect negative cycles<br>
            • Graph is sparse (E << V²)<br>
            • Correctness more important than speed
        </div>
        
        <h2 class="section-title">Algorithm Optimizations</h2>
        
        <p class="academic-text">
            Several optimizations can improve Bellman-Ford performance:
        </p>
        
        <ul>
            <li><strong>Early Termination:</strong> Stop if no updates in an iteration</li>
            <li><strong>SPFA:</strong> Use queue to process only vertices with updated distances</li>
            <li><strong>Yen's Optimization:</strong> Maintain candidate list of vertices to process</li>
            <li><strong>Parallel Processing:</strong> Relax edges in parallel</li>
        </ul>
        
        <h2 class="section-title">Common Pitfalls ⚠️</h2>
        
        <ul>
            <li><strong>Negative Cycles:</strong> Algorithm cannot find shortest paths through negative cycles</li>
            <li><strong>Integer Overflow:</strong> Large negative weights can cause overflow</li>
            <li><strong>Initialization:</strong> Must initialize source distance to 0, others to infinity</li>
            <li><strong>Edge Order:</strong> Different edge processing orders may affect convergence speed</li>
            <li><strong>Cycle Detection:</strong> Must run additional iteration to detect negative cycles</li>
        </ul>
        
        <h2 class="section-title">Interview Tips 🎯</h2>
        
        <ul>
            <li><strong>Negative Weights:</strong> Emphasize this key advantage over Dijkstra</li>
            <li><strong>Dynamic Programming:</strong> Explain the DP principle behind the algorithm</li>
            <li><strong>Relaxation:</strong> Clearly explain the edge relaxation process</li>
            <li><strong>Negative Cycles:</strong> Know how to detect and handle them</li>
            <li><strong>Applications:</strong> Mention currency arbitrage and network routing</li>
            <li><strong>Complexity Trade-off:</strong> Discuss when to use vs Dijkstra</li>
        </ul>
        
        <div class="completion-summary">
            <h3>Key Takeaways</h3>
            <ul>
                <li>Bellman-Ford finds shortest paths with negative edge weights</li>
                <li>Can detect negative cycles in the graph</li>
                <li>Uses dynamic programming with V-1 iterations of edge relaxation</li>
                <li>Time complexity O(VE), slower than Dijkstra but more general</li>
                <li>Space complexity O(V) for distance and parent arrays</li>
                <li>Essential for applications with negative costs or cycle detection</li>
                <li>Can be optimized with SPFA and early termination techniques</li>
            </ul>
        </div>
    </div>

    </div>
            
</body>
</html>